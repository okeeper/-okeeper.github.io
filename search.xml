<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>为网站申请免费的ssl证书</title>
      <link href="/ruan-jian-bi-ji/wei-wang-zhan-shen-qing-mian-fei-de-ssl/"/>
      <url>/ruan-jian-bi-ji/wei-wang-zhan-shen-qing-mian-fei-de-ssl/</url>
      
        <content type="html"><![CDATA[<ol><li><p><a href="http://xn--fressssl-2z1p39x.cn" target="_blank" rel="noopener">打开fressssl.cn</a></p><p><a href="https://freessl.cn/" target="_blank" rel="noopener">https://freessl.cn/</a></p></li><li><p>进入控制台，点击证书自动化</p><p><a href="https://freessl.cn/chart" target="_blank" rel="noopener">https://freessl.cn/chart</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164049693.png" alt="image-20241227164049693"></p></li><li><p>点击域名授权，添加域名，如果有多个可以添加多个，重复此步骤即可</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227170200615.png" alt="image-20241227170200615"></p></li><li><p>添加域名后，还需要到dns域名解析配置响应的DCV, 如阿里云的dns域名配置，填入步骤3所示的主机记录和记录值</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164438454.png" alt="image-20241227164438454"></p></li><li><p>点击ACME客户端，申请证书</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164621669.png" alt="image-20241227164621669"></p></li><li><p>复制ACME.sh命令，到服务端执行</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164802715.png" alt="image-20241227164802715"></p><blockquote><p>前提要先按照ACME.sh命令，参考文档：<a href="https://docs.certcloud.cn/docs/edupki/acme/" target="_blank" rel="noopener">https://docs.certcloud.cn/docs/edupki/acme/</a></p></blockquote><p>执行成功后，默认会在~/.acme.sh/目录下生成对应域名的目录下</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227165057177.png" alt="image-20241227165057177"></p></li><li><p>部署并开启自动续费和证书更新，acme.sh内部会开启对应crontab自动check，证书进入到30天有效期，<a href="http://acme.sh" target="_blank" rel="noopener">acme.sh</a> 会自动完成续期。</p><p><strong>Apache example</strong></p><pre class="highlight"><code class="bash">acme.sh --install-cert -d /root/.acme.sh/pen.okeeper.com/ \--cert-file      /path/to/certfile/in/apache/cert.pem  \--key-file       /path/to/keyfile/in/apache/key.pem  \--fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \--reloadcmd     <span class="hljs-string">&quot;service apache2 force-reload&quot;</span> </code></pre><p><strong>Nginx example</strong></p><pre class="highlight"><code class="bash">acme.sh --install-cert -d example.com \--key-file       /path/to/keyfile/in/nginx/key.pem  \--fullchain-file /path/to/fullchain/nginx/cert.pem \--reloadcmd     <span class="hljs-string">&quot;service nginx force-reload&quot;</span></code></pre><p>上述命令中：</p><p>​•--key-file 指定私钥的保存路径。</p><p>​•--fullchain-file 指定完整证书链的保存路径（包括服务器证书和中间证书）。</p><p>​•--reloadcmd 用于指定证书更新后需要执行的命令，例如重新加载 Nginx 配置。</p></li><li><p>到此整个过程就完成了，最后介绍一种为了取巧将步骤6和7合并的一种命令，如下</p><pre class="highlight"><code class>acme.sh --issue -d pen.okeeper.com -d a2v.okeeper.com -d model-bridge.okeeper.com --dns dns_dp --server https://acme.freessl.cn/v2/DV90/directory/xxxxxxxxxxxxx \--key-file       /data/nginx/cert/key.pem  \--fullchain-file /data/nginx/cert/cert.pem \--reloadcmd     &quot;docker restart my-nginx&quot;</code></pre><p>此命令可以直接在服务器端生成对应的证书，并安装到指定的文件目录中，便于后续的nginx.conf的配置</p><pre class="highlight"><code class="sh">http {    <span class="hljs-comment"># 配置 SSL</span>    ssl_certificate /etc/nginx/cert/cert.pem;    ssl_certificate_key /etc/nginx/cert/key.pem;<span class="hljs-comment">#    ssl_protocols TLSv1.2 TLSv1.3;</span><span class="hljs-comment">#    ssl_ciphers HIGH:!aNULL:!MD5;</span><span class="hljs-comment">#    ssl_prefer_server_ciphers on;</span>}</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> ssl </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/xue-xi/mao-xuan-du-hou-gan/"/>
      <url>/xue-xi/mao-xuan-du-hou-gan/</url>
      
        <content type="html"><![CDATA[<h1 id="矛盾论"><a class="markdownIt-Anchor" href="#矛盾论"></a> 矛盾论</h1><p>任何事物都是矛盾的对立统一，是矛与盾达到相对平衡的结果，矛盾几相互斗争又相互依存，并在一定条件下还能相互转化。</p><p>矛盾是推动事物发展变化的内在动力。</p><p>这种思想具有物理的客观事实规律，又有更加深刻的哲学思考。</p><p>生与死、没有生就无所谓死。</p><p>没有悲就不会有所谓的欢乐。</p><p>白天与黑夜，如果地球生来就永远是白天，就感觉不到黑夜是什么东西。</p><p>而这些即相互依存，在特点条件又会相互转化</p><p>这种思想又和道家的阴阳调和、道法自然的思想又不谋而合，一切都是对立后统一的结果。</p><p>正因为这种思想，毛泽东主张”矫枉必须过正“，不过正何以知道矫正方向对不对，会暴露出什么问题。</p><p>也有了</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>利用Cursor开发智能剪辑工具</title>
      <link href="/ren-gong-zhi-neng/ru-he-li-yong-cousor-zai-yi-tian-nei-xie-chu-yi-ge-zhi-neng-jian-ji-ruan-jian/"/>
      <url>/ren-gong-zhi-neng/ru-he-li-yong-cousor-zai-yi-tian-nei-xie-chu-yi-ge-zhi-neng-jian-ji-ruan-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="想法"><a class="markdownIt-Anchor" href="#想法"></a> 想法</h1><p>作为一个主要工作语言为Java的软件工程师，如果要实现一个前后端全栈的一个应用是个不小的挑战，不仅要知道前端前端开发技术栈，例如Vue 3、TypeScript、Vite，css，你还得知道一些想实现的样式和效果该如何实现，用什么实现，我一般认为这个过程就像绣花，要不断地调整细节，像素、字体大小、配色。而这一切工作，要是能够通过我的描述直接生成代码就好了，且是可运行的代码，也就是说我可以零基础（少量基础）即可实现我想要的前段效果。</p><p>直到看到Cursor的出现，我感觉程序员越来越廉价的过程会越来越快，直到你没有比这种“工具”更具价值的时候，就应该被淘汰了。但我们都是时代的尘埃，无法改变就去使用它、适应它最后驾驭它。</p><p>我的实际需求是：</p><pre class="highlight"><code class>希望有一个通过一个音频或者视频的url生成一个带字幕且根据字幕内容自动配图的成品视频。</code></pre><h1 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h1><p>这么一个需求，很显然使用python语言能够很好地实现。接下来我将全程用Cursor进行代码开发，主打就是一个偷懒。</p><p>首先，新建一个应用目录<code>audio-to-video-demo</code>, 然后进入根目录<code>Ctrl + I</code> 发起Composer界面，使用聊天的交互方式，把代码给开发了。至于发文技巧，就按你的语言习惯把事情说清楚就行，说的细节越多它实现的就越接近你的想法，一次描述不清楚继续让他修改即可，直到可以正常运行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152559794.png" alt="image-20241125152559794"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152635488.png" alt="image-20241125152635488"></p><p>![image-20241125152802302](<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152802302.png" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152802302.png</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152827067.png" alt="image-20241125152827067"></p><p>如此反复，直到整个代码达到你的要求，就这样经历了十几轮的对话聊天，后端代码终于生成好了。感兴趣的可以查看github地址：</p><p>接下来是前端部分：</p><p>目录初始化</p><pre class="highlight"><code class>npm create vue@latest audio-to-video在创建过程中选择以下选项：TypeScript: YesJSX: NoVue Router: YesPinia: YesESLint: YesPrettier: Yes</code></pre><p>进入<code>audio-to-video</code></p><pre class="highlight"><code class>cd  audio-to-video</code></pre><p>初始化好的目录结构：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125160507661.png" alt="image-20241125160507661"></p><p>接下来告诉它需求。你可以一次性描述详细一点，也可以一步一步来慢慢迭代，我这里为了快速生成，我尽可能在一开始就描述好</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162845000.png" alt="image-20241125162845000"></p><p>![image-20241125162832255](<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162832255.png" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162832255.png</a></p><p>当实现差不多了，我们运行下看下效果，发现报错：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125175425101.png" alt="image-20241125175425101"></p><p>直接选中“Add to Composer”说报错，它就会吭哧吭哧给你修复了</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162911823.png" alt="image-20241125162911823"></p><p>当整个项目可以运行时,<code>npm run dev</code></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162928195.png" alt="image-20241125162928195"></p><h1 id="最后的效果"><a class="markdownIt-Anchor" href="#最后的效果"></a> 最后的效果</h1><p>最终效果是这样：</p><p>第一步：输入B站网页地址：<a href="https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180640719.png" alt="image-20241125180640719"></p><p>第二步：解析字幕，得到字幕列表</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180732142.png" alt="image-20241125180732142"></p><p>第三步：为字幕进行配图</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180811412.png" alt="image-20241125180811412"></p><p>第四步：剪辑生成最终视频, 等待1分钟左右。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180825708.png" alt="image-20241125180825708"></p><p>最后：生成视频完成，可预览，可下载。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125181004129.png" alt="image-20241125181004129"></p><p>B站网页地址：<a href="https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0</a><br>生成的视频展示：<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_180846_c709e8e2.mp4" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_180846_c709e8e2.mp4</a></p><h2 id="其他视频实例"><a class="markdownIt-Anchor" href="#其他视频实例"></a> 其他视频实例：</h2><p>B站视频：<a href="https://www.bilibili.com/video/BV1VhSXYTEfx/?spm_id_from=333.1391.0.0&amp;vd_source=53691d195cb0699b08237b7e5bdf7c61" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1VhSXYTEfx/?spm_id_from=333.1391.0.0&amp;vd_source=53691d195cb0699b08237b7e5bdf7c61</a></p><p>最终生成视频：<br><a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_194940_cb8554e8.mp4" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_194940_cb8554e8.mp4</a></p><h1 id="最后总结"><a class="markdownIt-Anchor" href="#最后总结"></a> 最后总结</h1><h3 id="耗时"><a class="markdownIt-Anchor" href="#耗时"></a> 耗时</h3><p>前后端开发完总耗时10个小时左右。包括代码生成、调试、前后端联调。期间我是比较happy的，没有苦恼于怎么写代码，如何实现我不知道怎么实现的功能，而是在看效果对不对，如何运行以及如何用文字描述出我的想法和遇到的问题。</p><h3 id="项目源码"><a class="markdownIt-Anchor" href="#项目源码"></a> 项目源码</h3><p>audio-to-video：<a href="https://github.com/okeeper/audio-to-video" target="_blank" rel="noopener">https://github.com/okeeper/audio-to-video</a></p><h3 id="cursor的安装和使用"><a class="markdownIt-Anchor" href="#cursor的安装和使用"></a> Cursor的安装和使用</h3><p>请参考文章：<a href="https://mp.weixin.qq.com/s/ycgMLHMS6UnPBJaL_5K0kA" target="_blank" rel="noopener">Cursor的安装和使用</a></p><h2 id="写在最后"><a class="markdownIt-Anchor" href="#写在最后"></a> 写在最后</h2><p>最后，我想说的是，从有这个想法，到最终代码实现，我只花了一天的事件，期间我甚至一行代码都可以不用写，全靠人话说，要生成什么文件、生么代码、什么目录、出错了改哪里你都可以不用知道，你只需把代码当成一个黑盒，你需要做的就是看它实现的最终效果和你的预期差距多大，并不断对话，描述清除你要的东西。</p><p>自从ChatGPT问世以来，让我们看到人工智能的巨大潜力，以前举得是开玩笑的场景，现在它就呈现在你面前，而我们都是时代的随从，无法改变时代，时代就来改变你，当下唯一要做的就是认识他、使用它、驾驭它，未来我认为人工智能不会完全替代所有人类，但一定会从某些方面替代那些不需要太多创造力的劳动。</p><p>人工智能不管怎么发展，它很难有情感、且没有生命延续，就注定和人类不是在一个维度，人的创造力、情感或许是未来人类的唯一价值。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cursor </tag>
            
            <tag> AI </tag>
            
            <tag> 开发工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>亲测有效！前端小白的我0.5天内用Cursor开发出微信小程序</title>
      <link href="/ruan-jian-bi-ji/qin-ce-you-xiao-qian-duan-xiao-bai-de-wo-0.5-tian-nei-yong-cursor-kai-fa-chu-wei-xin-xiao-cheng-xu/"/>
      <url>/ruan-jian-bi-ji/qin-ce-you-xiao-qian-duan-xiao-bai-de-wo-0.5-tian-nei-yong-cursor-kai-fa-chu-wei-xin-xiao-cheng-xu/</url>
      
        <content type="html"><![CDATA[<h1 id="突发奇想"><a class="markdownIt-Anchor" href="#突发奇想"></a> 突发奇想</h1><p>有过小孩的都知道，4、5岁正是他最喜欢问为什么的年纪？脑子里对任何事情都好奇，都想问个明白。可是这就要求我们家长要当一个移动的百科全书，这对我来说可太难了，于是灵感一动要是有这么一个软件，能够在我不认识某些事物时能够照相机拍一拍就出来百科结果就太好了。</p><p>市面上找了一圈，确实有很多这种软件，但是有的要么收费、要么识别植物、要么还要下载软件。这可太麻烦了，身为程序员的我想这有什么难得，我自己开发一个。</p><p>可是我是后端开发工程师，对于前端可不擅长。不过现在是AI时代，什么事情是AI做不了的呢。</p><p>说干就干，首先打开Cursor,同时打开微信开发中工具（因为要预览效果）</p><p>目标有了，直接告诉Cursor让它帮我实现。需求如下：</p><pre class="highlight"><code class># 需求介绍帮我新建一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用后台API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。 2. 识别过程中有一个中间页面，用于等待后台接口结果返回，内容是一个图片预览窗口，有富有科技感的逐帧扫描的动画效果3. 如果识别成功后，显示识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。4. 如果后台接口返回识别失败或者超时，跳转到一个识别失败页，友好地提示可重试或者返回首页</code></pre><p>它视乎听懂了我的需求，不过可能由于Cursor是外国人训练的，对国内微信小程序的开发目录结构可能认识不够，生成的目录结构貌似有点问题，如下所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108173140040.png" alt="image-20241108173140040"></p><p>没关系，Cursor不知道我就告诉它，可是我好像也不知道，毕竟我是小白，那腾讯自家的<strong>元宝</strong>肯定知道</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108170725270.png" alt="image-20241108170725270"></p><p>目录结构有了，我们优化下我们的需求，重来一下</p><pre class="highlight"><code class># 需求介绍帮我新建一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用后台API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。 2. 识别过程中有一个中间页面，用于等待后台接口结果返回，内容是一个图片预览窗口，有富有科技感的逐帧扫描的动画效果3. 如果识别成功后，显示识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。4. 如果后台接口返回识别失败或者超时，跳转到一个识别失败页，友好地提示可重试或者返回首页# 技术栈1. typescript2. 微信小程序3. 百度AI# 项目结构```docs/                     # 文档目录,样例图片等miniprogram/├── app.json              # 小程序公共设置├── app.wxss              # 小程序公共样式表├── app.ts                # 小程序逻辑层入口文件（TypeScript版本）├── pages/                # 页面文件夹│   ├── index/            # 首页│   │   ├── index.json    # 页面配置文件│   │   ├── index.wxml    # 页面结构层文件│   │   └── index.wxss    # 页面样式表文件│   │   └── index.ts      # 页面逻辑层文件（TypeScript版本）│   ├── logs/              # 日志页面│   │   ├── logs.json     # 页面配置文件│   │   ├── logs.wxml     # 页面结构层文件│   │   └── logs.wxss     # 页面样式表文件│   │   └── logs.ts       # 页面逻辑层文件（TypeScript版本）│   └── ...                # 其他页面├── utils/                 # 工具函数文件夹│   ├── util.ts           # 工具函数（TypeScript版本）│   └── ...                # 其他工具函数├── components/            # 自定义组件文件夹│   ├── my-component/      # 自定义组件│   │   ├── my-component.json│   │   ├── my-component.wxml│   │   ├── my-component.ts # 自定义组件逻辑层文件（TypeScript版本）│   │   └── my-component.wxss # 自定义组件样式表文件│   └── ...                # 其他自定义组件├── typings/                 # 类型定义文件夹│   ├── index.d.ts         # 全局类型定义│   └── types                # 其他类型定义├── project.config.json    # 项目配置文件├── tsconfig.json          # TypeScript配置文件└── package.json           # 项目依赖和脚本配置```</code></pre><pre class="highlight"><code class># 需求介绍这是一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用百度AI的API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。参考图片 @1.PNG 2. 识别成功后，显示识别结果，参考图片 @2.PNG，这是对“绿萝”植物的识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。有点击查看详情的按钮。3. 点击查看详情按钮后，跳转到一个新的页面，显示植物的详细信息，参考图片 @3.PNG，包括植物的名称、描述、科属、图片、与之相关的诗、趣事、寓意、传说等。数据内容可以来源于百科。4. 点击返回按钮后，返回到首页。</code></pre><p>第一步：小程序的目录结构长什么样呢？找到腾讯自家的<strong>元宝</strong>，它自家的东西它肯定最清除</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108170725270.png" alt="image-20241108170725270"></p><p>第二步：有了目录结构的介绍，加上我的需求描述，这下Cursor应该能知道我要干嘛了</p><pre class="highlight"><code class># 需求介绍这是一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用百度AI的API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。参考图片 @1.PNG 2. 识别成功后，显示识别结果，参考图片 @2.PNG，这是对“绿萝”植物的识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。有点击查看详情的按钮。3. 点击查看详情按钮后，跳转到一个新的页面，显示植物的详细信息，参考图片 @3.PNG，包括植物的名称、描述、科属、图片、与之相关的诗、趣事、寓意、传说等。数据内容可以来源于百科。4. 点击返回按钮后，返回到首页。# 技术栈1. typescript2. 微信小程序3. 百度AI# 项目结构```docs/                     # 文档目录,样例图片等miniprogram/├── app.json              # 小程序公共设置├── app.wxss              # 小程序公共样式表├── app.ts                # 小程序逻辑层入口文件（TypeScript版本）├── pages/                # 页面文件夹│   ├── index/            # 首页│   │   ├── index.json    # 页面配置文件│   │   ├── index.wxml    # 页面结构层文件│   │   └── index.wxss    # 页面样式表文件│   │   └── index.ts      # 页面逻辑层文件（TypeScript版本）│   ├── logs/              # 日志页面│   │   ├── logs.json     # 页面配置文件│   │   ├── logs.wxml     # 页面结构层文件│   │   └── logs.wxss     # 页面样式表文件│   │   └── logs.ts       # 页面逻辑层文件（TypeScript版本）│   └── ...                # 其他页面├── utils/                 # 工具函数文件夹│   ├── util.ts           # 工具函数（TypeScript版本）│   └── ...                # 其他工具函数├── components/            # 自定义组件文件夹│   ├── my-component/      # 自定义组件│   │   ├── my-component.json│   │   ├── my-component.wxml│   │   ├── my-component.ts # 自定义组件逻辑层文件（TypeScript版本）│   │   └── my-component.wxss # 自定义组件样式表文件│   └── ...                # 其他自定义组件├── typings/                 # 类型定义文件夹│   ├── index.d.ts         # 全局类型定义│   └── types                # 其他类型定义├── project.config.json    # 项目配置文件├── tsconfig.json          # TypeScript配置文件└── package.json           # 项目依赖和脚本配置```</code></pre><p>找到aliyun的百炼大模型平台，里面有个多模态视觉模型，正合我意</p><p>于是找到官网</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108165745146.png" alt="image-20241108165745146"></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> Cursor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenAI推出O1模型：引领AI模型新时代的力量</title>
      <link href="/ren-gong-zhi-neng/openai-de-o1-mo-xing/"/>
      <url>/ren-gong-zhi-neng/openai-de-o1-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="openai-o1模型技术巅峰与国内访问的解决方案"><a class="markdownIt-Anchor" href="#openai-o1模型技术巅峰与国内访问的解决方案"></a> OpenAI O1模型：技术巅峰与国内访问的解决方案</h1><p>2024年9月13日，OpenAI发布了其最新的人工智能模型o1，这款被称为“草莓”的模型一经问世便引发了业界的广泛关注。o1模型在推理能力上取得了重大突破，标志着OpenAI在大模型领域的持续领先地位。o1通过强化学习训练来执行复杂推理任务，与之前的模型相比，它在回答问题前会经历一个较长的“思考”过程，从而提高了回答的准确性和可靠性。</p><p>AIME 2024，一个高水平的数学竞赛，GPT4o准确率为13.4%，而这次的o1 预览版，是56.7%，还未发布的o1正式版，是83.3%。</p><p>代码竞赛，GPT4o准确率为11.0%，o1 预览版为62%，o1正式版，是89%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640.png" alt></p><p>而最牛逼的博士级科学问题 (GPQA Diamond)，GPT4o是56.1，人类专家水平是69.7，o1达到了恐怖的78%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20241004002902853.png" alt="图片"></p><p>什么叫全面碾压，这就是。</p><p>特别是在测试测试化学、物理和生物学专业知识的基准GPQA-diamond上，o1 的表现全面超过了人类博士专家，这也是有史以来，第一个获得此成就的模型。</p><h2 id="国内无法使用"><a class="markdownIt-Anchor" href="#国内无法使用"></a> 国内无法使用</h2><p>然而，尽管o1模型展现了前所未有的强大功能，但国内用户却面临着一个严峻的挑战——OpenAI API服务对中国内地和中国香港地区的开发者进行了屏蔽。这意味着，即便o1模型再优秀，国内的开发者也无法直接享受到这项技术带来的便利。</p><p>这一决定背后的原因复杂多样，但从结果上看，它确实在一定程度上阻碍了国内开发者与全球最先进技术接轨的步伐。尤其是在人工智能快速发展的当下，失去这样一个重要的技术参考和学习机会，无疑是对国内AI生态的一种损失。</p><h2 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h2><p>面对这样的局面，许多国内开发者不得不寻找替代方案。幸运的是，一些创新型平台应运而生，它们不仅填补了技术空白，还为国内用户提供了接触前沿技术的渠道。其中，ModelBridge就是一个典型的例子。作为一个支持GPT-3.5、GPT-4、GPT-4o以及百度“千帆”等多种国内外主流大语言模型的代理平台，ModelBridge不仅完全兼容OpenAI API的标准接口，使得调用者可以方便地进行模型切换，而且还为开发者提供了一个跨越地域限制、享受先进技术服务的途径。</p><p>ModelBridge的出现，不仅解决了国内开发者因OpenAI API屏蔽而面临的技术访问难题，更为重要的是，它促进了国内外先进技术的交流与融合。通过这样一个平台，国内开发者不仅能够接触到最新的大模型技术，还可以根据自身需求灵活选择最适合的模型，从而推动国内AI应用的发展。</p><p>ModelBridge官网：<a href="https://model-bridge.okeeper.com" target="_blank" rel="noopener">https://model-bridge.okeeper.com</a>  注册即可免费体验！！！</p><h2 id="结语"><a class="markdownIt-Anchor" href="#结语"></a> 结语</h2><p>技术的进步永无止境，即便面临挑战，总有方法让我们跨越障碍，共享科技发展带来的成果。正如ModelBridge所做的那样，它不仅是一座连接国内外优秀资源的桥梁，更是每一位追求卓越的技术爱好者实现梦想的助力者。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> OpenAI </tag>
            
            <tag> Baidu </tag>
            
            <tag> API 代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无OpenAI API KEY? 试试这个 - ModelBridge(魔桥)</title>
      <link href="/ren-gong-zhi-neng/modelbridge-jie-shao/"/>
      <url>/ren-gong-zhi-neng/modelbridge-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="国内无法访问openai-api-试试这个-modelbridge魔桥"><a class="markdownIt-Anchor" href="#国内无法访问openai-api-试试这个-modelbridge魔桥"></a> 国内无法访问OpenAI API? 试试这个 - ModelBridge(魔桥)</h1><blockquote><p>凌晨，OpenAI突然发出一封告知信：</p><p>不支持国家地区将会被停止使用OpenAI的API，7月9日起执行。想要继续使用的话，可以联系支持国家地区的有关服务。</p></blockquote><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/d9c9f7c80c2896bfd619750e60ad2ee9e8b597.jpg" alt="图片"></p><blockquote><p>原文对此表示的很明显：</p><p>自7月9日起，OpenAI将开始阻止来自非支持国家和地区的API流量。</p><p>受影响组织若希望继续使用OpenAl的服务，必须在其支持的国家或地区内访问。</p><p>那么想访问OpenAI的API，该怎么办？即使不封禁，想要获取官方的openai api账号，你需要境外银行卡进行订阅，同时还需要梯子才能访问。不过，今天我要介绍一个不需要任何魔法，免费可用的OpenAI API——<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>。</p></blockquote><h2 id="前言openai-api有什么用"><a class="markdownIt-Anchor" href="#前言openai-api有什么用"></a> 前言：OpenAI API有什么用</h2><p>在介绍ModelBridge之前，我们先来了解下OpenAI API有什么用，可以说OpenAI API的应用场景非常广泛，涵盖了从自然语言处理到图像生成等多个领域。以下是一些具体的应用场景示例：</p><ul><li><strong>自然语言处理和生成</strong>：用于自动撰写文章、生成创意文案、构建聊天机器人、客户服务自动化等。</li><li><strong>内容创建和编辑</strong>：自动生成新闻报道、博客文章、小说等。</li><li><strong>代码辅助和开发</strong>：理解自然语言并生成相应的代码。</li><li><strong>数据分析和理解</strong>：用于会议记录、播客制作等。</li><li><strong>自动化办公任务</strong>：自动写作、自动翻译等。</li><li><strong>教育和培训</strong>：改进教育软件和服务，提供个性化的学习体验。</li><li><strong>娱乐和游戏开发</strong>：开发各种类型的游戏，包括文字游戏、图形游戏等。</li><li><strong>机器人技术</strong>：开发各种类型的机器人，包括家庭机器人、工业机器人等。</li><li><strong>实时语音交互</strong>：用于语音助手、在线教育、游戏等场景。</li></ul><p>市面上可直接使用OpenAI API_KEY应用软件。</p><ul><li><strong>ChatBox:</strong> 一款开源免费的跨平台OpenAI API桌面客户端，支持Windows、macOS和Linux。它允许用户自定义API Key和API Host地址，并在本地保存所有聊天记录，同时管理多个会话和设置不同的Prompt</li><li><strong>OpenCat</strong>:  专为macOS和iOS设计的原生客户端，支持自定义API地址，提供即开即用的体验，无需等待网页加载</li><li><strong>PingPongChat</strong>：一款智能AI客户端，支持iPhone、iPad、Mac等设备，无需注册账号或折腾API即可使用，基于GPT-3.5模型</li><li><strong>ChatGPT-Next-Web</strong>: 一键免费部署你的私人 ChatGPT 网页应用，支持 GPT3, GPT4 &amp; Gemini Pro 模型。可配置自定义的base_url和api key.</li></ul><h2 id="modelbridge是什么"><a class="markdownIt-Anchor" href="#modelbridge是什么"></a> ModelBridge是什么？</h2><p>想象一下，有一个平台，它能够让你轻松访问国内外的主流大语言模型，而且免费体验。这就是ModelBridge——一个国内免费的OpenAI API代理，它让人工智能的魔法触手可及。</p><p>ModelBridge官网：<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241210170317716.png" alt="image-20241210170317716"></p><h3 id="1-标准的openai接口格式"><a class="markdownIt-Anchor" href="#1-标准的openai接口格式"></a> 1. 标准的OpenAI接口格式</h3><p>ModelBridge遵循OpenAI的接口格式，这意味着如果你已经熟悉OpenAI的API，那么ModelBridge对你来说就像是老朋友一样亲切。你可以直接参照OpenAI的接口文档，轻松上手。</p><h3 id="2-一次对接模型任意切换"><a class="markdownIt-Anchor" href="#2-一次对接模型任意切换"></a> 2. 一次对接，模型任意切换</h3><p>ModelBridge的另一个神奇之处在于它的灵活性。你只需要进行一次API对接，就可以在不同的大模型之间自由切换，就像在魔法世界中随意变换魔杖一样简单。</p><h3 id="3-无需魔法免费使用"><a class="markdownIt-Anchor" href="#3-无需魔法免费使用"></a> 3. 无需魔法，免费使用</h3><p>对于国内用户来说，访问某些国外的API可能需要一些“魔法”。但ModelBridge打破了这一限制，让你无需任何特殊配置，就能免费使用这个平台。</p><h3 id="4-支持国内外主流大模型"><a class="markdownIt-Anchor" href="#4-支持国内外主流大模型"></a> 4. 支持国内外主流大模型</h3><p>无论你需要的是百度文心一言、阿里、讯飞、智谱ChatGLM，还是GPT系列等，ModelBridge都能满足你的需求。它就像一个魔法宝库，里面装满了各种强大的模型。</p><h2 id="如何开始使用modelbridge只需两步"><a class="markdownIt-Anchor" href="#如何开始使用modelbridge只需两步"></a> 如何开始使用<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>？只需两步</h2><p>首先，访问<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>的官网进行注册和登录。然后，参照官方文档进行API对接。由于接口请求规范完全和OpenAI一样，你可以直接以OpenAI的接口文档为参考。如果是国内模型，只需要将模型参数<code>model</code>修改为国内的模型名字即可。</p><h3 id="第1步用邮箱登录modelbridge获取api_secret_key"><a class="markdownIt-Anchor" href="#第1步用邮箱登录modelbridge获取api_secret_key"></a> 第1步：用邮箱登录ModelBridge，获取API_SECRET_KEY，</h3><p>注册地址：<a href="https://model-bridge.okeeper.com/home/register" target="_blank" rel="noopener">https://model-bridge.okeeper.com/home/register</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240926155117726.png" alt="image-20240926155117726"></p><h3 id="第2步编写代码-配置的base_url是httpsmodel-bridgeokeepercomv1"><a class="markdownIt-Anchor" href="#第2步编写代码-配置的base_url是httpsmodel-bridgeokeepercomv1"></a> 第2步：编写代码。配置的base_url是：<a href="https://model-bridge.okeeper.com/v1" target="_blank" rel="noopener">https://model-bridge.okeeper.com/v1</a></h3><p>使用openai的sdk(python/java/go)或标准的openai的http接口进行访问，修改base_url为<a href="https://model-bridge.okeeper.com/v1" target="_blank" rel="noopener">https://model-bridge.okeeper.com/v1</a><br>下面是常见客户端访问的代码：</p><h4 id="方式1python中使用openai的官方包新版"><a class="markdownIt-Anchor" href="#方式1python中使用openai的官方包新版"></a> 方式1：python中使用openai的官方包（新版）：</h4><blockquote><p>注意：如果是python，注意openai包的版本要对，它升级了！！<br>要注意，关键是base_url要设置成ModelBridge的，如果这个不正确，其它肯定都不行。<br>所以一定要注意他在不同的包中base_url的设置方式，<br>目前已知的是：在老版本中的设置方式是：openai.api_base = BASE_URL，<br>而在新版本中的设置方式是：client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)，<br>别问为什么，问就是openai的锅</p></blockquote><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os<span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<span class="hljs-keyword">import</span> openai<span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> time<span class="hljs-keyword">import</span> json<span class="hljs-keyword">import</span> timeAPI_SECRET_KEY = <span class="hljs-string">&quot;YOURR_API_SECRECT_KEY&quot;</span>;BASE_URL = <span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1/&quot;</span><span class="hljs-comment"># chat</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions3</span>(<span class="hljs-params">query</span>):    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)    resp = client.chat.completions.create(        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query}        ]    )    <span class="hljs-built_in">print</span>(resp)    <span class="hljs-comment">#print(resp.choices[0].message.content)</span><span class="hljs-comment"># chat with other model</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions4</span>(<span class="hljs-params">query</span>):    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)    resp = client.chat.completions.create(        model=<span class="hljs-string">&quot;deepseek-chat&quot;</span>,        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query}        ]    )    <span class="hljs-built_in">print</span>(resp)    <span class="hljs-comment">#print(resp.choices[0].message.content)</span></code></pre><h4 id="方式2python使用openai的官方包旧版-openai0280及以下"><a class="markdownIt-Anchor" href="#方式2python使用openai的官方包旧版-openai0280及以下"></a> 方式2：python使用openai的官方包（旧版）, <strong>openai=0.28.0</strong>及以下</h4><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> openai <span class="hljs-comment">#openai.api_type = &quot;open_ai&quot;</span>openai.api_key = <span class="hljs-string">&quot;YOURR_API_SECRECT_KEY&quot;</span>openai.api_base = <span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1&quot;</span> <span class="hljs-comment"># 定义对话函数</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">openai_chat</span>(<span class="hljs-params">prompt</span>):    <span class="hljs-comment"># 调用 OpenAI API 进行对话生成</span>    response = openai.ChatCompletion.create(        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<span class="hljs-comment">#目前仅支持gpt-3.5-turbo</span>        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt}        ]    )     <span class="hljs-comment"># 获取生成的回复</span>    reply = response.choices[<span class="hljs-number">0</span>].message.content    <span class="hljs-keyword">return</span> reply <span class="hljs-comment"># 进行对话</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>():    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:        <span class="hljs-comment"># 提示用户输入</span>        user_input = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;用户：&quot;</span>)         <span class="hljs-comment"># 结束对话的条件</span>        <span class="hljs-keyword">if</span> user_input.lower() == <span class="hljs-string">&#x27;bye&#x27;</span>:            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;机器人：再见！&quot;</span>)            <span class="hljs-keyword">break</span>         <span class="hljs-comment"># 调用 OpenAI 进行对话生成</span>        response = openai_chat(user_input)         <span class="hljs-comment"># 打印机器人的回复</span>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;机器人：&quot;</span> + response) <span class="hljs-comment"># 调用对话函数开始对话</span>chat()</code></pre><h4 id="方式3使用http请求"><a class="markdownIt-Anchor" href="#方式3使用http请求"></a> 方式3：使用http请求：</h4><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os<span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> time<span class="hljs-keyword">import</span> json<span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions</span>():    url=<span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1/chat/completions&quot;</span>    api_secret_key = <span class="hljs-string">&#x27;xxxxxxxxx&#x27;</span>;  <span class="hljs-comment"># 你的api_secret_key</span>    headers = {<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>, <span class="hljs-string">&#x27;Accept&#x27;</span>:<span class="hljs-string">&#x27;application/json&#x27;</span>,               <span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">&quot;Bearer &quot;</span>+api_secret_key}    params = {<span class="hljs-string">&#x27;user&#x27;</span>:<span class="hljs-string">&#x27;张三&#x27;</span>,<span class="hljs-string">&#x27;model&#x27;</span>:<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,              <span class="hljs-string">&#x27;messages&#x27;</span>:[{<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>:<span class="hljs-string">&#x27;1+100=&#x27;</span>}]};    r = requests.post(url, json.dumps(params), headers=headers)    <span class="hljs-built_in">print</span>(r)    <span class="hljs-comment">#print(r.json())</span><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    chat_completions();</code></pre><h4 id="方式4使用java客户端chatgpt-java"><a class="markdownIt-Anchor" href="#方式4使用java客户端chatgpt-java"></a> 方式4：使用Java客户端<strong>chatgpt-java</strong></h4><p>客户端Github:<a href="https://github.com/Grt1228/chatgpt-java#1%E5%AF%BC%E5%85%A5pom%E4%BE%9D%E8%B5%96" target="_blank" rel="noopener">https://github.com/Grt1228/chatgpt-java#1%E5%AF%BC%E5%85%A5pom%E4%BE%9D%E8%B5%96</a></p><ul><li>引入第三方java sdk :</li></ul><pre class="highlight"><code class>&lt;dependency&gt;    &lt;groupId&gt;com.unfbx&lt;/groupId&gt;    &lt;artifactId&gt;chatgpt-java&lt;/artifactId&gt;    &lt;version&gt;1.0.14-beta1&lt;/version&gt;&lt;/dependency&gt;</code></pre><ul><li><p>实例代码</p><pre class="highlight"><code class="java"><span class="hljs-keyword">import</span> com.unfbx.chatgpt.OpenAiStreamClient;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.entity.chat.ChatCompletion;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.entity.chat.Message;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.sse.ConsoleEventSourceListener;<span class="hljs-keyword">import</span> org.junit.jupiter.api.Test; <span class="hljs-keyword">import</span> java.util.Arrays;<span class="hljs-keyword">import</span> java.util.concurrent.CountDownLatch; <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ClientTest</span> {     <span class="hljs-meta">@Test</span>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">streamChatCompletion</span><span class="hljs-params">()</span> {        <span class="hljs-type">OpenAiStreamClient</span> <span class="hljs-variable">client</span> <span class="hljs-operator">=</span> OpenAiStreamClient.builder()                .apiKey(Arrays.asList(<span class="hljs-string">&quot;ModelBridege的API_SECRECT_KEY&quot;</span>))                .apiHost(<span class="hljs-string">&quot;https://model-bridge.okeeper.com/&quot;</span>)                .build();                 <span class="hljs-type">ConsoleEventSourceListener</span> <span class="hljs-variable">eventSourceListener</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ConsoleEventSourceListener</span>();        <span class="hljs-type">Message</span> <span class="hljs-variable">message</span> <span class="hljs-operator">=</span> Message.builder().role(Message.Role.USER).content(<span class="hljs-string">&quot;你好啊我的伙伴！&quot;</span>).build();        <span class="hljs-type">ChatCompletion</span> <span class="hljs-variable">chatCompletion</span> <span class="hljs-operator">=</span> ChatCompletion.builder()                <span class="hljs-comment">//.model(ChatCompletion.Model.GPT_3_5_TURBO.getName())</span>                .model(<span class="hljs-string">&quot;gpt-4o&quot;</span>)                .messages(Arrays.asList(message)).build();        client.streamChatCompletion(chatCompletion, eventSourceListener);        <span class="hljs-type">CountDownLatch</span> <span class="hljs-variable">countDownLatch</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CountDownLatch</span>(<span class="hljs-number">1</span>);        <span class="hljs-keyword">try</span> {            countDownLatch.await();        } <span class="hljs-keyword">catch</span>(InterruptedException e) {            e.printStackTrace();        }    }}</code></pre></li></ul><h4 id="方式5使用curl命令访问"><a class="markdownIt-Anchor" href="#方式5使用curl命令访问"></a> 方式5：使用curl命令访问</h4><pre class="highlight"><code class>curl --location --request POST 'https://model-bridge.okeeper.com//v1/chat/completions' \--header 'Authorization: Bearer ModelBridege的API_SECRECT_KEY' \--header 'Content-Type: application/json' \--data-raw '{        &quot;model&quot;: &quot;gpt-4o-mini&quot;,    &quot;stream&quot;: false,    &quot;messages&quot;: [        {            &quot;role&quot;: &quot;user&quot;,            &quot;content&quot;: &quot;你好啊!&quot;        }    ]}'</code></pre>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> OpenAI </tag>
            
            <tag> Baidu </tag>
            
            <tag> API 代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能技术发展史</title>
      <link href="/ren-gong-zhi-neng/2024-ren-gong-zhi-neng-fa-zhan-yu-ce/"/>
      <url>/ren-gong-zhi-neng/2024-ren-gong-zhi-neng-fa-zhan-yu-ce/</url>
      
        <content type="html"><![CDATA[<h1 id="2024年人工智能最新进展全面分析"><a class="markdownIt-Anchor" href="#2024年人工智能最新进展全面分析"></a> 2024年人工智能最新进展全面分析</h1><p>随着科技的不断进步，2024年将迎来人工智能领域的一系列重要突破和趋势。这些进展不仅将改变各行各业的面貌，还将深刻影响我们的日常生活。以下是几大关键趋势和突破性技术的详细剖析。</p><h3 id="生成式ai"><a class="markdownIt-Anchor" href="#生成式ai"></a> 生成式AI</h3><p>生成式AI在2024年将继续快速发展，逐步从炒作走向实际应用。生成式AI技术能够创作文本、图像、音乐等多种形式的内容，这在教育、娱乐、广告等领域有着广泛的应用。未来，我们可能会看到更多的生成式AI驱动的“超级应用”出现，这些应用将使AI能够更智能地辅助完成复杂任务，如自动化编写报告、生成创意广告等。</p><h3 id="多模态ai"><a class="markdownIt-Anchor" href="#多模态ai"></a> 多模态AI</h3><p>AI模型将从单一模式转向多模态，这意味着AI将能够同时处理文本、图像、音频等多种类型的数据。多模态AI的进步将大幅提升机器理解和生成内容的能力，促进医疗、金融、自动驾驶等领域的创新。例如，医疗诊断系统可以结合影像、病历和基因数据提供更准确的诊断和治疗方案。</p><h3 id="ai的民主化"><a class="markdownIt-Anchor" href="#ai的民主化"></a> AI的民主化</h3><p>随着AI技术的普及和易用性提升，AI的民主化趋势愈加明显。更多的中小企业和个人开发者将能够利用AI技术开发创新应用。这一趋势将推动AI技术在各行各业的广泛应用，促进经济增长和社会进步。</p><h3 id="小型化语言模型"><a class="markdownIt-Anchor" href="#小型化语言模型"></a> 小型化语言模型</h3><p>小型化语言模型在性能和资源消耗之间取得了平衡，使得AI能够在资源受限的环境中运行，例如移动设备和物联网设备。这将推动AI技术在日常生活中的应用，如智能家居、智能助手等。</p><h3 id="ai伦理"><a class="markdownIt-Anchor" href="#ai伦理"></a> AI伦理</h3><p>随着AI技术的广泛应用，AI伦理问题也变得越来越重要。2024年，关于数据隐私、算法透明度和公平性的讨论将更加深入。开发者和企业需要制定更严格的伦理规范和法律法规，以确保AI技术的安全和可信。</p><h3 id="人工通用智能agi"><a class="markdownIt-Anchor" href="#人工通用智能agi"></a> 人工通用智能（AGI）</h3><p>虽然AGI仍处于研究阶段，但2024年可能会看到一些重要的理论突破。AGI旨在开发具有广泛认知能力的AI，能够自主学习和解决多领域复杂问题。尽管距离实现AGI还有很长的路要走，但其研究进展将为现有AI技术提供新的思路和方法。</p><h3 id="ai即服务aiaas"><a class="markdownIt-Anchor" href="#ai即服务aiaas"></a> AI即服务（AIaaS）</h3><p>AI即服务（AIaaS）将使企业能够通过云平台方便地获取和使用AI技术。通过AIaaS，企业无需自行开发和维护AI系统，而是可以直接使用由第三方提供的AI解决方案。2024年，AIaaS市场将进一步扩展，更多的企业将受益于这一模式。</p><h3 id="生成式ai内容创建"><a class="markdownIt-Anchor" href="#生成式ai内容创建"></a> 生成式AI内容创建</h3><p>生成式AI在内容创建领域的应用将更加广泛和深入。例如，自动生成新闻报道、小说、音乐、视频等内容。通过生成式AI，内容创作者可以大幅提升创作效率，探索新的创意形式。与此同时，生成式AI也将面临版权和道德方面的挑战，需要在技术和法律层面加以规范。</p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>2024年，人工智能技术将继续推进，多个领域的应用将更加成熟和普及。生成式AI、多模态AI、AI的民主化、小型化语言模型和AI伦理等关键趋势将推动AI技术在各行各业的深度融合。同时，人工通用智能、AI即服务和生成式AI内容创建等突破性技术将为未来带来更多可能性。我们期待在新的一年中，人工智能能够为社会带来更多价值和创新。</p><p>这篇文章旨在为精通技术的读者提供关于2024年人工智能最新进展的全面洞察，帮助他们理解这些技术趋势的具体应用和潜在影响。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 大语言模型 </tag>
            
            <tag> LLM </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>存储引擎RocksDB工作原理</title>
      <link href="/hou-duan-jia-gou/cun-chu-yin-qing-rocksdb-gong-zuo-yuan-li/"/>
      <url>/hou-duan-jia-gou/cun-chu-yin-qing-rocksdb-gong-zuo-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="rocksdb简介"><a class="markdownIt-Anchor" href="#rocksdb简介"></a> RocksDB简介</h2><p>RocksDB是一个高性能读写、可扩展、嵌入式、持久化、可靠、易用及可定制的键值数据库。内部采用LSM-Tree数据，支持高吞吐的写入和快速的范围查找。</p><p>RocksDB是一种嵌入式数据库，2012年基于谷歌的LevelDB分叉而来，最初由Dhruba Borthakur在Facebook创建，目的是提高服务器工作负载性能。目前，RocksDB由Meta开发和维护。</p><p>使用RocksDB存储引擎的分布式数据库有许多，其中一些比较著名的包括：</p><p>​1.<strong>TiDB</strong>：TiDB 是一款开源的分布式关系型数据库，兼容 MySQL 协议。它将 RocksDB 用作底层存储引擎，并通过 Raft 协议实现高可用和分布式一致性。</p><p>​2.<strong>CockroachDB</strong>：CockroachDB 是一个分布式 SQL 数据库，支持水平扩展和强一致性。它使用 RocksDB 作为存储引擎来管理数据的持久化。</p><p>​3.<strong>YugabyteDB</strong>：YugabyteDB 是一个开源的高性能分布式 SQL 数据库，支持 PostgreSQL 和 Cassandra 的接口。它采用 RocksDB 作为存储引擎，提供强一致性和线性扩展能力。</p><p>​4.<strong>ScyllaDB</strong>：ScyllaDB 是一个高性能的 NoSQL 数据库，兼容 Apache Cassandra。它在某些场景下也可以选择使用 RocksDB 作为存储引擎，以提升性能。</p><p>​5.<strong>MyRocks</strong>：MyRocks 是基于 MySQL 的一个分支实现，直接使用 RocksDB替换InnoDB存储引擎 来提高写入性能和压缩比。这使得 MyRocks 成为一个支持高吞吐量和低延迟的存储解决方案。</p><h2 id="rocksdb有几个特点"><a class="markdownIt-Anchor" href="#rocksdb有几个特点"></a> RocksDB有几个特点：</h2><ol><li>嵌入式数据库，所谓嵌入式即它没有独立的进程，而是集成到应用中和应用共享内存资源</li><li>它没有内置服务器，无法通过网络进行远程访问</li><li>它不是分布式的，它不提供分区容错性、高可用及分片机制</li><li>RocksDB是以Key-Value形式存储数据，Key、value都是人异常度的字节数组(Byte array),因此他没有数据类型</li><li>适合写大于读的场景，支持大量数据存储，写更快、存储空间占用更小（紧凑存储）</li></ol><h2 id="如何才能进行硬件的快速读写"><a class="markdownIt-Anchor" href="#如何才能进行硬件的快速读写"></a> 如何才能进行硬件的快速读写</h2><p>快速读写硬件的性能主要取决于如何有效利用内存和磁盘的 I/O 特性。</p><p><strong>磁盘在随机IO和顺序IO之间的差异</strong>：</p><p>​•随机 I/O：HDD 通过磁头读取数据，随机访问需要磁头移动和盘片旋转，导致较高的寻道时间和旋转延迟。</p><p>​•顺序 I/O：顺序访问数据时，磁头只需很少的移动或不移动，数据连续读取，减少了寻道时间和旋转延迟，性能明显提高。</p><h3 id="innodb-的写入机制"><a class="markdownIt-Anchor" href="#innodb-的写入机制"></a> InnoDB 的写入机制</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/watermark%2Ctype_ZHJvaWRzYW5zZmFsbGJhY2s%2Cshadow_50%2Ctext_Q1NETiBAbHZxaW5nbG91%2Csize_20%2Ccolor_FFFFFF%2Ct_70%2Cg_se%2Cx_16.png" alt="img"></p><p>如图所示：</p><ol><li>第一步：在内存中新增undolog用于MVCC(多版本事务控制)，方便事务的后续回滚，如果执行失败或事物提交会标记为待删除。</li><li>第二部：在buffer pool缓冲池中找到要修改的行所在页(MySQL中数据操作最小单位)，如果找不到会报缺页，等待从磁盘中进行加载</li><li>第三部：顺序写入Redo log buffer,会按照策略进行同步或者异步镜像系统刷盘</li><li>Checkpoint: 后台异步线程会定时或者达到刷盘条件时，触发Double writer机制，保证异步离散写的数据一致性(mysql 16K的页对应系统4个4K的页)</li></ol><p>从上面第二部可以看出，Mysql其实是原地写，即要找到原来的记录进行修改，如果缓存池中频繁报缺页，写入性能势必会收到影响</p><p><strong>接下来我们看看RocksDB它是如何做的？它是如何利用磁盘的顺序写同时还保证了写的性能的</strong></p><h2 id="lsm-treelog-structure-merge-tree"><a class="markdownIt-Anchor" href="#lsm-treelog-structure-merge-tree"></a> LSM-Tree（Log Structure Merge tree）</h2><p>RocksDB采用的是LSM树（Log-Structure merge Tree）的数据结构, 它是将所有的数据修改(增删改)都记录内存的顺序memtable和磁盘顺序的日志文件中(Write-Ahead Log,WAL)中，在由异步“Flush”流程，将内存的memtable慢慢归并成L0、L1、12…Ln的磁盘文件中。如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-qjpy-20240720190601835.png" alt></p><p>LSM-Tree 的顶层保存在内存中，包含最近插入的数据。较低层存储在磁盘上，编号从 0 到 N。0 级 (L0) 存储从内存移动到磁盘的数据，1 级及以下存储较旧的数据。当某个层变得太大时，它会与下一个层合并，而下一个层通常比前一个层大一个数量级。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-lsm.png" alt="img"></p><p>为了更好地理解 LSM 树的工作原理，让我们仔细看看写入数据的过程。</p><h2 id="写入数据"><a class="markdownIt-Anchor" href="#写入数据"></a> 写入数据</h2><h3 id="预写日志"><a class="markdownIt-Anchor" href="#预写日志"></a> 预写日志</h3><p>无论是在进程意外崩溃退出还是计划内重启时，其内存中的数据都会丢失。为了防止数据丢失，保证数据的持久化，除了 MemTable 之外，RocksDB 会将所有更新写入到磁盘上的预写日志（WAL，Write-ahead log）中。这样，在重启后，数据库可以回放日志，进而恢复 MemTable 的原始状态。</p><p>WAL 是一个只允许追加的文件，包含一组更改记录序列。每个记录包含键值对、记录类型（Put / Merge / Delete）和校验和（checksum）。与 MemTable 不同，在 WAL 中，记录不按 key 有序，而是按照请求到来的顺序被追加到 WAL 中。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-wal.png" alt="img"></p><h3 id="memtable"><a class="markdownIt-Anchor" href="#memtable"></a> Memtable</h3><p>RocksDB会将内存划分为大小相近的memtable进行存储对对数据的增删改查操作，通常在memtable内部是一个SkipList结构，按Key顺序记录了当前key在当前这个memtable中最新的操作记录。当memtable满了时，会将当前active memtable改成immutable memtable（不可变的memtable），并同时生成一个新的active memtable供后续的写操作使用。</p><p><em>内存表的默认大小为 64MB。</em></p><p>例如添加以下键值</p><pre class="highlight"><code class>db.put(&quot;chipmunk&quot;, &quot;1&quot;)db.put(&quot;cat&quot;, &quot;2&quot;)db.put(&quot;raccoon&quot;, &quot;3&quot;)db.put(&quot;dog&quot;, &quot;4&quot;)</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-memtable.png" alt="img"></p><p>我们看到，尽管<code>chipmunk</code>是第一个插入的，但在MemTable中仍然排在<code>cat</code>之后，因为他是按key的顺序排序的，顺序排序的好处可以加快我们的检索效率(如用二分法、跳表、红黑树)</p><h3 id="flush"><a class="markdownIt-Anchor" href="#flush"></a> <strong>Flush</strong></h3><p>RocksDB 使用一个专门的后台线程定期地把不可变的 MemTable 从内存持久化到磁盘。一旦刷盘（flush）完成，不可变的 MemTable 和相应的 WAL 就会被丢弃。RocksDB 开始写入新的 WAL、MemTable。每次刷盘都会在 L0 层上产生一个新的 SST 文件。该文件一旦写入磁盘后，就不再会修改。</p><p>RocksDB 的 MemTable 的默认基于跳表实现。该数据结构是一个具有额外采样层的链表，从而允许快速、有序地查询和插入数据。有序性使得 MemTable 刷盘时更高效，因为可以直接按顺序迭代键值对顺序写入磁盘。<strong>将随机写变为顺序写是 LSM-Tree 的核心设计之一</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-flush.png" alt="img"></p><h3 id="sstablesorted-string-table"><a class="markdownIt-Anchor" href="#sstablesorted-string-table"></a> SSTable(Sorted String Table)</h3><p>SST 文件包括从 MemTable 刷盘而来的键值对，并且使用一种对查询友好的数据格式来存储。SST 是 Static Sorted Table 的缩写（其他数据库中也称为 Sorted String Table）。它是一种基于块（ block） 的文件格式，会将数据切成固定大小的块（默认为 4KB）进行存储。RocksDB 支持各种压缩 SST 文件的压缩算法，例如 Zlib、BZ2、Snappy、LZ4 或 ZSTD 算法。与 WAL 的记录类似，每个数据块中都包含用于检测数据是否损坏的校验和。每次从磁盘读取数据时，RocksDB 都会使用这些校验和进行校验。</p><p>SST 文件由几个部分组成：首先是数据部分，包含一系列有序的键值对。key 的有序性可以让我们对 其进行增量编码，也即，对于相邻的 key ，我们可以只存其差值而非整个 key。</p><p>尽管 SST 中的 kv 对是有序的，我们也并非总能进行二分查找，尤其是数据块在压缩过后，会使得查找很低效。RocksDB 使用索引来优化查询，存储在紧邻数据块之后的索引块。Index 会把每个 block 数据中最后一个 key 映射到它在磁盘上的对应偏移量。同样地，index 中的 key 也是有序的，因此我们可以通过二分搜索快速找到某个 key。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-sst.png" alt="img"></p><h3 id="compaction压缩"><a class="markdownIt-Anchor" href="#compaction压缩"></a> Compaction（压缩）</h3><p>到现在为止，一个功能完备的键值存储引擎讲完了。但如果这样直接上生产环境，会有一些问题：空间放大（space amplifications）和读放大（read amplifications）。空间放大是存储数据所用实际空间与逻辑上数据大小的比值。假设一个数据库需要 2 MB 磁盘空间来存储逻辑上的 1 MB 大小的键值对是，那么它的空间放大率是 2。类似地，读放大用来衡量用户执行一次逻辑上的读操作，系统内所需进行的实际 IO 次数。作为一个小练习，你可以尝试推演下什么是写放大。</p><p>现在，让我们向数据库添加更多 key 并删除当中的一些 key：</p><pre class="highlight"><code class>db.delete(&quot;chipmunk&quot;)db.put(&quot;cat&quot;, &quot;5&quot;)db.put(&quot;raccoon&quot;, &quot;6&quot;)db.put(&quot;zebra&quot;, &quot;7&quot;)// Flush triggersdb.delete(&quot;raccoon&quot;)db.put(&quot;cat&quot;, &quot;8&quot;)db.put(&quot;zebra&quot;, &quot;9&quot;)db.put(&quot;duck&quot;, &quot;10&quot;)</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction1.png" alt="img"></p><p>随着我们的不断写入，MemTable 不断被刷到磁盘，L0 上的 SST 文件数量也在增长：</p><ul><li>删除或更新 key 所占用的空间永远不会被回收。例如，<code>cat</code> 这个 key 的三次更新记录分别在 SST1，SST2 和 SST3 中，而 <code>chipmunk</code> 在 SST1 中有一次更新记录，在 SST2 中有一次删除记录，这些无用的记录仍然占用额外磁盘空间。</li><li>随着 L0 上 SST 文件数量的增加，读取变得越来越慢。每次查找都要逐个检查所有 SST 文件。</li></ul><p>RocksDB 引入了压实（ Compaction ）机制，可以降低空间放大和读放大，但代价是更高的写放大。Compaction 会将某层的 SST 文件同下一层的 SST 文件合并，并在这个过程中丢弃已删除和被覆盖的无效 key。Compaction 会在后台专用的线程池中运行，从而保证了 RocksDB 可以在做 Compaction 时能够正常处理用户的读写请求。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction2.png" alt="img"></p><p>Leveled Compaction 是 RocksDB 中的默认 Compaction 策略。使用 Leveled Compaction，L0 层中的不同 SST 文件键范围会重叠。L1 层及以下层会被组织为包含多个 SST 文件的序列，并保证同层级内的所有 SST 在键范围上没有交叠，且 SST 文件之间有序。Compaction 时，会选择性地将某层的 SST 文件与下一层的 key 范围有重叠 SST 文件进行合并。</p><p>举例来说，如下图所示，在 L0 到 L1 层进行 Compaction 时，如果 L0 上的输入文件覆盖整个键范围，此时就需要对所有 L0 和 L1 层的文件进行 Compaction。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction3.png" alt="img"></p><p>而像是下面的这种 L1 和 L2 层的 Compaction，L1 层的输入文件只与 L2 层的两个 SST 文件重叠，因此，只需要对部分文件进行 Compaction 即可。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction4.png" alt="img"></p><p>当 L0 层上的 SST 文件数量达到一定阈值（默认为 4）时，将触发 Compaction。对于 L1 层及以下层级，当整个层级的 SST 文件总大小超过配置的目标大小时，会触发 Compaction 。当这种情况发生时，可能会触发 L1 到 L2 层的 Compaction。从而，从 L0 到 L1 层的 Compaction 可能会引发一直到最底层级联 Compaction。在 Compaction 完成之后，RocksDB 会更新元数据并从磁盘中删除 已经被 Compcated 过的文件。</p><p><em>注：RocksDB 提供了不同 Compaction 策略来在空间、读放大和写放大之间进行权衡</em>。</p><p>看到这里，你还记得上文提过 SST 文件中的 key 是有序的吗？有序性允许使用 K 路归并算法逐步合并多个 SST 文件。K 路归并是两路归并的泛化版本，其工作方式类似于归并排序的归并阶段。</p><h2 id="读取数据过程"><a class="markdownIt-Anchor" href="#读取数据过程"></a> 读取数据过程</h2><p>使用持久化在磁盘上不可变的 SST 文件，读路径要比写路径简单很多。要找寻某个 key，只需自顶而下遍历 LSM—Tree。从 MemTable 开始，下探到 L0，然后继续向更低层级查找，直到找到该 key 或者检查完所有 SST 文件为止。</p><p>以下是查找步骤：</p><ol><li>检索 MemTable。</li><li>检索不可变 MemTables。</li><li>搜索最近 flush 过的 L0 层中的所有 SST 文件。</li><li>对于 L1 层及以下层级，首先找到可能包含该 key 的单个 SST 文件，然后在文件内进行搜索。</li></ol><p>搜索 SST 文件涉及：</p><ol><li>（可选）探测布隆过滤器。</li><li>查找 index 来找到可能包含这个 key 的 block 所在位置。</li><li>读取 block 文件并尝试在其中找到 key。</li></ol><p>这就是全部所需步骤了！看看这个 LSM-Tree：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-lookup.png" alt="img"></p><p>根据待查找的 key 的具体情况，查找过程可能在上面任意步骤提前终止。例如，在搜索 MemTable 后，key “cat” 或 “chipmunk” 的查找工作会立即结束。查找 “raccoon” 则需要搜索 L1 为止，而查找根本不存在的 “manul” 则需要搜索整个树。</p><h2 id="rocksdb的优缺点"><a class="markdownIt-Anchor" href="#rocksdb的优缺点"></a> RocksDB的优缺点</h2><p>RocksDB是一种高性能的嵌入式键值存储引擎，具有以下优点和缺点：</p><p><strong>优点</strong>：</p><ol><li><p>高性能：RocksDB采用LSM-Tree数据结构，具有高效的写入性能，同时使用Bloom Filter和Block Cache等技术，具有高效的读取性能，可以在高负载和大规模数据情况下保持高性能。</p></li><li><p>灵活性：RocksDB具有丰富的配置选项和插件机制，可以根据不同的应用场景和需求进行灵活的调整和扩展，例如支持不同的压缩算法、过滤器和存储引擎等。</p></li><li><p>可扩展性：RocksDB支持水平扩展和自动容错，可以通过添加新的节点，来提高系统的吞吐量和存储容量。</p></li><li><p>多语言支持：RocksDB支持多种编程语言，包括C++、Java、Python等，可以方便地在不同的应用场景下使用。</p></li><li><p>稳定性：RocksDB是Facebook开发的开源项目，已经经过多年的稳定运行和优化，具有高可靠性和稳定性</p><p><strong>缺点</strong>：</p></li><li><p>内存占用较高：由于RocksDB需要维护多个LSM树，需要占用较多的内存空间，对于内存资源较为紧张的环境可能不太适用。</p></li><li><p>存储空间浪费：RocksDB的LSM-Tree结构需要占用更多的磁盘空间，对于存储资源较为紧张的环境可能造成浪费。</p></li><li><p>部署复杂：RocksDB需要根据实际的应用场景进行配置和调整，需要专业的系统管理员进行管理和维护。</p></li><li><p>写放大问题：RocksDB的LSM-Tree结构可能会造成写放大问题，即需要更多的磁盘I/O来保证数据的一致性和可靠性。</p></li><li><p>不支持分布式事务：RocksDB是一种嵌入式存储引擎，不支持分布式事务，需要借助其他组件（如TiDB）来实现分布式事务。</p></li></ol><h2 id="rocksdb-为什么快"><a class="markdownIt-Anchor" href="#rocksdb-为什么快"></a> <strong>RocksDB 为什么快</strong></h2><p>RocksDB 的高性能源于其 LSM-Tree 架构，同时还有很多技术优化，如高效的写入路径、多级 Compaction 策略、高效的缓存机制、并发优化以及读取优化等，如下：</p><p>​1.<strong>LSM-Tree（Log-Structured Merge-Tree）架构</strong>：</p><p>​•<strong>高效写入</strong>：LSM-Tree 将所有写入操作首先写入内存中的 MemTable，然后顺序写入 WAL（Write-Ahead Log），最后在后台合并到 SSTables（Sorted String Tables）。这种设计避免了随机写入磁盘，提高了写入吞吐量。</p><p>​•<strong>后台合并</strong>：通过后台的 Compaction 过程，将多个 SSTables 合并成更大的 SSTables，进一步优化磁盘 I/O 并减少读放大。</p><p>​2.<strong>多级 Compaction 策略</strong>：</p><p>​•<strong>Level Compaction</strong>：将 SSTables 分层存储，通过逐层合并减少读放大和磁盘空间的浪费。</p><p>​•<strong>Universal Compaction</strong>：适用于需要快速写入的大型数据集，通过更灵活的合并策略进一步优化写性能。</p><p>​3.<strong>高效的缓存机制</strong>：</p><p>​•<strong>Block Cache</strong>：缓存 SSTables 的数据块，减少磁盘读取，提高读性能。</p><p>​•<strong>Table Cache</strong>：缓存 SSTables 的元数据，快速定位数据块，减少不必要的磁盘 I/O。</p><p>​4.<strong>高效的写入路径</strong>：</p><p>​•<strong>WAL（Write-Ahead Log）</strong>：顺序写入日志，确保数据持久性，减少写入延迟。</p><p>​•<strong>MemTable</strong>：内存中的写入缓冲区，快速写入数据，然后批量刷入磁盘。</p><p>​5.<strong>高并发和低延迟</strong>：</p><p>​•<strong>多线程 Compaction</strong>：利用多线程进行后台合并，充分利用多核 CPU，提高并发性。</p><p>​•<strong>Fine-grained Locking</strong>：细粒度锁机制，减少锁争用，提高并发性能。</p><p>​6.<strong>优化的读取路径</strong>：</p><p>​•<strong>Bloom Filters</strong>：使用布隆过滤器快速过滤不存在的键，减少不必要的磁盘 I/O。</p><p>​•<strong>Prefix Seek</strong>：前缀查找优化，快速定位相关键值对。</p><p>通过这些优化，RocksDB 提供了卓越的性能和可靠性，成为许多高性能应用的首选存储引擎。</p><h2 id="适合场景"><a class="markdownIt-Anchor" href="#适合场景"></a> 适合场景</h2><p>​1.<strong>高写入吞吐量的应用</strong>：</p><p>​•由于 LSM-Tree 的架构和高效的写入路径，RocksDB 非常适合需要高写入吞吐量的应用，如日志收集、时间序列数据存储等。</p><p>​2.<strong>低延迟的实时应用</strong>：</p><p>​•RocksDB 的多级缓存和高效的读写路径使其适合低延迟的实时应用，如实时分析、实时消息处理等。</p><p>​3.<strong>高并发访问的应用</strong>：</p><p>​•RocksDB 的细粒度锁机制和多线程 Compaction 支持高并发访问，非常适合高并发的在线服务，如社交媒体平台、电子商务网站等。</p><p>​4.<strong>嵌入式存储需求</strong>：</p><p>​•由于其嵌入式设计，RocksDB 非常适合作为大型系统的嵌入式存储引擎，如数据库系统的存储引擎、分布式存储系统等。</p><p>​5.<strong>大规模数据存储</strong>：</p><p>​•RocksDB 的多级 Compaction 策略和高效的磁盘空间管理使其适合大规模数据存储应用，如数据仓库、大数据分析平台等。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式数据库 </tag>
            
            <tag> KV存储引擎 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/hou-duan-jia-gou/jvm/"/>
      <url>/hou-duan-jia-gou/jvm/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink技术架构及原理</title>
      <link href="/hou-duan-jia-gou/flink-ji-zhu-yuan-li/"/>
      <url>/hou-duan-jia-gou/flink-ji-zhu-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="flink简介"><a class="markdownIt-Anchor" href="#flink简介"></a> Flink简介</h1><p>Flink是一个用于分布式流处理和批处理的大数据处理框架。它由Apache基金会维护，旨在提供高吞吐量、低延迟的数据处理能力，并且支持复杂的事件处理和状态管理。它的重点能力就是<strong>同时支持批处理和流处理的有状态计算</strong></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/watermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9saXhpbmt1YW4uYmxvZy5jc2RuLm5ldA%3D%3D%2Csize_16%2Ccolor_FFFFFF%2Ct_70-20240605144243247.png" alt></p><p>Flink起源于Stratosphere项目，Stratosphere是在2010~2014年由3所地处柏林的大学和欧洲的一些其他的大学共同进行的研究项目，2014年4月Stratosphere的代码被复制并捐赠给了Apache软件基金会，参加这个孵化项目的初始成员是Stratosphere系统的核心开发人员，2014年12月，Flink一跃成为Apache软件基金会的顶级项目。</p><h3 id="应用场景"><a class="markdownIt-Anchor" href="#应用场景"></a> 应用场景</h3><ol><li>实时智能推荐</li><li>复杂时间流处理</li><li>实时反欺诈检测</li><li>实时数仓与ETL</li><li>数据流分析和报表统计</li></ol><h3 id="flink的特点"><a class="markdownIt-Anchor" href="#flink的特点"></a> Flink的特点</h3><ul><li><p><strong>高吞吐、低延迟、高性能</strong>：Flink能够同时支持高吞吐、低延迟、高性能的流处理，使其成为处理大规模、高吞吐量的实时数据流和批量数据的首选</p></li><li><p><strong>事件时间支持</strong>：Flink支持事件时间(event time)概念，结合watermark处理乱序数据，这使得Flink在处理乱序事件流时能够提供一致且准确的结果</p></li><li><p><strong>有状态计算</strong>：Flink支持有状态计算，并且支持多种状态存储方式，如内存、文件、RocksDB，这使得Flink能够维护复杂的计算状态，提高计算效率</p></li><li><p><strong>精确一次的状态一致性保证</strong>：基于轻量级分布式快照(checkpoint)实现的容错保证exactly- once语义，确保了数据处理的准确性和一致性</p></li><li><p><strong>灵活的窗口操作</strong>：支持高度灵活的窗口操作，如time、count、session等，使得Flink能够适应各种复杂的流数据处理需求</p></li><li><p><strong>支持多种编程语言和API</strong>：Flink提供了丰富的API，包括Java和Scala的API，以及SQL和Table API，使得开发者可以根据自己的需求选择合适的编程语言进行开发</p></li></ul><h3 id="flink与storm-spark-streaming的比较"><a class="markdownIt-Anchor" href="#flink与storm-spark-streaming的比较"></a> Flink与Storm、Spark Streaming的比较</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/webp" alt></p><ul><li><p><strong>实时性</strong>：Flink提供了比Storm和Spark Streaming更低的延迟，能够实现毫秒级的实时处理，而Storm和Spark Streaming虽然也能处理实时数据，但在某些场景下可能无法满足低延迟的要求</p></li><li><p><strong>吞吐量</strong>：Flink在吞吐量方面表现出色，能够处理大规模的数据流，而Storm和Spark Streaming虽然也能处理大规模数据，但在某些场景下可能无法达到Flink的吞吐量</p></li><li><p><strong>容错性和状态管理</strong>：Flink提供了精确一次的状态一致性保证，以及基于轻量级分布式快照的容错机制，这使得Flink在容错性和状态管理方面表现更加优秀</p></li><li><p><strong>编程模型和API</strong>：Flink提供了丰富的API和灵活的编程模型，支持多种编程语言，使得开发者可以更加方便地构建复杂的流处理应用</p></li></ul><h1 id="flink架构"><a class="markdownIt-Anchor" href="#flink架构"></a> Flink架构</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1717556697669.png" alt></p><p><em>Client</em> 不是运行时和程序执行的一部分，而是用于准备数据流并将其发送给 JobManager。之后，客户端可以断开连接（<em>分离模式</em>），或保持连接来接收进程报告（<em>附加模式</em>）。客户端可以作为触发执行 Java/Scala 程序的一部分运行，也可以在命令行进程<code>./bin/flink run ...</code>中运行。</p><p>可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/resource-providers/standalone/overview/" target="_blank" rel="noopener">standalone 集群</a>启动、在容器中启动、或者通过<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/resource-providers/yarn/" target="_blank" rel="noopener">YARN</a>等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。</p><p><strong>Flink的架构包括以下几个关键组件：</strong></p><h4 id="jobmanager"><a class="markdownIt-Anchor" href="#jobmanager"></a> <strong>JobManager</strong></h4><p><em>JobManager</em> 具有许多与协调 Flink 应用程序的分布式执行有关的职责：它决定何时调度下一个 task（或一组 task）、对完成的 task 或执行失败做出反应、协调 checkpoint、并且协调从失败中恢复等等。这个进程由三个不同的组件组成：</p><ul><li><strong>ResourceManager</strong>负责 Flink 集群中的资源提供、回收、分配 - 它管理 <strong>task slots</strong>，这是 Flink 集群中资源调度的单位（请参考<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/flink-architecture/#taskmanagers" target="_blank" rel="noopener">TaskManagers</a>）。Flink 为不同的环境和资源提供者（例如 YARN、Kubernetes 和 standalone 部署）实现了对应的 ResourceManager。在 standalone 设置中，ResourceManager 只能分配可用 TaskManager 的 slots，而不能自行启动新的 TaskManager。</li><li><strong>Dispatcher</strong>提供了一个 REST 接口，用来提交 Flink 应用程序执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 用来提供作业执行信息。</li><li><strong>JobMaster</strong>负责管理单个<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/glossary/#logical-graph" target="_blank" rel="noopener">JobGraph</a>的执行。Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。<br>始终至少有一个 JobManager。高可用（HA）设置中可能有多个 JobManager，其中一个始终是 <em>leader</em>，其他的则是 <em>standby</em>（请参考 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/ha/overview/" target="_blank" rel="noopener">高可用（HA）</a>）。</li></ul><h4 id="taskmanager"><a class="markdownIt-Anchor" href="#taskmanager"></a> <strong>TaskManager</strong></h4><p><strong>TaskManager</strong>负责实际执行任务，管理任务的状态和数据流动。<em>TaskManager</em>（也称为 <em>worker</em>）执行作业流的 task，并且缓存和交换数据流。必须始终至少有一个 TaskManager。在 TaskManager 中资源调度的最小单位是 task <em>slot</em>。TaskManager 中 task slot 的数量表示并发处理 task 的数量。请注意一个 task slot 中可以执行多个算子（请参考<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/flink-architecture/#tasks-and-operator-chains" target="_blank" rel="noopener">Tasks 和算子链</a>）。</p><h2 id="tasks-和算子链"><a class="markdownIt-Anchor" href="#tasks-和算子链"></a> Tasks 和算子链</h2><p>对于分布式执行，Flink 将算子的 subtasks <em>链接</em>成 <em>tasks</em>。每个 task 由一个线程执行。将算子链接成 task 是个有用的优化：它减少线程间切换、缓冲的开销，并且减少延迟的同时增加整体吞吐量。</p><p>下图中，假设Source、map的并行度是2，keyBy()/window()/apply()的并行度也是2，而最终结果的输出处理sink只有1个并行。那么由于Source()和map()处理的相关性将优化成到一个slot由一个线程进行处理，而key()/window()/apply()等这种需要有状态计算的subtask可以优化到另外一个slot由一个线程进行处理，最终将结果汇集到一个subtask中进行汇总计算，最终整个job将有5个Solt进行计算</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1717555608114.png" alt></p><p><img src alt></p><h1 id="窗口"><a class="markdownIt-Anchor" href="#窗口"></a> 窗口</h1><p>窗口本质就是将无限数据集沿着时间（或者数量）的边界切分成有限数据集。在流处理系统中，窗口（Window）用于将无限的数据流划分为有限的部分进行处理。Flink支持多种类型的窗口：</p><ol><li><p><strong>Time Window</strong>：基于时间的，分为Tumbling Window（无数据重叠）和Sliding Window（有数据重叠） 。</p></li><li><p><strong>Count Window</strong>：基于数量的，分为Tumbling Window（无数据重叠）和Sliding Window（有数据重叠）。</p></li><li><p><strong>Session Window</strong>：基于会话的，一个session window关闭通常是由于一段时间没有收到元素。</p></li><li><p><strong>Global Window</strong>：全局窗口。</p></li></ol><h1 id="如何保证消息的可靠性"><a class="markdownIt-Anchor" href="#如何保证消息的可靠性"></a> 如何保证消息的可靠性</h1><p>实时任务不同于批处理任务，除非用户主动停止，一般会一直运行，运行的过程中可能存在机器故障、网络问题、外界存储问题等等，要想实时任务一直能够稳定运行，实时任务要有自动容错恢复的功能。而批处理任务在遇到异常情况时，在重新计算一遍即可。实时任务因为会一直运行的特性，如果在从头开始计算，成本会很大，尤其是对于那种运行时间很久的实时任务来说。</p><p>实时任务开启 Checkpoint 功能，也能够减少容错恢复的时间。因为每次都是从最新的 Chekpoint 点位开始状态恢复，而不是从程序启动的状态开始恢复。举个列子，如果你有一个运行一年的实时任务，如果容错恢复是从一年前启动时的状态恢复，实时任务可能需要运行很久才能恢复到现在状态，这一般是业务方所不允许的。</p><h2 id="checkpoint机制"><a class="markdownIt-Anchor" href="#checkpoint机制"></a> Checkpoint机制</h2><p>Flink Checkpoint 是一种容错恢复机制。这种机制保证了实时程序运行时，即使突然遇到异常或者机器问题时也能够进行自我恢复。Flink Checkpoint 对于用户层面来说，是透明的，用户会感觉实时任务一直在运行。</p><p>Flink Checkpoint 是 Flink 自身的系统行为，用户无法对其进行交互，用户可以在程序启动之前，设置好实时任务 Checkpoint 相关的参数，当任务启动之后，剩下的就全交给 Flink 自行管理。</p><h2 id="什么是flink任务的状态state"><a class="markdownIt-Anchor" href="#什么是flink任务的状态state"></a> 什么是Flink任务的状态State</h2><p>Flink 任务状态可以理解为实时任务计算过程中，中间产生的数据结果，同时这些计算结果会在后续实时任务处理时，能够继续进行使用。实时任务的状态可以是一个聚合结果值，比如 WordCount 统计的每个单词的数量，也可以是消息流中的明细数据。</p><p>Flink 任务状态整体可以划分两种：Operator 状态和 KeyedState。常见的 Operator 状态，比如 Kafka Topic 每个分区的偏移量。KeyedState 是基于 KeyedStream 来使用的，所以在使用前，你需要对你的流通过 keyby 来进行分区，常见的状态比如有 MapState、ListState、ValueState 等等。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/--1-4.png" alt></p><h2 id="checkpoint流程和原理"><a class="markdownIt-Anchor" href="#checkpoint流程和原理"></a> Checkpoint流程和原理</h2><p>要开启任务的额Checkpoint，要进行配置。一种是在Job代码中设置，如下,设置了开启checkpoint功能，并设置CheckpointMode为<strong>EXACTLY_ONCE</strong>, 使用RocksDB进行存储：</p><pre class="highlight"><code class="java"><span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<span class="hljs-comment">/** 开启 checkpoint 功能 */</span>env. enableCheckpointing ( interval: <span class="hljs-number">3000</span>, CheckpointingMode.EXACTLY_ONCE);<span class="hljs-comment">/** 使用RocksDB 进行状态存储 */</span>env.setStateBackend(<span class="hljs-keyword">new</span> <span class="hljs-title class_">RocksDBStateBackend</span> ( checkpointDataUri: <span class="hljs-string">&quot;hdfsPath&quot;</span> )) ;</code></pre><p>由于 Flink 管理的 keyed state 是一种分片的键/值存储，每个 keyed state 的工作副本都保存在负责该键的 taskmanager 本地中。另外，Operator state 也保存在机器节点本地。Flink 定期获取所有状态的快照，并将这些快照复制到持久化的位置，例如分布式文件系统。</p><p>如果发生故障，Flink 可以恢复应用程序的完整状态并继续处理，就如同没有出现过异常。这个过程就是Checkpoint的容错和恢复的机制。</p><p>接下来先解释下两个概念</p><h3 id="statebackend"><a class="markdownIt-Anchor" href="#statebackend"></a> StateBackend</h3><p>Flink 管理的状态存储在 <em>state backend</em> 中，实现有三种：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。三种状态存储方式与使用场景各不相同，对比如下:</p><table class="table table-bordered">  <thead>    <tr class="book-hint info">      <th class="text-left">名称</th>      <th class="text-left">Working State</th>      <th class="text-left">状态备份</th>      <th class="text-left">快照</th>    </tr>  </thead>  <tbody>    <tr>      <th class="text-left">RocksDBStateBackend</th>      <td class="text-left">本地磁盘（tmp dir）</td>      <td class="text-left">分布式文件系统</td>      <td class="text-left">全量/增量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>支持大于内存大小的状态</li>          <li>经验法则：比基于堆的后端慢10倍</li>        </ul>      </td>    </tr>    <tr>      <th class="text-left">FsStateBackend</th>      <td class="text-left">JVM Heap</td>      <td class="text-left">分布式文件系统</td>      <td class="text-left">全量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>快速，需要大的堆内存</li>          <li>受限制于 GC</li>        </ul>      </td>    </tr>    <tr>      <th class="text-left">MemoryStateBackend</th>      <td class="text-left">JVM Heap</td>      <td class="text-left">JobManager JVM Heap</td>      <td class="text-left">全量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>适用于小状态（本地）的测试和实验</li>        </ul>      </td>    </tr>  </tbody></table><p>可以看到只有<strong>RocksDBStateBackend</strong>方式的working state是保存到磁盘中的，这就意味着这种存储方式最为可靠且支持大状态存储，但同时也比基于堆内存的存储更慢。</p><p><strong>所有这些 state backends 都能够异步执行快照，这意味着它们可以在不妨碍正在进行的流处理的情况下执行快照。</strong></p><h3 id="checkpointmode"><a class="markdownIt-Anchor" href="#checkpointmode"></a> CheckpointMode</h3><p>当流处理应用程序发生错误的时候，结果可能会产生丢失或者重复。Flink 根据你为应用程序和集群的CheckpointMode配置，可以产生以下结果：</p><ul><li>Flink 不会从快照中进行恢复（<em><code>CheckpointingMode.AT_MOST_ONCE</code></em>）</li><li>没有任何丢失，但是你可能会得到重复冗余的结果（<em>CheckpointingMode.AT_LEAST_ONCE</em>）</li><li>没有丢失或冗余重复（<em>CheckpointingMode.EXACTLY_ONCE</em>）</li></ul><p>其中精准不重复消费(<em>CheckpointingMode.EXACTLY_ONCE</em>),只是通过屏障对齐(Barrier alignment)保证了流处理内部的状态一致性，如果要确保严格的端到端精准只消费一次，还必须额外满足一下两个条件：</p><ol><li><p>你的 sources 必须是可重放的</p></li><li><p>你的 sinks 必须是事务性的（或幂等的）</p></li></ol><p>Barrier 只有在需要提供精确一次的语义保证时需要进行对齐（Barrier alignment）。如果不需要这种语义，可以通过配置 <code>CheckpointingMode.AT_LEAST_ONCE</code> 关闭 Barrier 对齐来提高性能。</p><h3 id="基于exactly_once的checkpoint过程"><a class="markdownIt-Anchor" href="#基于exactly_once的checkpoint过程"></a> 基于EXACTLY_ONCE的Checkpoint过程</h3><p>一次 Flink Checkpoint 的流程是从 <code>CheckpointCoordinator</code> 的 <code>triggerCheckpoint </code>方法开始，下面来看看一次 Flink Checkpoint 涉及到的主要内容：</p><ol><li>Checkpoint 开始之前先进行预检查，比如检查最大并发的 Checkpoint 数，最小的 Checkpoint 之间的时间间隔。默认情况下，最大并发的 Checkpoint 数为 1，最小的 Checkpoint 之间的时间间隔为 0.</li><li>判断所有 Source 算子的 Subtask (Execution) 是否都处于运行状态，有则直接报错。同时检查所有待确认的算子的 SubTask(Execution)是否是运行状态，有则直接报错。</li><li>创建 <code>PendingCheckpoint</code>，同时为该次 Checkpoint 创建一个 <code>Runnable</code>，即超时取消线程，默认 Checkpoint 十分钟超时。</li><li>循环遍历所有 Source 算子的 <code>Subtask(Execution)</code>,最底层调用 Task 的<code>triggerCheckpointBarrier</code>, 广播 CheckBarrier 到下游 ，同时 Checkpoint 其状态。</li><li>下游的输入中有 <code>CheckpointBarrierHandler</code> 类来处理 <code>CheckpoinBarrier</code>，然后会调用 <code>notifyCheckpoint</code> 方法，通知 Operator SubTask 进行 Checkpoint。</li><li>每当 Operator SubTask 完成 Checkpoint 时，都会向 <code>CheckpointCoordoritor</code> 发送确认消息。<code>CheckpointCoordinator</code> 的 <code>receiveAcknowledgeMessage</code> 方法会进行处理。</li><li>在一次 Checkpoint 过程中，当所有从 Source 端到 Sink 端的算子 SubTask 都完成之后，<code>CheckpointCoordoritor</code> 会通知算子进行 <code>notifyCheckpointCompleted</code> 方法，前提是算子的函数实现 <code>CheckpointListener</code> 接口。</li></ol><p>Flink 会定时在任务的 Source 算子的 SubTask 触发 <code>CheckpointBarrier</code>，<code>CheckpointBarrier</code> 是一种特殊的消息事件，会随着消息通道流入到下游的算子中。只有当最后 Sink 端的算子接收到 <code>CheckpointBarrier</code> 并确认该次 Checkpoint 完成时，该次 <code>Checkpoint</code> 才算完成。所以在某些算子的 Task 有多个输入时，会存在 Barrier 对齐时间，我们可以在 Flink Web UI上面看到各个 Task 的 <code>CheckpointBarrier</code> 对齐时间。</p><p>下图是一次 Flink Checkpoint 实例流程示意图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/flink----.png" alt></p><h1 id="如何保证消息乱序的正确计算"><a class="markdownIt-Anchor" href="#如何保证消息乱序的正确计算"></a> 如何保证消息乱序的正确计算</h1><p>在分布式系统中的并发处理过程中，数据流在subtask间传输可能会乱序到达。这会导致我们在依赖时事件时间进行计算时出现错误结果。在Flink中是采用watermark机制进行解决。</p><p>在了解watermark之前先来理解下时间语义的几个概念。</p><ol><li><strong>事件时间（Event Time）</strong>：事件在源系统中生成的时间。Flink支持使用事件时间进行处理，使得处理更加准确。</li><li><strong>进入Flink时间（Ingestion Time）</strong>：事件进入Flink系统的时间。</li><li><strong>处理时间（Processing Time）</strong>：Flink处理事件的当前系统时间。</li></ol><p>那么一般情况下，我们所说的消息乱序是指基于时间时间的乱序，需要基于事件时间进行计算时，由于网络传输等原因，事件时间在到达处理节点是并不一定是顺序的，如下图所示的一个事件流：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/4f662ef225d04c03b0e65f6e62b11aa4.png" alt="在这里插入图片描述"></p><p>它的原理就相当于当数据流到达进行窗口计算时，不严格按照时间窗口定义的结束时间触发窗口计算，而是根据watermark设定的延迟时间适当地进行延迟计算，等一等迟到的数据。</p><p>watermark就是一个简单的周期性标记，上图中设置watermark的late time=4, 触发计算的事件窗口长度为20，当source的数据事件时间7达到之后，立刻生成watermark=3(7-4)特殊数据流插入到数据流后下发给下游，当11数据到达之后生成w(7)的watermark,以此类推…直到24数据到达时，watermark变成20，触发窗口结束计算，此后如果19这个数据再到达则直接丢弃，因为它小于watermark。</p><p>下游收到一个接收到watermark具体值时，代表这这个wartermark对于的事件时间前的事件数据已经达到，当时间窗口结束时间与watermark时间一致时，将触发窗口的结束计算，即使可能真的还有小于watermark时间的数据还没来，也不管了，先结束当前的事件窗口触发计算。</p><p>watermark有几个特点如下：</p><ol><li><p>当数据流到达后根据设置的watermark延迟时间计算出watermark,如果计算出的watermark大于之前收到的watermark值，则覆盖为最新的watermark，否则维持原有水位不变</p></li><li><p>watermark只能单调递增或者持平，不能递减</p></li><li><p>只有Source算子才会产生watermark</p><p><strong>如果真的有比watermark更晚的数据如何处理</strong></p></li></ol><p>flink有三种处理方式：</p><ol><li><p>直接丢弃（默认方式）</p></li><li><p>通过allowedLateness 指定允许数据延迟的时间</p><p>即使真的有数据达到watermark时间后还是迟到，可以在延迟回收计算好的窗口数据状态，等它来了之后再更新一下,如下代码：</p><pre class="highlight"><code class="java">waterMarkStream.keyBy(<span class="hljs-number">0</span>).window(TumblingEventTimeWindows.of(Time.seconds(<span class="hljs-number">3</span>))).allowedLateness(Time.seconds(<span class="hljs-number">2</span>))<span class="hljs-comment">//允许数据迟到2S</span><span class="hljs-comment">//function: (K, W, Iterable[T], Collector[R]) =&gt; Unit</span>.apply(<span class="hljs-keyword">new</span> <span class="hljs-title class_">MyWindowFunction</span>).print()</code></pre></li><li><p>通过sideOutputLateData 收集迟到的数据</p><p>可以通过侧输出流将异常数据保存下来进行后续的手工处理或者告警。</p></li></ol><p>通过这种机制，可以通过短暂的等待延迟来处理大部分的乱序数据，应为实际情况中的乱序数据也是在短时间（几时毫秒到几秒之间）产生的。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>Apache Flink因其独特的特性和强大的性能：其高吞吐、低延迟的流处理能力让其成为处理实时数据流和批量数据的首选，而且其支持复杂的事件处理和状态管理，使得处理实时数据流变得更加简单、高效。</p><p>Flink的窗口操作提供了多种灵活的窗口类型，可以根据业务需求选择合适的窗口类型，从而实现对数据流的精确控制和高效计算。而Checkpoint机制则保证了数据处理的可靠性和一致性，即使在发生故障或异常情况下，Flink也能够自动进行容错恢复，保障数据处理的稳定性。此外，通过Watermark机制处理消息乱序问题，Flink能够在实时数据流中准确地确定事件的发生顺序，从而确保了计算结果的准确性和一致性。</p><h3 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献：</h3><p><a href="https://tech.youzan.com/flink_checkpoint_mechanism/" target="_blank" rel="noopener">Flink Checkpoint 原理流程以及常见失败原因分析</a></p><p><a href="https://blog.jrwang.me/2019/flink-source-code-checkpoint/" target="_blank" rel="noopener">Flink 源码阅读笔记（11）- Checkpoint 机制和状态恢复 </a></p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> Flink </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何画好软件架构图</title>
      <link href="/hou-duan-jia-gou/ru-he-hua-hao-ruan-jian-jia-gou-tu/"/>
      <url>/hou-duan-jia-gou/ru-he-hua-hao-ruan-jian-jia-gou-tu/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>作为架构师，如果你需要对复杂的业务进行应用落地，在前期设计过程，或者后期给领导、新同事、业务同学做汇报或者培训时，难免需要一些直观的图来表达你的信息，所谓一图胜过千言万语。</p><h1 id="什么是架构"><a class="markdownIt-Anchor" href="#什么是架构"></a> 什么是架构</h1><p>首先，架构图是一个软件开发工程中用到的一些列图的总称，针对不同的场景，不同的受众，需要有不同视角的架构图进行展示。</p><p>从字面意思上理解，架构图=架构 + 图，它是一种当前软件架构的一种表达方式。</p><p>我们都知道现实世界到软件世界的映射，是一个不断抽象的过程，这其中的方法就是不断地进行建立模型，所以架构的过程其实就是建模的过程，而架构图就是表达你建模过程的一种方式。</p><h1 id="架构的理论"><a class="markdownIt-Anchor" href="#架构的理论"></a> 架构的理论</h1><p>在架构时，有一些业界成熟的架构方法论和范式，能够便于我们进行学习和套用</p><h1 id="41架构范式"><a class="markdownIt-Anchor" href="#41架构范式"></a> 4+1架构范式</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-e830c60fc6baa069facff2e9e62ea3ae_720w.webp" alt="img"></p><p>4+1视图的核心理念是从不同的角度去剖析系统，看看系统的结构是什么样的，具体每个视图的含义是：</p><ul><li><ol><li>逻辑视图：从终端用户角度看系统提供给用户的功能，对应 UML的 class 和 state diagrams。</li></ol></li><li><ol start="2"><li>处理视图：从动态的角度看系统的处理过程，对应 UML 的 sequence 和 activity diagrams。</li></ol></li><li><ol start="3"><li>开发视图：从程序员角度看系统的逻辑组成，对应 UML 的 package diagrams。</li></ol></li></ul><p>我们可以看到，4+1视图本身很全面也很规范，但是为什么在实际工作中，真正按照这个标准来画架构图的公司和团队并不多。其原因是这套标准是针对之前的单体应用提出来的架构方法，如今大多系统都是分布式系统，无法每个微服务都画出对应的开发视图</p><h2 id="4r架构模型"><a class="markdownIt-Anchor" href="#4r架构模型"></a> 4R架构模型</h2><p>一个完整的架构图分别需要有不同的表现形式。分别是顶层设计(Rank)、定义的系统角色(Role)、角色之间的关系(Relation)和运作规则(Rule)。如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/efc20e3906d31b82cd36b1bd60a5f6d4.png" alt="img"></p><ul><li>顶层设计Rank——业务架构/产品架构图</li></ul><p>业务架构指的是使用一套方法论/逻辑对产品（项目）所涉及到的业务进行边界划分，核心点就是把业务边界通过不同颜色模块标识出来，并做分组，同时不需要去考虑具体技术点。这个是我们实际工作中画的最多的一种图，因为这种图一般是给领导汇报，产品人员规划业务，新员工培训用的，没有这个图很难讲清楚业务大概。例如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-056928b23841cb0fc5987c574c4fa7a0_720w.webp" alt="img"></p><p>在比如下面的产品架构图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-5b9c8ba892b39f6baa5c7a1ea57f5f83_r.jpg" alt="img"></p><ul><li>定义系统角色(Role)——应用架构/系统架构</li></ul><p>应用架构更侧重于系统实现的一个总体架构，需要指出系统的层次、系统开发的原则、系统各个层次的应用服务，通过不同的颜色来标识角色，自顶向下分层设计。</p><p>如下图，系统应用分为数据层、服务层、通讯层、展示层，并西风写明每个层次的应用服务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/aca89fe2d9847328a558fa9708381c38.png" alt="img"></p><p>如果你觉得不需要花的那么细，那么也可以按下图所示进行展示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/5b48da8ec860129f8bed202a0f237195.png" alt="img"></p><ul><li>展示角色之间的关系(Relation)——系统关系图</li></ul><p>如果系统比较复杂，按照架构分层的角度来看，应用架构已经到了可执行程序这一层，例如支付中台这一类的系统，包含的应用可能有几百上千个，如果把整个支付中台所有的应用都在一张图里面展示出来，信息太多太密，可能会导致架构图都看不清。+这种情况下，应用架构一般都是按照子域来画应用架构图，可以参考支付中台的会员域的应用架构图</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-428f6cce9e675e0bb80547d60575fa3f_720w.webp" alt="img"></p><ul><li>展示角色的交互协作规则(Rule)——核心业务时序图/泳道图</li></ul><p>一般情况下核心业务不止一个，可能会有多个，例如下单流程，支付流程、交付流程等都是比较核心的流程，一般会由多个不同的核心业务时序图来描述，例如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-c52535e2da10d566a9f9b20cbd9299b8_720w.webp" alt="img"></p><h1 id="c4架构模型"><a class="markdownIt-Anchor" href="#c4架构模型"></a> C4架构模型</h1><p>这里再推荐一个现在很流行的 C4 架构模型，其官网为：<a href="https://c4model.com/" target="_blank" rel="noopener">https://c4model.com/</a></p><p>C4 架构模型由一系列分层的软件架构图组成，这些架构图用于描述上下文、容器、组件和代码。C4 图的层次结构提供了不同的抽象级别，每种抽象级别都与不同的受众有关。</p><p>C4 代表 上下文（Context）、容器（Container）、组件（Component）和代码（Code），是一系列分层的图表，可以用这些图表来描述不同 Level 的软件架构，每种图表都适用于不同的受众。可以将其视为代码的谷歌地图。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/ebc5d5e54bb1e3b40e864812a7ebd4b9.png" alt="img"></p><p>C4模型的理论也在不断进化，以适应不同的软件形态</p><h1 id="画好架构图的思路"><a class="markdownIt-Anchor" href="#画好架构图的思路"></a> 画好架构图的思路</h1><p>上面介绍了那么多行业的架构图标准和范式，在实际过程中不一定都要按照这种来，有时候完全按照这种范式进行画图反而会觉得比较繁琐和多余。</p><p>那么一般画好一副软件建模过程中的一幅图，一般的思路为：</p><ul><li><p>第一，搞清楚要画的架构图类型，明确画架构图的核心目的；</p></li><li><p>第二，确认架构图中的关键要素（比如产品、技术、服务）；</p></li><li><p>第三，梳理关键要素之间的关联：包含、支撑、同级并列等；</p></li><li><p>第四，输出关联关系清晰的架构图。</p></li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-25fa97abf2e16cf2ed70df985e7d8815_720w.webp" alt="img"></p><p>其实归根接地就是想清楚你要表达什么，受众是谁。</p><h1 id="画架构图的一些工具"><a class="markdownIt-Anchor" href="#画架构图的一些工具"></a> 画架构图的一些工具</h1><h2 id="1-processon"><a class="markdownIt-Anchor" href="#1-processon"></a> 1、ProcessOn</h2><p><a href="https://www.processon.com/diagrams" target="_blank" rel="noopener">https://www.processon.com/diagrams</a></p><p>免费画图有限制，我一般用这个比较多，用起来比较方便，开通个连续5年的vip也不贵，关键是经常用的上</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240323190925419.png" alt="image-20240323190925419"></p><h2 id="2-httpdrawio"><a class="markdownIt-Anchor" href="#2-httpdrawio"></a> 2、<a href="http://draw.io" target="_blank" rel="noopener">http://draw.io</a></h2><p><a href="http://draw.io" target="_blank" rel="noopener">http://draw.io</a></p><p>大家一定会喜欢这个，因为免费！！！这个连接的是 GitHub 和 Google Drive，不连接的话就是个离线版本。而且有 vscode 的插件可用。所以我身边用这个的大佬颇多。界面和processOn有点像，不知道是谁炒的谁。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240323190949700.png" alt="image-20240323190949700"></p><h2 id="3-excalidraw"><a class="markdownIt-Anchor" href="#3-excalidraw"></a> 3、excalidraw</h2><p><a href="https://excalidraw.com/" target="_blank" rel="noopener">https://excalidraw.com/</a></p><p>这个就是拼脑洞的，很好看,有种涂鸦的效果，在很多开源项目中经常能看到这种图，就是用它画出来的</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/va5u5frapi3mrh30q09l.png" alt="img"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v3dg5xgd6ybygwevuzas.png" alt="img"></p><h2 id="3-uml-图"><a class="markdownIt-Anchor" href="#3-uml-图"></a> 3、UML 图：</h2><p><a href="https://plantuml.com/zh/" target="_blank" rel="noopener">https://plantuml.com/zh/</a>  ，有非常多的示例，同时 VScode / webstorm 都有对应的插件，可以方便的在编辑器中书写</p><p>okeeper/blog-images</p><p><img src alt="loading-ag-1625"></p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis为什么快</title>
      <link href="/hou-duan-jia-gou/redis-wei-shi-me-kuai/"/>
      <url>/hou-duan-jia-gou/redis-wei-shi-me-kuai/</url>
      
        <content type="html"><![CDATA[<h1 id="redis介绍"><a class="markdownIt-Anchor" href="#redis介绍"></a> Redis介绍</h1><p>关系型数据库（如MySQL）的I/O瓶颈通常是由于数据存储和检索操作的频繁性以及磁盘读写速度限制所致。随着互联网应用和数据量的爆炸式增长，传统的关系型数据库在某些场景下可能无法满足高并发和低延迟的需求，特别是在读取密集型或者数据量非常大的情况下。在这种情况下，开发人员开始寻找更高效的解决方案。</p><p>Redis产生的背景正是基于这样的需求。Redis是一个基于内存的数据存储系统，具有高性能、低延迟和高并发的特点。相比于传统的关系型数据库，Redis通过将数据存储在内存中，极大地提高了数据的读取和写入速度。在Redis中，数据通常存储在内存中，并通过快速的键值对存储和检索来实现。</p><p>Redis的产生背景可以追溯到互联网应用需要处理大量实时数据、缓存和会话管理等需求。随着这些需求的不断增长，传统的关系型数据库在性能方面逐渐暴露出瓶颈。于是，人们开始寻求一种更适合这些需求的解决方案，Redis就是其中之一。</p><p>Redis的出现不仅解决了传统关系型数据库的I/O瓶颈问题，还为开发人员提供了更多的工具和机会来构建高性能、可扩展的应用程序。通过将数据存储在内存中，并提供丰富的数据结构和功能，Redis成为了许多互联网公司构建实时应用、缓存系统和消息队列等方面的首选解决方案之一。</p><p>根据DB-Engines的K-V数据库排名，Redis一直是最受欢迎的键值存储数据库。</p><p><a href="https://db-engines.com/en/ranking/key-value+store" target="_blank" rel="noopener">DB-Engines Ranking - popularity ranking of key-value stores</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716263591173.png" alt></p><p>Redis做为一个KV内存NoSQL数据的优点如下：</p><ul><li><p>高性能：Redis是一个基于内存的数据库，这意味着它可以提供非常快速的数据读写操作。由于数据存储在内存中，Redis能够实现非常低延迟的访问，适用于需要快速响应的应用场景，如实时数据处理、缓存等。</p></li><li><p>丰富的数据结构支持：Redis支持丰富的数据结构，包括字符串、哈希、列表、集合、有序集合等。这使得开发人员可以更灵活地处理数据，不仅可以简单地存储键值对，还可以实现复杂的数据操作和数据结构。</p></li><li><p>持久化支持：尽管Redis是一个内存数据库，但它也提供了持久化的支持，可以将数据定期写入磁盘，以防止数据丢失。这种持久化支持可以在数据库重启时恢复数据，确保数据的安全性和持久性。</p></li><li><p>高可用性和可扩展性：Redis支持主从复制和分片等机制，可以实现数据的高可用性和可扩展性。通过配置主从复制和分片，可以实现数据的备份和负载均衡，提高系统的稳定性和可靠性。</p></li><li><p>丰富的生态系统和社区支持：Redis拥有一个活跃的开源社区和丰富的生态系统，有大量的第三方工具和库可供使用。这些工具和库可以帮助开发人员更轻松地集成Redis到他们的应用中，并提供更多的功能和特性。</p></li></ul><h1 id="redis为什么快"><a class="markdownIt-Anchor" href="#redis为什么快"></a> Redis为什么快</h1><p>我们对Redis的印象就是快，高性能，理论能达到10wqps。这得益于它的线程模型和基于内存的高速读写</p><p>Redis的单线程模型具体工作方式如下：</p><ol><li><p><strong>Redis它属于内存数据库</strong>，数据的读写都在内存中进行，减少了对磁盘IO的依赖</p></li><li><p><strong>多路复用技术的非阻塞IO</strong>：Redis使用同步非阻塞I/O操作来处理客户端请求。可以通过单个线程借助系统内核的epoll实现IO多路复用，用极少的线程资源处理大量的并发请求，增加了CPU的利用率。同时在Redis6.0之后当主线程epoll监听到多个可读写的IO事件时，利用多线程并行处理IO读写事件，加快了IO处理的并行度</p></li><li><p><strong>数据处理事件单线程处理</strong>：在任何给定的时间点，Redis只有一个线程在执行。这个线程负责处理所有的客户端达到的请求挨个进行处理，避免了多线程间的同步和锁竞争。</p></li></ol><p>虽然Redis采用了单线程模型，但它仍然能够实现高性能和高并发。这是因为Redis的主要瓶颈通常是在CPU或者网络带宽上，而不是在线程调度或者同步开销上。此外，Redis通过使用多路复用技术（如epoll、kqueue等）来同时处理大量的客户端连接，从而提高了系统的吞吐量和并发性能。</p><p>所以总结两点，redis为什么快：</p><ul><li><p>基于内存单线程，内存快速存取无锁竞争，摆脱了磁盘IO瓶颈</p></li><li><p>使用IO多路复用，提升了处理客户端请求并发能力，摆脱了网络IO的瓶颈</p></li></ul><h1 id="如何理解io多路复用"><a class="markdownIt-Anchor" href="#如何理解io多路复用"></a> 如何理解IO多路复用</h1><p>简单理解就是一个服务端线程可以同时接受处理来自多个不同网络链路的网络IO请求。</p><p>其中多路复用我们分开理解</p><ul><li>多路：多个客户端连接</li><li>复用：使用单进程就能够实现同时处理多个客户端的连接 ​</li></ul><p>它的基本原理就是不再由应用程序自己监视连接，而是由内核替应用程序监视文件描述符。客户端在操作的时候，会产生具有不同事件类型的 socket。</p><p>I/O多路复用经过一下这几个阶段发展</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20190225204240.png" alt></p><h2 id="阻塞式ioblocking-io"><a class="markdownIt-Anchor" href="#阻塞式ioblocking-io"></a> 阻塞式IO(Blocking IO)</h2><p>这里的阻塞是指注册用户进程，从用户进程发起IO读取请求到真正读到数据过程中完全阻塞，用户线程做不了任何事情，CPU资源利用率极低。</p><h2 id="非阻塞是io"><a class="markdownIt-Anchor" href="#非阻塞是io"></a> 非阻塞是IO</h2><p>这个过程就是用户线程向内核发起网络IO请求，如果当前有就绪可用的IO就开始读取数据并返回，如果没有就绪链路就返回异常，用户线程继续轮询，知道返回可读数据。那么这个过程用户线程全程没有闲着，不停地在询问系统内核是否有可用IO,虽然是非阻塞的，但也效率低下，都在做一些大量重复且没有太多价值的事情。</p><h2 id="io多路复用"><a class="markdownIt-Anchor" href="#io多路复用"></a> I/O多路复用</h2><p>以上两种如果在高并发场景下，如果一个线程只能处理一个网络IO请求，必然考开启多个线程进行，这样避免不了上下文切换的开销，而随着系统内核技术的发展，IO多路复用技术出现，只需要一个用户线程即可处理多个网络IO请求，极大的提高了并发处理的性能。</p><h2 id="信号量驱动的io模型"><a class="markdownIt-Anchor" href="#信号量驱动的io模型"></a> 信号量驱动的IO模型</h2><p>应用进程先调用系统的sigacation,建立SIGIO信号，接着等待系统内核主动通知是否有准备就绪的可读IO，接下来交给用户进程进行数据读取</p><h2 id="异步io"><a class="markdownIt-Anchor" href="#异步io"></a> 异步IO</h2><p>异步IO是指从等待IO时间准备就绪到IO数据独居都已经在系统内核执行完成，整个过程无需用户进程参与，也不需要读取IO数据，直接用即可，真正的一部IO只有window实现了，linux目前大多只实现了IO多路复用(基于select/poll/epoll)</p><h1 id="操作系统内核selectpollepoll的区别"><a class="markdownIt-Anchor" href="#操作系统内核selectpollepoll的区别"></a> 操作系统内核select/poll/epoll的区别</h1><p>这三个都是IO多路复用操作系统底层的实现，都是同步非阻塞是的IO模型，这是三个不同的发展阶段</p><h2 id="最开始的select"><a class="markdownIt-Anchor" href="#最开始的select"></a> 最开始的select</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716285479387.png" alt></p><p>如上图所示，用户进程需要记录所有需要遍历的套接字集合，传给操作系统内核帮我们挨个轮询是否有准备就绪的IO，且linux最大上限是1024连接描述符</p><h2 id="poll"><a class="markdownIt-Anchor" href="#poll"></a> poll</h2><p>本质上原理和select一样，算是select改进版本，但底层还是有系统内核进行轮询实现，主要改进是在文件描述符上限远大于1024</p><h2 id="epoll"><a class="markdownIt-Anchor" href="#epoll"></a> epoll</h2><p>这是目前主流的linux多路复用底层实现，它相较于select/poll。操作系统内核不在使用主动轮询的方式来确定是否有可用的IO socket,而是基于网络IO事件的主动通知机制，准备就绪的IO事件会被操作系统内核缓存起来(红黑树结构)，等待用户进程调用epoll_wait时返回。返回之后任然需要用户进程进行主动读取IO数据<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716286989659.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> Redis </tag>
            
            <tag> DB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>互联网大厂中分布式ID解决方案</title>
      <link href="/hou-duan-jia-gou/hu-lian-wang-da-han-de-fen-bu-shi-id-jie-jue-fang-an/"/>
      <url>/hou-duan-jia-gou/hu-lian-wang-da-han-de-fen-bu-shi-id-jie-jue-fang-an/</url>
      
        <content type="html"><![CDATA[<h1 id="互联网大厂中分布式id解决方案"><a class="markdownIt-Anchor" href="#互联网大厂中分布式id解决方案"></a> 互联网大厂中分布式ID解决方案</h1><blockquote><p>在高并发、高可用场景中，为了满足后续数据库水平扩容，如由于日益增长的数据需要分库分表时，通过数据库认的ID生成策略显然有诸多问题，例如他只能满足在单个数据库实例中唯一，不能全局唯一，其次如果所有的insert依赖数据库的自增也会有一定的性能问题。这就引出了我们今天的主角：分布式ID生成</p></blockquote><h2 id="常见的集中分布式id生成策略"><a class="markdownIt-Anchor" href="#常见的集中分布式id生成策略"></a> 常见的集中分布式ID生成策略</h2><h3 id="1-uuid"><a class="markdownIt-Anchor" href="#1-uuid"></a> 1. UUID</h3><p>UUID（Universally Unique Identifier）是一种由128位数字表示的唯一标识符。它的唯一性基于标准的UUID生成算法和硬件地址、时间戳等信息。UUID不依赖于中心化的ID生成器，可以在分布式系统中生成全局唯一的ID。</p><p><strong>优点</strong>：JDK自带，直接可生成，简单。</p><p><strong>缺点</strong>：字符串类型，无序，长度过长。</p><p>知道数据库主键索引的底层原理的就知道，这几个缺点就直接决定它一般不会使用在数据库主键的生成策略中。它只满足分布式唯一性，并不能当ID使用。</p><h3 id="2-基于redis"><a class="markdownIt-Anchor" href="#2-基于redis"></a> 2. 基于Redis</h3><p>基于Redis是一个高性能的内存数据库，能够快速地生成ID并响应请求，并保证全局有序和唯一</p><p><strong>优点</strong>：</p><ul><li>性能高：Redis支持主从复制和哨兵模式，能够保证服务的高可用性。</li><li>全局有序：通过redis的原子性操作能够实现全局ID递增</li></ul><p><strong>缺点</strong>：</p><ul><li>单点故障：Redis单点故障可能会影响整个系统的可用性，需要使用主从复制或者哨兵模式来解决。</li><li>数据一致性：Redis的持久化存储可能会导致数据一致性问题，需要合理配置持久化策略和备份机制来保证数据的一致性。</li><li>可扩展性：虽然Redis支持集群模式，但是在规模较大的情况下，可能需要进行水平扩展，这需要额外的成本和复杂性。</li></ul><p>总的来说，基于Redis实现的分布式ID生成器具有高性能、全局有序的优点，但是需要注意单点故障、数据一致性和可扩展性等方面的挑战。引入了额外的运维复杂性，极端情况可能会丢数据导致数据一致性问题</p><h3 id="3-基于zookeeper"><a class="markdownIt-Anchor" href="#3-基于zookeeper"></a> 3. 基于Zookeeper</h3><p>基于ZK的ZAB一致性协议，能够保证数据的强一致性，实现高可用地生成全局有序的分布式ID,同时支持方便的动态水平节点扩容。</p><p><strong>优点：</strong></p><ul><li>强一致性：Zookeeper保证数据的强一致性，能够确保生成的ID在整个系统中是唯一的。</li><li>分布式锁支持：Zookeeper提供了分布式锁的机制，可以在生成ID时加锁以保证并发安全。</li><li>动态扩展：Zookeeper集群支持动态扩展，可以根据系统的需求随时添加新节点来提高服务的性能和可用性。</li></ul><p><strong>缺点：</strong></p><ul><li>复杂性：Zookeeper的配置和管理相对复杂，需要一定的学习和了解成本。</li><li>性能瓶颈：Zookeeper在高并发场景下可能存在性能瓶颈，需要合理设计和优化。</li><li>依赖性：基于Zookeeper实现的分布式ID生成器对Zookeeper集群的稳定性和可用性有一定依赖性，需要注意Zookeeper集群的维护和监控。</li></ul><p>基于ZK和基于Redis实现的分布式ID原理类似，都是基于第三方存储组件实现全局的ID有序，但相对于redis，它会有一定的性能瓶颈问题。<br>那么不管是基于Redis还是基于ZK实现的分布式ID在非三高场景下基本也能满足我们的需求，相较于数据库的ID自增也充分预留了很多后续数据库水平扩容的可能性。但还有一个比较致命的问题是，由于它的自增特性，对外暴露的ID容易被用户猜到系统的单量和qps，商业敏感性问题就暴露出来了。</p><h3 id="4-基于内存自增第三方存储号段分配"><a class="markdownIt-Anchor" href="#4-基于内存自增第三方存储号段分配"></a> 4. 基于内存自增+第三方存储号段分配</h3><p>基于内存自增和第三方存储号段分配的分布式ID生成策略是一种常见的实现方式，它结合了内存和外部存储的优势，可以在一定程度上保证高性能和可靠性。</p><p><strong>优点：</strong></p><ul><li>高性能：利用内存自增的方式可以实现高效的ID生成，减少了对外部存储的依赖，提高了ID生成的速度和吞吐量。</li><li>可靠性：通过第三方存储的号段分配机制，可以确保生成的ID在整个系统中是唯一的，从而保证了系统的数据一致性和正确性。<br>灵活性：该策略可以灵活地根据系统的需求调整号段的大小和分配方式，从而更好地适应不同的业务场景和负载。</li><li>可扩展性：每个节点可以独立地从第三方存储获取号段，并在本地生成ID，因此该策略具有良好的水平扩展性，能够适应系统的扩展和增长。</li></ul><p><strong>缺点：</strong></p><ul><li>依赖性：该策略依赖于第三方存储来分配号段，如果第三方存储发生故障或者性能瓶颈，可能会影响整个系统的稳定性和可用性。</li><li>一致性：节点之间获取号段的过程可能存在一定的延迟，因此可能会出现一段时间内生成的ID不是严格有序的情况。需要根据业务需求和系统要求来权衡一致性和性能。</li><li>故障恢复：当节点发生故障或者重启时，需要重新初始化并从第三方存储获取一个新的号段，可能会导致一段时间内无法生成ID。</li></ul><h3 id="5-互联网大厂中用的最为广泛的雪花算法"><a class="markdownIt-Anchor" href="#5-互联网大厂中用的最为广泛的雪花算法"></a> 5. 互联网大厂中用的最为广泛的雪花算法</h3><p>那么有没有一种分布式ID生成策略，既能满足高性能、高可用、全局有序、还不暴露商业名感性问题的一种完美解决方案呢，经过互联网的长期实践，答案肯定是有的，也就是我们在互联网大厂中用的最为广泛的雪花算法（Snowflake Algorithm）</p><p>雪花算法（Snowflake Algorithm）是Twitter开发的一种分布式唯一ID生成算法，主要用于生成分布式系统中的唯一ID。该算法生成的ID是一个64位的整数，结构如下：</p><pre class="highlight"><code class>0  1               41             51               64+-+----------------+--------------+----------------+|0| timestamp(ms)  | worker node  | sequence number|+-+----------------+--------------+----------------+</code></pre><p>其中：</p><p>timestamp(ms)：41位，表示生成ID的时间戳，精确到毫秒级。<br>worker node：10位，表示机器ID，用于标识不同的机器。<br>sequence number：12位，表示每个节点每毫秒生成的序列号。</p><p>它的核心算法如下：</p><pre class="highlight"><code class="java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SnowflakeIdGenerator</span> {    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> startTime;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">workerIdBits</span> <span class="hljs-operator">=</span> <span class="hljs-number">5L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequenceBits</span> <span class="hljs-operator">=</span> <span class="hljs-number">12L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">maxWorkerId</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span> ^ (-<span class="hljs-number">1L</span> &lt;&lt; workerIdBits);    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">workerIdShift</span> <span class="hljs-operator">=</span> sequenceBits;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">timestampLeftShift</span> <span class="hljs-operator">=</span> sequenceBits + workerIdBits;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequenceMask</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span> ^ (-<span class="hljs-number">1L</span> &lt;&lt; sequenceBits);    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> workerId;    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequence</span> <span class="hljs-operator">=</span> <span class="hljs-number">0L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-variable">lastTimestamp</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span>;    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SnowflakeIdGenerator</span><span class="hljs-params">(<span class="hljs-type">long</span> workerId)</span> {        <span class="hljs-keyword">if</span> (workerId &lt; <span class="hljs-number">0</span> || workerId &gt; maxWorkerId) {            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>(String.format(<span class="hljs-string">&quot;Worker ID must be between 0 and %d&quot;</span>, maxWorkerId));        }        <span class="hljs-built_in">this</span>.workerId = workerId;        <span class="hljs-built_in">this</span>.startTime = <span class="hljs-number">1609459200000L</span>; <span class="hljs-comment">// 2021-01-01 00:00:00</span>    }    <span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-type">long</span> <span class="hljs-title function_">generateId</span><span class="hljs-params">()</span> {        <span class="hljs-comment">// 获取当前时间戳（毫秒级）</span>        <span class="hljs-type">long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis();        <span class="hljs-comment">// 如果当前时间戳小于上次生成ID的时间戳，说明发生了时钟回拨，抛出异常</span>        <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(<span class="hljs-string">&quot;时钟回拨，请等待...&quot;</span>);        }        <span class="hljs-comment">// 如果当前时间戳和上次生成ID的时间戳相等，则需要生成同一时间戳下的下一个ID</span>        <span class="hljs-keyword">if</span> (timestamp == lastTimestamp) {            <span class="hljs-comment">// 序列号自增，&amp; sequenceMask保证序列号不超过最大值</span>            sequence = (sequence + <span class="hljs-number">1</span>) &amp; sequenceMask;            <span class="hljs-comment">// 如果序列号溢出（超过最大值），等待下一个毫秒</span>            <span class="hljs-keyword">if</span> (sequence == <span class="hljs-number">0</span>) {                timestamp = waitNextMillis(timestamp);            }        } <span class="hljs-keyword">else</span> {            <span class="hljs-comment">// 如果当前时间戳大于上次生成ID的时间戳，则重置序列号为0</span>            sequence = <span class="hljs-number">0</span>;        }        <span class="hljs-comment">// 更新上次生成ID的时间戳</span>        lastTimestamp = timestamp;        <span class="hljs-comment">// 生成ID</span>        <span class="hljs-comment">// 时间戳部分左移timestampLeftShift位，机器ID部分左移workerIdShift位，再与序列号做或运算</span>        <span class="hljs-type">long</span> <span class="hljs-variable">id</span> <span class="hljs-operator">=</span> ((timestamp - startTime) &lt;&lt; timestampLeftShift) |                  (workerId &lt;&lt; workerIdShift) |                  sequence;        <span class="hljs-comment">// 返回生成的唯一ID</span>        <span class="hljs-keyword">return</span> id;    }    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-title function_">waitNextMillis</span><span class="hljs-params">(<span class="hljs-type">long</span> lastTimestamp)</span> {        <span class="hljs-type">long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis();        <span class="hljs-keyword">while</span> (timestamp &lt;= lastTimestamp) {            timestamp = System.currentTimeMillis();        }        <span class="hljs-keyword">return</span> timestamp;    }    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {        <span class="hljs-type">SnowflakeIdGenerator</span> <span class="hljs-variable">idGenerator</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SnowflakeIdGenerator</span>(<span class="hljs-number">1</span>);        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {            System.out.println(idGenerator.generateId());        }    }}</code></pre><p>在我们初始化时，只需要指定一个workerId传入，new一个SnowflakeIdGenerator()就可以happy地generateId()。</p><h3 id="那么这个workerid一般怎么来呢"><a class="markdownIt-Anchor" href="#那么这个workerid一般怎么来呢"></a> 那么这个workerId一般怎么来呢？</h3><p>Worker ID 一般是根据具体的部署环境来确定的，通常有以下几种方式来确定 Worker ID：</p><ul><li><p>手动分配：在部署系统时，手动为每个部署实例分配一个唯一的 Worker ID。这种方式简单直接，适用于部署数量有限且固定的情况。例如，对于一组服务器集群，可以手动为每台服务器分配一个唯一的 Worker ID。</p></li><li><p>基于IP地址或主机名生成：可以根据部署实例的IP地址或主机名生成 Worker ID。例如，可以使用IP地址的一部分或者主机名的哈希值作为 Worker ID。这种方式可以确保不同的部署实例拥有不同的 Worker ID。</p></li><li><p>动态注册：部署实例在启动时向一个中心注册中心注册，注册中心分配一个唯一的 Worker ID。这种方式适用于部署实例数量不固定或者动态变化的情况。例如，可以使用Zookeeper作为注册中心，在部署实例启动时向Zookeeper注册，并从Zookeeper获取 Worker ID。</p></li><li><p>基于环境参数配置：在系统的配置文件中配置 Worker ID，部署时根据环境参数加载相应的配置。这种方式可以灵活地根据部署环境配置 Worker ID。例如，可以在系统的配置文件中配置 Worker ID，然后在部署时根据环境变量加载相应的配置。</p></li></ul><h2 id="成熟的组件"><a class="markdownIt-Anchor" href="#成熟的组件"></a> 成熟的组件</h2><p>那么多方式中，大厂一般用第三种实现，基于动态注册的方式获取workerId，因为一般一个应用实例集群实例可能有上百台之多，且每逢大促还要进行扩缩容，如果还要依赖外部配置或认为干预的分配实例级别唯一的workderId好像也挺复杂的，那么有没有成熟的解决方案呢？答案是肯定的</p><h3 id="美团的leaf"><a class="markdownIt-Anchor" href="#美团的leaf"></a> 美团的Leaf</h3><p>取名Leaf（树叶），是对标Snowflake（雪花）的。<br>Leaf这个名字是来自德国哲学家、数学家莱布尼茨的一句话： &gt;There are no two identical leaves in the world &gt; “世界上没有两片相同的树叶”</p><p>Leaf Github: <a href="https://github.com/Meituan-Dianping/Leaf" target="_blank" rel="noopener">https://github.com/Meituan-Dianping/Leaf</a></p><p>它有两种实现，一种是利用数据库获取号段Segment后再内存做递增的Leaf-segement方案。<br>另外一种就是基于ZK实现自动workerId生成的雪花算法实现。</p><h4 id="leaf-segement方案实现原理"><a class="markdownIt-Anchor" href="#leaf-segement方案实现原理"></a> Leaf-segement方案实现原理</h4><p>利用数据库每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。从而几增加了可用性，实现了全局有序。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715864830524-ca2d5ed2-37d9-4c18-8aa8-7bb1d8b390a2.png" alt></p><p>书库表中记录每个biz_tag当前使用到的最大的id,当别的实例来获取号段Segment时则从当前最大的id往后获取一个Segement给服务实例在内存使用。<br>每次获取号段是实际上是执行以下sql</p><pre class="highlight"><code class="sql"><span class="hljs-keyword">Begin</span><span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">SET</span> max_id<span class="hljs-operator">=</span>max_id<span class="hljs-operator">+</span>step <span class="hljs-keyword">WHERE</span> biz_tag<span class="hljs-operator">=</span>xxx<span class="hljs-keyword">SELECT</span> tag, max_id, step <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> biz_tag<span class="hljs-operator">=</span>xxx<span class="hljs-keyword">Commit</span></code></pre><p>默认的step步长是1000，一般步长越长性能越高，但也意味着如果频繁重启，浪费的未使用ID也就越多。<br>在实际使用过程中，如果内存中号段用完再去数据库中获取下一个号段，会对业务有一定的阻塞。在此又做了双buffer的优化。</p><p><strong>双buffer的优化</strong><br>Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。</p><p>为此，我们希望DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的TP999指标。详细实现如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715865227563-f2354ea1-035b-4c90-aca3-9f6868abc4f7.png" alt></p><h4 id="leaf-snowflake方案"><a class="markdownIt-Anchor" href="#leaf-snowflake方案"></a> Leaf-snowflake方案</h4><p>Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf服务规模较大，动手配置成本太高。所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID。Leaf-snowflake是按照下面几个步骤启动的：</p><ol><li>启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。</li><li>如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。</li><li>如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715865479775-e6a4368c-3abe-4dd4-a704-abe2c1222514.png" alt></p><p><strong>此外还做了一些额外的优化，例如弱依赖ZooKeeper。</strong><br>除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA。</p><p><strong>雪花算法中最近点的时钟回拨问题</strong><br>因为雪花算法依赖系统时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。当然实际上发生这种概率较少，但是一旦发生将造成严重的后果，Leaf的解决思路就是在zk中记录定期（每个3s）上报的上一次系统时间戳，如果发现回拨过长就过长在启动时将失败，</p><p><img src="https://raw.githubusercontent.com/okeeper/blog-images/main/2024/05/16/1715865919010-9ce1694c-acf1-42fd-bab1-f32b65832bf3.png" alt></p><p>如果在获取ID时发现回拨时间过长也将报错，较短时如小于5ms将进行短暂地等待。</p><pre class="highlight"><code class="java"><span class="hljs-comment">//发生了回拨，此刻时间小于上次发号时间</span> <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {            <span class="hljs-type">long</span> <span class="hljs-variable">offset</span> <span class="hljs-operator">=</span> lastTimestamp - timestamp;            <span class="hljs-keyword">if</span> (offset &lt;= <span class="hljs-number">5</span>) {                <span class="hljs-keyword">try</span> {                    <span class="hljs-comment">//时间偏差大小小于5ms，则等待两倍时间</span>                    wait(offset &lt;&lt; <span class="hljs-number">1</span>);<span class="hljs-comment">//wait</span>                    timestamp = timeGen();                    <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {                       <span class="hljs-comment">//还是小于，抛异常并上报</span>                        throwClockBackwardsEx(timestamp);                      }                    } <span class="hljs-keyword">catch</span> (InterruptedException e) {                     <span class="hljs-keyword">throw</span>  e;                }            } <span class="hljs-keyword">else</span> {                <span class="hljs-comment">//throw</span>                throwClockBackwardsEx(timestamp);            }        } <span class="hljs-comment">//分配ID       </span></code></pre><h3 id="百度的uid-generator"><a class="markdownIt-Anchor" href="#百度的uid-generator"></a> 百度的uid-generator</h3><p>Git Hub: <a href="https://github.com/baidu/uid-generator" target="_blank" rel="noopener">https://github.com/baidu/uid-generator</a></p><p>UidGenerator是Java实现的, 基于Snowflake算法的唯一ID生成器。UidGenerator以组件形式工作在应用项目中, 支持自定义workerId位数和初始化策略, 从而适用于docker等虚拟化环境下实例自动重启、漂移等场景。 在实现上, UidGenerator通过借用未来时间来解决sequence天然存在的并发限制; 采用RingBuffer来缓存已生成的UID, 并行化UID的生产和消费, 同时对CacheLine补齐，避免了由RingBuffer带来的硬件级「伪共享」问题. 最终单机QPS可达600万。</p><p>它对标准的雪花算法位数做了一些优化，如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715866183150-20ceed8e-0cc8-4470-9fa5-5ded08130154.png" alt></p><ul><li><p>sign(1bit)<br>固定1bit符号标识，即生成的UID为正数。</p></li><li><p>delta seconds (28 bits)<br>当前时间，相对于时间基点&quot;2016-05-20&quot;的增量值，单位：秒，最多可支持约8.7年</p></li><li><p>worker id (22 bits)<br>机器id，最多可支持约420w次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用后即弃，后续可提供复用策略。</p></li><li><p>sequence (13 bits)<br>每秒下的并发序列，13 bits可支持每秒8192个并发。</p></li></ul><p>此外它还使用RingBuffer进行内存的ID自增，将性能压缩到极致。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715866435360-505ed8ad-6b3a-4995-844b-4e3d286b5eaa.png" alt></p><p>它的WorkderId是基于数据集记录实现的，需要提前在数据库表中维护每个host机器对应的当前workerId，每次发生重启workder将递增,单台机器最大支持420w次重启，超过这个数时将从0开始复用</p><pre class="highlight"><code class>DROP DATABASE IF EXISTS `xxxx`;CREATE DATABASE `xxxx` ;use `xxxx`;DROP TABLE IF EXISTS WORKER_NODE;CREATE TABLE WORKER_NODE(ID BIGINT NOT NULL AUTO_INCREMENT COMMENT 'auto increment id',HOST_NAME VARCHAR(64) NOT NULL COMMENT 'host name',PORT VARCHAR(64) NOT NULL COMMENT 'port',TYPE INT NOT NULL COMMENT 'node type: ACTUAL or CONTAINER',LAUNCH_DATE DATE NOT NULL COMMENT 'launch date',MODIFIED TIMESTAMP NOT NULL COMMENT 'modified time',CREATED TIMESTAMP NOT NULL COMMENT 'created time',PRIMARY KEY(ID)) COMMENT='DB WorkerID Assigner for UID Generator',ENGINE = INNODB;</code></pre><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>在设计和实现一个分布式ID生成器时，虽然看起来似乎是一个简单的任务，但实际上需要考虑和解决的问题并不简单。以下是对分布式ID生成器设计和实现过程中需要注意的关键问题的续写总结：</p><p>首先，分布式ID生成器的设计需要考虑到系统的需求和规模。不同的业务场景可能需要不同的ID生成策略和算法。例如，一些系统可能需要生成有序的ID，而另一些系统可能更关注ID的唯一性和性能。</p><p>其次，要注意时钟回拨和并发安全性。时钟回拨可能会导致生成的ID不唯一，因此需要在算法中考虑时钟回拨的情况，并采取相应的措施来处理。同时，要保证在高并发情况下生成的ID是唯一且有序的，可以使用分布式锁等机制来确保并发安全性。</p><p>另外，选择合适的存储和分布式协调服务也是很重要的。不同的存储和分布式协调服务有不同的特性和适用场景，需要根据系统的需求和性能要求来选择合适的服务。</p><p>最后，要考虑系统的扩展性和可维护性。分布式ID生成器需要能够随着系统的扩展而扩展，并且易于部署和维护。因此，设计和实现分布式ID生成器时要考虑到系统的未来发展和维护成本。</p><p>欢迎关注我的公众号“<strong>神笔君</strong>”，原创技术文章第一时间推送。</p><center>    <img src="https://raw.githubusercontent.com/okeeper/blog-images/main/2024/05/16/1715867273785-7c091e0c-9b01-44de-b34a-6ffd0887b01b.jpg" style="width: 100px;"></center>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 分布式ID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch技术架构及原理</title>
      <link href="/hou-duan-jia-gou/elasticsearch-ji-zhu-jia-gou-ji-yuan-li/"/>
      <url>/hou-duan-jia-gou/elasticsearch-ji-zhu-jia-gou-ji-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="elasticsearch介绍"><a class="markdownIt-Anchor" href="#elasticsearch介绍"></a> Elasticsearch介绍</h1><p>Elasticsearch 是一个基于 Apache Lucene 的开源搜索和分析引擎，设计用于云计算中，能够快速地处理大量数据。它可以近实时地进行复杂的查询，并且可以用于全文搜索、结构化搜索以及分析。</p><p>特性：</p><ul><li><p>分布式搜索引擎，可以扩展到上百台服务器，处理PB级的数据。</p></li><li><p>RESTful API，使用JSON进行数据交换。</p></li><li><p>实时分析，可以对数据进行实时分析。</p></li><li><p>高可用性，节点失败时可以自动重分配。</p></li><li><p>近实时，数据被索引后立即可搜索。1s内返回</p></li><li><p>支持各种编程语言。</p></li></ul><h1 id="elasticsearch的原理"><a class="markdownIt-Anchor" href="#elasticsearch的原理"></a> Elasticsearch的原理</h1><p>每一种存储引擎都有自己特定的应用场景，例如Mysql，它更擅长的是事务的操作，事务里面有原子性、持久性、一致性、隔离性这些，因此可以保证数据的安全性、持久化存储、数据一致，但它不适合大量数据的查询和搜索(亿级海量数据)，它底层的存储引擎虽然使用B+ tree索引优化了检索速度，但随着数据量的增大，多次的磁盘IO读写依然会比较慢。此时IO读写将是不可逾越的一大瓶颈。</p><p>Elasticsearch搜索引擎就是为了解决海量数据的搜索和数据检索。那么之所以它适合海量数据的检索，一定有它独特的设计，优化了检索磁盘IO读写过程。</p><h2 id="倒排索引"><a class="markdownIt-Anchor" href="#倒排索引"></a> 倒排索引</h2><p>我们知道数据是放磁盘中的，要对磁盘中海量数据的搜索，一定要为这些数据建立索引数据结构，降低磁盘IO次数。那么ES的索引方式就不是MySQL的B+ tree方式，而是倒排索引。</p><p><strong>倒排索引中有两个非常重要的概念：</strong></p><ul><li>文档（<code>Document</code>）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息</li><li>词条（<code>Term</code>）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条</li></ul><p><strong>倒排索引</strong>简单来说就是通过doc(数据行)的某个字段的词条（Term）对应起doc的id及出现的位置信息等的一种数据结构，例如将下图中的title字段进行分词后映射了每个词条对应的文档id.</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/2729274-20230205171751933-576636800.png" alt></p><p>最终将一个所有表数据维护成了词条和文档id集合的一个映射，这个就是倒排索引。而每个词条对应的文档id集合是按顺序进行存储的，称为posting list. 词条这一列称为Term Dictionary（词项字典）。</p><p>这里有两个问题：</p><ol><li><p>如果一个词条对应的文档id特别多，岂不是要大量的磁盘空间进行存储</p></li><li><p>一般一个文档不单只有一个字段，如果每个字段分别建立了倒排索引，当需要取各个字段的搜索交集时，如何快速实现。</p></li></ol><blockquote><p>一般来讲，一个文档id时long类型的，8byte存储，如果一个词条包含的文档id特别多，成千上万个，例如要所示英文文档中包含&quot;of&quot;单词的所有文档，这是英文中最常见的单词，显然会很多。如果是1千万个id * 8byte/1024 = 78125KB = 76M。这还只是一个词条，实际上词条会很多，每个词条包含的文档数量可能远不止1千万个id，如果直接存储id对搜索来讲会大大增加磁盘空间的占用和后续搜索性能的降低。</p></blockquote><p>为了解决这两个问题，ES想到的是将Posting list进行压缩，ES实现了两种节省空间的压缩算法，一个是<strong>Frame Of Reference（FOR）</strong>，另一个是 **Roaring Bitmaps(RBP) **</p><p>针对不同的文档ID序列会选择不同的压缩算法</p><h3 id="frame-of-referencefor算法"><a class="markdownIt-Anchor" href="#frame-of-referencefor算法"></a> Frame Of Reference（FOR）算法</h3><p>它的核心思想是对于一个有序的doc id列表，只记录从第一个元素依次开始的增量数组，进而达到压缩空间的目的。</p><p>例如有以下一个数组：</p><pre class="highlight"><code class>[73, 300, 302, 332, 343, 372]</code></pre><p>进行增量编码之后：</p><pre class="highlight"><code class>[73, 227, 2, 30, 11, 29]</code></pre><p>那么id的所需的存储空间就由这个增量编码的最大值决定，例如这里的最大值是227，如果采用无符号二进制位表示需要1byte，那么6个数总共压缩之后=6*1byte=6byte</p><p>而原数组的最大值是372，需要2byte, 原数组就需要12byte表示。压缩了一半的空间。那么看起来有一定的压缩率了，能不能进一步压缩呢？</p><p>答案是肯定的，ES在实际实现过程中，会将数组中每255个id进行分组，并在每一个分组中取最大的数值所需的空间大小当成整个分组中每个元素的空间大小。这样每个分组都能尽可能地使用最低存储空间进行存储。例上面这个增量数组，假设如果是按3个元素进行分组。</p><pre class="highlight"><code class>[73, 227, 2], [30, 11, 29]</code></pre><p>对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，所以就给每个元素都分配 8 bits的空间。</p><p>但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，所有给每个元素只分配 5 bits 的空间足矣。</p><p>为了在解码的时候知道这个分组用了多少位，用一个bit来存储所用的bit位数即可。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/es%20FOR%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF.jpg" alt="es FOR编码技术"></p><p>这个就是Frame Of Reference（FOR）编码算法，在Posting list中的文档id步长相差不大的情况下，能够极大地压缩所需的磁盘空间存储。</p><p>当有多个字段的倒排索引需要聚合条件取交集搜索时，从磁盘中加载到内存中进行计算，从最短的数组的最小元素开始遍历，通过有序数组进行跳表搜索(Skip table)其他数组中是否存在即可取得最终的交集。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/Lucene%E8%B7%B3%E8%A1%A8%E8%AE%A1%E7%AE%97%E4%BE%8B%E5%AD%90.jpg" alt="Lucene 跳表例子"></p><p>从上面例子可以看出，使用FOR进行压缩后能够极大降低磁盘所需空间，便于一次性加载到内存中进行聚合计算，但当文档ID数据依然很多，压缩之后依然暂用很多空间时，加载到内存肯定也吃不消。</p><p>这就引出了我们另外一种压缩编码算法，<strong>Roaring Bitmaps</strong></p><h3 id="roaring-bitmapsrbm咆哮位图"><a class="markdownIt-Anchor" href="#roaring-bitmapsrbm咆哮位图"></a> Roaring Bitmaps(RBM)——咆哮位图</h3><p>Bitmap我们知道，它通过一个bit数组，来表示一个有序数组是否在当前bit位中存在元素的一种数据结构，假设有这样一个数组：</p><pre class="highlight"><code class>[3,6,7,10]</code></pre><p>它的最大值是10，就需要10位的bit数组表示，bitmap （位图）来表示为：</p><pre class="highlight"><code class>[0,0,1,0,0,1,1,0,0,1]</code></pre><p>我们用 0 表示角标对应的数字不存在，用 1 表示存在。例如从第一个数组元素1开始，第3个元素为1表示这里有个值是3。</p><p>Roaring Bitmaps(RBM)的原理是，将原始的posting list的Integer Id，32位表示，划分为低16位和高16位两部分，通过计算得知这两部分最大的数值都是65535。</p><p>其效果和ID / 65535 的到<strong>一个商</strong>合<strong>一个余数</strong>效果是一样的。那么将一个有序不重复的ID数组必定能够转换成商合余数都是65535之内的数。</p><p>将商当做key，将余数当做value进行映射起来，就可以将有相同商的聚合到一个value钟，在通过bitmap分别表示key和value。这样可以通过恒定的65535的bit数组表示一个32位的Integer集合，大概是43亿。最终效果如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/74bf2380c19d4a039ca3ce3a2dd09661.png" alt="roaring array"></p><p>用65535位的bitmap标识 keys，用ArrayContrainer或者Bitmap Contrainer来表示每个key对应的values，由于values不管有多少个元素，都用65535位的bitmap标识，当元素较少时，固然也是比较浪费的，计算Bitmap和直接存Integer数组与元素个数的存储空间关系，得到以下临界关系，当元素个数&lt;4096时，用ArrayContrainer直接存Integer原始数值比较省空间，当元素个数&gt;=4096时，使用Bitmap Contraine来存储，存储空间很定在65536 个 bit</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/85a4ddbf2f2845b89818f64fc00d97b3.png" alt></p><p>通过Roaring Bitmaps(RBM)这种数据编码的优化，即使极端情况Posting List由43(2^32)亿个无符号Integer组成的Id数组，其最大所需的存储空间为计算如下：</p><p>65536 个 bit，也就是 65536/8 = 8192 bytes</p><p>8192 bytes * 8192 bytes=65535KB = 64M</p><p>而43亿个整形所需的空间为 2^32 * 4byte = 16384M = 16G，压缩了不是一点半点了。</p><p>而且Bitmap有个好处就是在取多个数组交集的时候，只需要&amp;位运算即可，相当方便，这样就可以将一个极大的有序Posting list一下加载到内存中进行快速计算得出搜索结果。</p><p>到目前为止，我们值将了ES如何优化和压缩Posting list。还有Term Dictionary词项字典是怎么处理的呢，对应上亿级的文档数据，其词项也是相当巨大的，如何在搜索时通过所示关键字(词项)快速找到对应的post list呢？接下来引出Term Index.</p><h2 id="term-index词项索引"><a class="markdownIt-Anchor" href="#term-index词项索引"></a> Term Index（词项索引）</h2><p>为了加快通过关键字快速找到PostingList, ES的思想是在词项字典中建立索引，并将索引缓存在内存中进行极速计算搜索。最终的结构应该如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84.jpg" alt="Lucene倒排索引内部结构"></p><p>那么问题来了，对于一个巨量的词项字典，其词项索引必然也是巨大的，直接加载到内存中肯定不是它的作风。</p><p>对的ES使用的是一种有限状态转换器（Finite StateTransducers 简称 FST）数据结构，将词项字典的前缀和后缀及对应的索引Block块位置构建成一个FST树。</p><p>它是从Trie前缀树演变而来的，其满足前缀树的特性：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/b33b1595505ec3a32774f79eae3dd8b8.png" alt></p><p>1、根节点不包含字符，除根节点外每一个节点都只包含一个字符<br>2、从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串<br>3、每个节点的所有子节点包含的字符都不相同</p><p>而ES实现数据结构是FST（Finite State Transducer）有的不一样，它不但可以表示相同前缀的词典，相同后缀也能表示。它有以下两个优点：</p><ol><li>空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；</li><li>查询速度快。O(len(str))的查询时间复杂度。</li></ol><h3 id="构建过程"><a class="markdownIt-Anchor" href="#构建过程"></a> 构建过程</h3><p>例如：</p><p>我们对“cat”、 “deep”、 “do”、 “dog” 、“dogs”这5个单词进行插入构建FST（注：必须已排序）。</p><ol><li><p>插入“cat”,每个字母形成一条边，其中t边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/e2a43283b890ee417d1680b1e2d15d28.png" alt></p></li><li><p>插入“deep”,与前一个单词“cat”进行最大前缀匹配，发现没有匹配则直接插入，P边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/c11a3bc0faf2d7d5c21f29ce29458c37.png" alt></p></li><li><p>插入“do”,与前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/166c463a70a4e724a788930bfbfe428e.png" alt></p></li><li><p>插入“dog”,与前一个单词“do”进行最大前缀匹配，发现是do，则在o边后增加新边g，g边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/ee27cb44f5171a4936f9f101a17c31ff.png" alt></p></li><li><p>插入“dogs”, 与前一个单词“dog”进行最大前缀匹配，发现是dog，则在g后增加新边s，s边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/075af4c74246952f99fa0876c583b7d1.png" alt></p><p>有了这个索引结构，就能很方便地在内存中快速查找posting list，进行进一步的快速搜索。</p><p>关于FST这里有个在线的算法演示网站，感兴趣的可以点开玩玩方便理解：<a href="http://examples.mikemccandless.com/fst.py?terms=&amp;cmd=Build+it%21" target="_blank" rel="noopener">http://examples.mikemccandless.com/fst.py?terms=&amp;cmd=Build+it!</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240605145158758.png" alt="image-20240605145158758"></p></li></ol><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><h2 id="为什么-elasticsearchlucene-检索可以比-mysql-快"><a class="markdownIt-Anchor" href="#为什么-elasticsearchlucene-检索可以比-mysql-快"></a> 为什么 Elasticsearch/Lucene 检索可以比 mysql 快</h2><ol><li><p>Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次随机 IO 的磁盘操作。</p></li><li><p>而 ES 在 term dictionary 的基础上添加了term index来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access （随机IO）次数。</p></li><li><p>ES在Posting List存储时，通过Frame Of Reference（FOR）和Roaring Bitmaps(RBM)的编码压缩，可以实现海量数据的存储而不再用太大的空间，大大节省了磁盘空间，进而检索了搜索时的随机IO次数。再者由于压缩的存在，使得可以一次性加载至内存中进行快速计算。</p></li></ol><p>以上就是ES之所能在海量数据搜索中快的核心技术。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> Elasticsearch </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能时代的技术底座：向量数据库</title>
      <link href="/ren-gong-zhi-neng/xiang-liang-shu-ju-ku/"/>
      <url>/ren-gong-zhi-neng/xiang-liang-shu-ju-ku/</url>
      
        <content type="html"><![CDATA[<h1 id="一-什么是向量"><a class="markdownIt-Anchor" href="#一-什么是向量"></a> 一、什么是向量</h1><p>随着ChatGPT的爆火，其embedding背后的向量检索技术让大家熟知。事实上，向量数据库并非近两年才出现的新技术，它已经存在了很长时间了。要了解什么是向量数据库，我们先来了解下什么是向量。</p><h2 id="向量的概念"><a class="markdownIt-Anchor" href="#向量的概念"></a> 向量的概念</h2><p>向量最初是数学和物理学中的一个基本概念，他表示既有大小又有方向的量，它与只有大小没有方向的标量（如温度、质量和长度）相对应。</p><p>在数学中，向量（也称为欧几里得向量、几何向量、矢量），指具有大小（magnitude）和方向的量。它可以形象化地表示为带箭头的线段。箭头所指：代表向量的方向；线段长度：代表向量的大小。与向量对应的只有大小，没有方向的量叫做数量（物理学中称标量）。　　如果用Rn表示n个实数的有序集，Rn中的一个向量就是一个n元有序组，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">R</mi><mi>n</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mrow><mo fence="true">(</mo><msub><mi>χ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>χ</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>χ</mi><mn>3</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>χ</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow><mo>∣</mo><msub><mi>χ</mi><mi>i</mi></msub><mo>∈</mo><mi mathvariant="normal">R</mi><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm {R}_n = \left \{ \left (\chi_{1} , \chi_{2},\chi_{3}, ...\chi_{n} \right )\mid  \chi_{i}\in \mathrm {R} \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathrm">R</span></span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span>　　向量的记法：印刷体记作粗体的字母（如a、b、u、v），书写时在字母顶上加一小箭头“→”。如果给定向量的起点（A）和终点（B），可将向量记作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mrow><mi>A</mi><mi>B</mi></mrow><mo stretchy="true">→</mo></mover></mrow><annotation encoding="application/x-tex">\overrightarrow{AB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20533em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.20533em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span class="svg-align" style="top:-3.6833299999999998em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em;"><svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67 151.7 139 205zm0 0v40h399900v-40z"/></svg></span></span></span></span></span></span></span></span></span><br>。实际上向量有多种记法，可以用元组表示一个向量，如 (x1, x2) 或 &lt; x1, x2&gt;。在线性代数中，n元向量可以用n×1矩阵表示，如：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">V</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>3</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>4</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>5</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mtext> 或 </mtext><msup><mi mathvariant="bold">V</mi><mi>T</mi></msup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="left left left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>3</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>4</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>5</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{V}=\left[\begin{array}{l}x_{1} \\x_{2} \\x_{3} \\x_{4} \\x_{5}\end{array}\right] \text { 或 } \mathbf{V}^{T}=\left[\begin{array}{lllll}x_{1} &amp; x_{2} &amp; x_{3} &amp; x_{4} &amp; x_{5}\end{array}\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:6.00503em;vertical-align:-2.75004em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2549900000000003em;"><span style="top:-1.0499800000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.1999800000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.79598em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.39198em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.9879800000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.0139700000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.25499em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75004em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2500000000000004em;"><span style="top:-5.410000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999998em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.6099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.7500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2549900000000003em;"><span style="top:-1.0499800000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.1999800000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.79598em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.39198em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.9879800000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.0139700000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.25499em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75004em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">或</span><span class="mord"> </span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span></span></p><p>向量中的每个元素xn，都称作向量的一个分量。</p><h2 id="向量的特点"><a class="markdownIt-Anchor" href="#向量的特点"></a> 向量的特点</h2><ul><li>方向和大小：向量不仅有大小，还有方向，这与普通的数（标量）不同，标量只有大小，没有方向。</li><li>可在空间中表示：向量可以在一维、二维、三维或更高维的空间中表示。</li><li>可相加减和数乘：向量之间可以进行加法、减法操作，也可以与标量进行乘法操作，遵循平行四边形法则和三角形法则。</li><li>向量空间：向量可以构成向量空间，向量空间内的向量可以通过向量加法和标量乘法的组合进行线性组合。</li></ul><h2 id="数的向量化表示对计算机运算的便利性"><a class="markdownIt-Anchor" href="#数的向量化表示对计算机运算的便利性"></a> 数的向量化表示对计算机运算的便利性</h2><ul><li>高效存储和处理：计算机通过向量化表示可以更高效地存储和处理大量数据。向量化可以减少循环和迭代计算，利用现代处理器的向量化指令集进行并行处理。</li><li>简化计算：数学运算，尤其是线性代数运算，在向量化表示下可以大大简化，<strong>因为可以利用矩阵乘法等操作直接处理整个数据集合，而不是单独处理每个数据点</strong>。</li><li>机器学习和深度学习：在机器学习和深度学习中，数据通常以向量、矩阵和张量的形式表示。向量化使得算法的实现更加直观，同时可以利用高度优化的数学库（如NumPy、TensorFlow、PyTorch）进行高效计算。</li><li>图形处理：在计算机图形处理中，向量化表示允许快速计算和渲染图形，比如在3D建模、动画和视频游戏开发中的应用。</li></ul><h2 id="机器学习中为什么使用向量"><a class="markdownIt-Anchor" href="#机器学习中为什么使用向量"></a> 机器学习中为什么使用向量</h2><p>在计算机世界中，向量的使用普遍且多样，特别是在机器学习中，向量用来描述特征有其独到之处和优势：</p><h3 id="1-数据表示的统一性和通用性"><a class="markdownIt-Anchor" href="#1-数据表示的统一性和通用性"></a> 1. 数据表示的统一性和通用性</h3><ul><li>统一性：使用向量来描述特征可以将不同类型的数据（数值、类别、文本等）转化为统一的数学表示形式。这种统一性使得算法能够处理多种类型的数据，而不需要根据数据类型改变算法逻辑。</li><li>通用性：向量化的数据可以被各种机器学习算法接受，从简单的线性回归到复杂的深度学习模型，都可以处理向量形式的输入数据。</li></ul><h3 id="2-高效的计算和存储"><a class="markdownIt-Anchor" href="#2-高效的计算和存储"></a> 2. 高效的计算和存储</h3><ul><li>高效计算：现代计算机和特定硬件（如GPU）对于向量和矩阵运算进行了优化，使得与向量相关的计算特别高效。这意味着使用向量来描述特征可以显著加快机器学习算法的训练和预测过程。</li><li>高效存储：向量化的数据可以通过紧凑的格式存储，减少内存占用，并且便于数据的快速读取和传输。</li></ul><h3 id="3-算法性能的提升"><a class="markdownIt-Anchor" href="#3-算法性能的提升"></a> 3. 算法性能的提升</h3><ul><li>特征工程：通过将特征向量化，数据科学家可以应用各种特征工程技术（如特征选择、特征提取、维度缩减）来提升模型性能。</li><li>模型精度：向量化的特征表示允许模型捕捉到数据中的复杂模式和关系，从而提高模型的精度和泛化能力。</li></ul><h3 id="4-灵活性和扩展性"><a class="markdownIt-Anchor" href="#4-灵活性和扩展性"></a> 4. 灵活性和扩展性</h3><ul><li>灵活性：向量表示的特征可以容易地扩展或修改，以适应模型的需要。例如，可以通过添加更多的维度来引入新的特征，而不需要对现有的数据处理流程或模型架构进行大的改动。</li><li>扩展性：对于大规模的数据集，向量化的表示方法可以有效地支持并行计算和分布式计算，从而使得处理大数据变得可行。</li></ul><h3 id="5-兼容性与集成性"><a class="markdownIt-Anchor" href="#5-兼容性与集成性"></a> 5. 兼容性与集成性</h3><ul><li>软件库和工具：几乎所有的机器学习和深度学习库（如scikit-learn、TensorFlow、PyTorch）都是围绕向量和矩阵运算设计的。使用向量来描述特征使得这些工具可以直接应用，无需进行数据格式转换。</li><li>集成性：向量化的特征可以方便地与其他数据处理和分析工具集成，如数据可视化、统计分析等，为整个数据处理和机器学习流程提供支持。</li></ul><h2 id="举例"><a class="markdownIt-Anchor" href="#举例"></a> 举例</h2><p>例如电影推荐系统中<br>假设我们正在构建一个电影推荐系统，我们希望根据用户的历史观影记录和电影的属性来推荐用户可能感兴趣的电影。</p><p>让我们细化一下电影推荐系统中电影特征向量化和用户特征向量化的过程，以便更深入理解这一概念。</p><h3 id="电影特征向量化的细化"><a class="markdownIt-Anchor" href="#电影特征向量化的细化"></a> 电影特征向量化的细化</h3><p>假设我们有以下电影特征进行向量化：</p><ol><li><p><strong>数值特征</strong>：</p><ul><li>电影长度（分钟）：一个直接的数值，比如<code>120</code>。</li><li>发布年份：一个数值，比如<code>2020</code>。</li></ul></li><li><p><strong>类别特征</strong>（电影类型）：</p><ul><li>假设我们有5种类型：动作、喜剧、科幻、爱情、惊悚。</li><li>电影《X》是动作和科幻类型，所以它的类型特征向量可以是<code>[1, 0, 1, 0, 0]</code>，表示动作和科幻为<code>1</code>，其他为<code>0</code>。</li></ul></li><li><p><strong>文本特征</strong>（电影描述）：</p><ul><li>电影《X》的描述：“一个未来的英雄战斗以拯救世界。”</li><li>使用TF-IDF或词嵌入技术将这段文本转换为固定长度的向量，例如，一个长度为<code>N</code>的向量<code>[0.5, 0.1, ..., 0.0]</code>，每个元素代表文本中一个特定词或概念的重要性。</li></ul></li></ol><h3 id="用户特征向量化的细化"><a class="markdownIt-Anchor" href="#用户特征向量化的细化"></a> 用户特征向量化的细化</h3><p>对于用户，我们可能会有如下特征进行向量化：</p><ol><li><p><strong>用户偏好</strong>：</p><ul><li>假设基于用户过去的评分记录，我们得出用户喜欢动作和科幻类型的电影。</li><li>用户的偏好向量可能类似于电影的类型向量，如<code>[0.8, 0.2, 0.7, 0.1, 0.0]</code>，表示用户偏好动作和科幻类型的电影，数值越高表示偏好程度越大。</li></ul></li><li><p><strong>评分活动</strong>：</p><ul><li>用户评分次数：一个数值，比如<code>50</code>次。</li><li>平均评分：另一个数值，比如<code>4.2</code>。</li></ul></li><li><p><strong>观影频率</strong>：</p><ul><li>根据用户的观影记录，我们可以计算出用户每月的观影频率，比如<code>8</code>部电影/月，这也可以转化为一个数值特征。</li></ul></li></ol><h3 id="综合向量表示"><a class="markdownIt-Anchor" href="#综合向量表示"></a> 综合向量表示</h3><ul><li><strong>电影向量</strong>：将数值特征、类别特征和文本特征的向量合并，形成一个综合的电影特征向量。例如，如果我们将所有特征合并，对于电影《X》，它的特征向量可能是<code>[120, 2020, 1, 0, 1, 0, 0, 0.5, 0.1, ..., 0.0]</code>，前面部分代表数值和类别特征，后面部分是文本特征转化来的向量。</li><li><strong>用户向量</strong>：同样地，将用户的偏好、评分活动和观影频率合并成一个综合的用户特征向量，例如<code>[0.8, 0.2, 0.7, 0.1, 0.0, 50, 4.2, 8]</code>。</li></ul><p>综合特征向量化后，我们可以通过计算向量之间的相似度来找到电影与用户偏好之间的相关性。这是机器学习和推荐系统中的一个常见步骤，它帮助我们理解和量化项目（如电影）与用户之间的匹配程度。以下是几种常用的相似度计算方法：</p><h4 id="1-余弦相似度consine"><a class="markdownIt-Anchor" href="#1-余弦相似度consine"></a> 1. 余弦相似度(CONSINE)</h4><p>余弦相似度是衡量两个向量在方向上的相似度，忽略它们的大小。它的值范围从-1（完全相反）到1（完全相同），0表示两个向量之间没有相关性。即计算向量空间中两个点的夹角大小，夹角越小，相似度越高，公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><mtext>余弦相似度</mtext><mo>=</mo><mfrac><mrow><mi mathvariant="bold">A</mi><mo>⋅</mo><mi mathvariant="bold">B</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">A</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">B</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[ \text{余弦相似度} = \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| |\mathbf{B}|} ]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord text"><span class="mord cjk_fallback">余弦相似度</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.29911em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36311em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathbf">A</span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord"><span class="mord mathbf">B</span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">]</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 是两个向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo>⋅</mo><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{A} \cdot \mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 是向量的点积，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">A</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\|\mathbf{A}\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathbf">A</span></span><span class="mord">∥</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">B</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\|\mathbf{B}\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathbf">B</span></span><span class="mord">∥</span></span></span></span> 是向量的欧几里得范数（即向量的长度）。</p><h4 id="2-欧几里得距离欧氏距离l2"><a class="markdownIt-Anchor" href="#2-欧几里得距离欧氏距离l2"></a> 2. 欧几里得距离（欧氏距离）(L2)</h4><p>欧几里得距离（或称欧式距离）测量的是两个向量在多维空间中的“直线”距离。距离越小，相似度越高。公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>欧几里得距离</mtext><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo>−</mo><msub><mi>B</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\text{欧几里得距离} = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">欧几里得距离</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em;"><span class="svg-align" style="top:-5.116816em;"><span class="pstrut" style="height:5.116816em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em;"><span class="pstrut" style="height:5.116816em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.196816em;"><svg width="400em" height="3.196816em" viewbox="0 0 400000 3196" preserveaspectratio="xMinYMin slice"><path d="M702 80H40000040H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">A_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">B_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 个维度上的值。</p><h4 id="3-内积ip"><a class="markdownIt-Anchor" href="#3-内积ip"></a> 3. 内积(IP)</h4><p>两个嵌入之间的IP距离定义如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/IP_formula.png" alt="ip"></p><p>如果您需要比较非标准化数据或当您关心幅度和角度时，IP 会更有用。如果您使用 IP 来计算嵌入相似度，则必须对嵌入进行标准化。归一化后，内积等于余弦相似度。</p><p>假设 X’ 通过嵌入 X 进行归一化：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/normalize_formula.png" alt="正常化"></p><p>两个embedding之间的相关性如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/normalization_formula.png" alt="正常化"></p><h4 id="4-曼哈顿距离"><a class="markdownIt-Anchor" href="#4-曼哈顿距离"></a> 4. 曼哈顿距离</h4><p>曼哈顿距离（或城市街区距离）测量的是在标准坐标系统中从一个点到另一个点的距离，只沿着坐标轴方向计算。公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>曼哈顿距离</mtext><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mi>i</mi></msub><mo>−</mo><msub><mi>B</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex"> \text{曼哈顿距离} = \sum_{i=1}^{n} |A_i - B_i| </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">曼哈顿距离</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span></p><p>这种方法在某些情况下比欧几里得距离更有意义，尤其是在维度非常高时。</p><h3 id="应用示例"><a class="markdownIt-Anchor" href="#应用示例"></a> 应用示例</h3><p>假设我们有一个用户的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和两部电影的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></mrow><annotation encoding="application/x-tex">\mathbf{M2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">2</span></span></span></span></span>。我们可以使用上述任何一种方法来计算用户向量与每部电影向量之间的相似度。</p><ul><li>如果我们使用<strong>余弦相似度</strong>，我们可能会发现 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 之间的相似度为 0.9（非常相似），而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></mrow><annotation encoding="application/x-tex">\mathbf{M2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">2</span></span></span></span></span> 之间的相似度为 0.3（不太相似）。基于这些结果，推荐系统会倾向于推荐 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 给用户。</li></ul><p>这个计算过程不仅适用于个性化推荐，还可用于聚类分析（将相似的电影或用户分为组）、异常检测（识别与大多数用户或项目显著不同的情况）等任务。</p><p>通过这种方式，机器学习模型可以根据综合特征向量的相似度，有效地识别并推荐用户可能感兴趣的电影，实现个性化推荐。</p><h1 id="二-向量数据库"><a class="markdownIt-Anchor" href="#二-向量数据库"></a> 二、向量数据库</h1><p>目前市场上存在许多向量数据库产品。从国内和国外两个维度来看，国内有</p><ul><li>Milvus</li><li>京东的VEARCH</li><li>蚂蚁金服的ZSearch等产品。</li></ul><p>Milvus是目前向量数据库赛道里较为热门的产品，而京东和蚂蚁更多的是将它们的应用于内部场景，外部使用较少。</p><p>在海外来看，大公司都有自己的向量数据库产品，比较知名的有如Qdrant和Weaviate等等。此外，Pinecone是目前商业向量数据库市场最热门的产品。国内的商业数据库产品有联汇和爱可生自己开发的向量数据库产品，当然这些产品都是基于开源产品进行包装的。</p><p>从三个维度来看，这些向量数据库可以分为：向量检索库、向量插件和向量字段。</p><ul><li>在检索库方面有Meta的Faiss、微软的SPTAG，谷歌的ScaNN等等。</li><li>插件方面包括ES、OpenSearch和PG等产品中都集成了向量的特性。</li><li>而向量字段则是数据库本身集成的向量特性，但功能相对较弱。</li></ul><h2 id="向量数据库的原理"><a class="markdownIt-Anchor" href="#向量数据库的原理"></a> 向量数据库的原理</h2><p>前面我们介绍到，计算向量空间中两个点的相似度可以使用<code>余弦相似度</code>、<code>欧几里得距离</code>、<code>曼哈顿距离</code>等。一般向量数据库常用的为前两种。</p><p>把空间向量两点的值带入公式即可得出一个数值，当两点之间的计算结果符合这个阈值，我们只需要设定一个相似度阈值我们就认为是相似度较高的。</p><h2 id="向量索引"><a class="markdownIt-Anchor" href="#向量索引"></a> 向量索引</h2><p>当需要检索匹配的数据巨大时，如果将输入的点和巨大的目标集合进行挨个比较计算，这个计算量是无法承受的，因此我们引入了一个概念叫向量索引。</p><blockquote><p>向量索引（vector index）：是指通过某种数学模型，对向量构建的一种时间和空间上比较高效的数据结构。借助向量索引，我们能够高效地查询与目标向量相似的若干个向量</p></blockquote><p>说白了就是牺牲一定的准确度来加快检索的效率的一种索引数据结构。</p><h3 id="向量索引类型"><a class="markdownIt-Anchor" href="#向量索引类型"></a> 向量索引类型：</h3><ol><li><p><strong>FLAT (FLAT)</strong>: 一个基本的线性索引，对数据库中的每个项进行全面扫描，以找到最近的邻居。虽然准确度高，但随着数据量的增加，搜索效率较低。</p></li><li><p><strong>IVF_FLAT (Inverted File with FLAT)</strong>: 使用倒排文件（IVF）将数据分割成多个桶（或称为聚类），在查询时首先确定查询向量所属的桶，然后在该桶内进行FLAT搜索。这种方法提高了搜索速度，但牺牲了一定的精度。<br>IVF_FLAT（Inverted File with FLAT）索引是一种用于加速向量搜索的技术，特别适用于高维空间的近似最近邻（ANN）搜索。它结合了倒排索引（Inverted File）和暴力搜索（FLAT）的特点，通过预先聚类减少搜索过程中需要比较的向量数量，从而加速查询过程。其基本原理如下：</p><p><strong>预处理阶段</strong>：</p><p>聚类：首先，IVF_FLAT对数据库中的所有向量进行聚类操作，通常使用k-means算法。每个聚类中心（或称为质心）代表了一个向量的聚类。<br>建立倒排索引：然后，为每个聚类建立一个倒排列表（或称桶），桶中存储属于该聚类中心的所有向量的索引。这样，每个向量就被分配到了一个与之最近的聚类中心对应的桶里。<br><strong>搜索阶段</strong>：</p><p>当进行向量搜索查询时，IVF_FLAT首先确定查询向量与哪个或哪些聚类中心最接近。<br>然后，只在与这些最近的聚类中心对应的倒排列表中的向量进行暴力搜索（FLAT），而不是在整个数据库中搜索。<br>通过这种方式，搜索过程被限制在一小部分相关向量中，显著减少了计算量。</p></li><li><p><strong>IVF_SQ8 (Inverted File with Scalar Quantization)</strong>: 在IVF的基础上，使用标量量化（SQ8）对向量进行压缩，进一步提高存储和搜索效率，同时牺牲了一定的搜索准确度。</p></li><li><p><strong>IVF_PQ (Inverted File with Product Quantization)</strong>: 利用产品量化（PQ）技术对向量进行编码和压缩，以减少内存占用并加速搜索。它在保持相对较高搜索质量的同时，大大提高了搜索速度。</p></li><li><p><strong>GPU_IVF_FLAT/GPU_IVF_PQ</strong>: 这些是IVF_FLAT和IVF_PQ索引的GPU版本，利用GPU的并行计算能力来加速搜索过程。</p></li><li><p><strong>HNSW (Hierarchical Navigable Small World)</strong>: 基于小世界网络的一种图索引，提供了高效的近似最近邻搜索，特别是在高维数据集上效果显著。</p></li><li><p><strong>DISKANN (Disk-based Approximate Nearest Neighbor)</strong>: 一种旨在大规模数据集上运行的索引，优化了磁盘存储和搜索速度，适用于不能完全加载到内存中的大数据集。</p></li><li><p><strong>BIN_FLAT (Binary FLAT)</strong>: 对二进制向量执行全面扫描的基本索引，类似于浮点数向量的FLAT索引，但专为处理二进制数据设计。</p></li><li><p><strong>BIN_IVF_FLAT (Binary Inverted File with FLAT)</strong>: 结合了倒排索引和二进制数据的特性，先将数据分割成多个桶，然后在查询时仅在特定的桶内进行搜索，适用于二进制向量数据。</p></li></ol><p>这些索引类型各有优势和适用场景，选择合适的索引类型需要根据具体的应用需求、数据特性和资源限制来决定。例如，对于需要高准确度的应用，可能会选择FLAT或HNSW索引；而对于大规模数据集，可能会选择IVF_PQ或DISKANN以平衡搜索速度和准确度。</p><h1 id="向量数据库milvus使用"><a class="markdownIt-Anchor" href="#向量数据库milvus使用"></a> 向量数据库Milvus使用</h1><p>Milvus国内比较火，社区比较活跃的一个向量数据库，本地免费使用，他也有Cloud云版本，无需自己运维。</p><p>下图是这个Milvus数据库的架构图，这其实是一个经典的分布式系统。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/architecture_02.jpg" alt="建筑学"></p><p>可以看出他最大的特点是存储和计算分离，每一部分都可弹性伸缩切都是无状态的，这是一个典型的分布式系统架构设计。</p><h2 id="milvus的docker安装"><a class="markdownIt-Anchor" href="#milvus的docker安装"></a> Milvus的docker安装</h2><p>Milvus有单机和集群版之分，小规模应用对可靠性没要求的直接使用单机版就够了</p><p>新建一个<code>docker-compose.yml</code>内容如下，包含了元数据中心、存储引擎、单机版Milvus以及图形化界面管理工具Attu,其中图形化管理工具是选择性安装的，其他的事必须要有的</p><pre class="highlight"><code class>version: '3.5'services:  # 元数据注册中心，用于管理 Milvus 内部组件的元数据访问和存储，例如：proxy、index node 等。  etcd:    container_name: milvus-etcd    # 生产环境用这个    #image: rancher/coreos-etcd:v3.4.16-rancher1    image: quay.io/coreos/etcd:v3.5.0    environment:      - ETCD_AUTO_COMPACTION_MODE=revision      - ETCD_AUTO_COMPACTION_RETENTION=1000      - ETCD_QUOTA_BACKEND_BYTES=4294967296      - ETCD_SNAPSHOT_COUNT=50000    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd  #  是存储引擎，负责维护 Milvus 的数据持久化, console界面 http://localhost:9001  minio:    container_name: milvus-minio    image: minio/minio:RELEASE.2022-03-17T06-34-49Z    environment:      MINIO_ACCESS_KEY: minioadmin      MINIO_SECRET_KEY: minioadmin    ports:      - &quot;9001:9001&quot;    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data    command: minio server /minio_data --console-address &quot;:9001&quot;    healthcheck:      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9000/minio/health/live&quot;]      interval: 30s      timeout: 20s      retries: 3  # 单机版 Milvus  standalone:    container_name: milvus-standalone    image: milvusdb/milvus:v2.2.2    command: [&quot;milvus&quot;, &quot;run&quot;, &quot;standalone&quot;]    environment:      ETCD_ENDPOINTS: etcd:2379      MINIO_ADDRESS: minio:9000    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus    ports:      - &quot;19530:19530&quot;      - &quot;9091:9091&quot;    depends_on:      - &quot;etcd&quot;      - &quot;minio&quot;  # 图形界面管理工具，http://localhost:8000  attu:    container_name: attu    image: zilliz/attu:v2.2.3    environment:      MILVUS_URL: milvus-standalone:19530    ports:      - &quot;8000:3000&quot;    depends_on:      - &quot;standalone&quot;networks:  default:    name: milvus</code></pre><p>直接启动</p><pre class="highlight"><code class="shell">cd ./milvussudo docker-compose up -d</code></pre><p>启动成功后看下图形界面是否能够进去<br><a href="http://localhost:8000" target="_blank" rel="noopener">http://localhost:8000</a></p><h2 id="管理-milvus-连接"><a class="markdownIt-Anchor" href="#管理-milvus-连接"></a> 管理 Milvus 连接</h2><pre class="highlight"><code class>from pymilvus import connectionsconnections.connect(  alias=&quot;default&quot;,  uri=&quot;localhost:19530&quot;,  #token=&quot;root:Milvus&quot;,  user=&quot;&quot;,  password=&quot;&quot;)</code></pre><p>在全局调用一次connect就好了，接下来就可以使用SDK直接操作里面的database、collection</p><h2 id="管理database"><a class="markdownIt-Anchor" href="#管理database"></a> 管理Database</h2><p>默认情况下，让我们不显示创建和指定数据库时，默认使用的就是<code>default</code><br>您也可以在 Milvus 中创建数据库，并为某些用户分配权限来管理它们。那么这些用户就有权管理数据库中的集合。一个 Milvus 集群最多支持 64 个数据库。</p><pre class="highlight"><code class>from pymilvus import connections, dbconn = connections.connect(host=&quot;127.0.0.1&quot;, port=19530)database = db.create_database(&quot;book&quot;)</code></pre><p>使用它</p><pre class="highlight"><code class>db.using_database(&quot;book&quot;)</code></pre><p>您还可以设置连接到 Milvus 集群时使用的数据库，如下所示：</p><pre class="highlight"><code class>conn = connections.connect(    host=&quot;127.0.0.1&quot;,    port=&quot;19530&quot;,    db_name=&quot;default&quot;)</code></pre><h2 id="collection集合管理"><a class="markdownIt-Anchor" href="#collection集合管理"></a> Collection集合管理</h2><pre class="highlight"><code class>from pymilvus import Collection, FieldSchema, CollectionSchema, DataType, connections, utilityconnections.connect(alias=&quot;default&quot;)schema = CollectionSchema(fields=[...     FieldSchema(&quot;int64&quot;, DataType.INT64, description=&quot;int64&quot;, is_primary=True),...     FieldSchema(&quot;float_vector&quot;, DataType.FLOAT_VECTOR, is_primary=False, dim=128),... ])collection = Collection(name=&quot;old_collection&quot;, schema=schema)utility.rename_collection(&quot;old_collection&quot;, &quot;new_collection&quot;) # Output: Trueutility.drop_collection(&quot;new_collection&quot;)utility.has_collection(&quot;new_collection&quot;) # Output: False</code></pre><p>你也可以在不存在时创建集合，并创建向量索引，在存在时加载，代码如下：</p><pre class="highlight"><code class="python"> <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_milvus_collection</span>(<span class="hljs-params">self, collection_name</span>):        <span class="hljs-comment"># utility.drop_collection(collection_name)</span>        has = utility.has_collection(collection_name)        logger.info(<span class="hljs-string">f&quot;Does collection <span class="hljs-subst">{collection_name}</span> exist in Milvus: <span class="hljs-subst">{has}</span>&quot;</span>)        embeddings_model_dim = EMBEDDING_MODEL_MAPPING[self.embed_model]        <span class="hljs-comment"># 判断是否存在</span>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> has:            fields = [                FieldSchema(name=<span class="hljs-string">&quot;id&quot;</span>, dtype=DataType.INT64, is_primary=<span class="hljs-literal">True</span>, auto_id=<span class="hljs-literal">True</span>),                FieldSchema(name=<span class="hljs-string">&quot;doc_id&quot;</span>, dtype=DataType.INT64),                FieldSchema(name=<span class="hljs-string">&quot;random&quot;</span>, dtype=DataType.DOUBLE),                FieldSchema(name=<span class="hljs-string">&quot;chunk&quot;</span>, dtype=DataType.VARCHAR, max_length=<span class="hljs-number">2048</span>),                FieldSchema(name=<span class="hljs-string">&quot;embeddings&quot;</span>, dtype=DataType.FLOAT_VECTOR, dim=embeddings_model_dim),                <span class="hljs-comment">#FieldSchema(name=&quot;embedding_model&quot;, dtype=DataType.VARCHAR, max_length=50),</span>            ]            schema = CollectionSchema(fields, <span class="hljs-string">&quot;hello_milvus is the simplest demo to introduce the APIs&quot;</span>)            collection = Collection(collection_name, schema, consistency_level=<span class="hljs-string">&quot;Strong&quot;</span>)            index_params = {                <span class="hljs-string">&quot;index_type&quot;</span>: <span class="hljs-string">&quot;IVF_FLAT&quot;</span>,  <span class="hljs-comment"># FLAT、IVF_FLAT、IVF_PQ、IVF_SQ8、ANNOY 和 HNSW</span>                <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>,                <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nlist&quot;</span>: <span class="hljs-number">128</span>},            }            collection.create_index(<span class="hljs-string">&quot;embeddings&quot;</span>, index_params)            logger.info(<span class="hljs-string">f&quot;Dose not exists collection <span class="hljs-subst">{collection_name}</span>, has create it.&quot;</span>)        <span class="hljs-keyword">else</span>:            collection = Collection(collection_name)            collection.load()        <span class="hljs-keyword">return</span> collection</code></pre><p>其中的</p><pre class="highlight"><code class> index_params = {                &quot;index_type&quot;: &quot;IVF_FLAT&quot;,  # FLAT、IVF_FLAT、IVF_PQ、IVF_SQ8、ANNOY 和 HNSW                &quot;metric_type&quot;: &quot;L2&quot;,                &quot;params&quot;: {&quot;nlist&quot;: 128},            }</code></pre><p>就是之前提到的向量索引的配置，<code>index_type</code>表示采用索引的类型，要根据数据集的大小和使用场景进行选择，一般数据量较小可以采用全量暴力检索FLAT可以提高搜索精度，如果数据量很大可以采用IVF_FLAT在精度和搜索效率上做个权衡。<code>metric_type</code>检索时使用的相似度算法，可选的有L2（欧几里德距离）、IP（内积）<br>、COSINE（余弦相似度），注意不同的index_type可能支持的metric_type略有不同，params是不同的index_type下的扩展参数，例如这里选的<code>IVF_FLAT</code>,params中的nlist则表示将数据集预处理成多少个聚类，每个聚类有一个聚类中心，当要检索目标输入时直接到与之最相近的聚类中查找即可，详细的参数配置和说明请参考官方文档详细说明：<a href="https://milvus.io/docs/index.md" target="_blank" rel="noopener">https://milvus.io/docs/index.md</a></p><h2 id="数据管理"><a class="markdownIt-Anchor" href="#数据管理"></a> 数据管理</h2><h3 id="输入插入"><a class="markdownIt-Anchor" href="#输入插入"></a> 输入插入</h3><pre class="highlight"><code class="python"> <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_to_milvus</span>(<span class="hljs-params">self, embedding_result: []</span>):        collection = self.get_milvus_collection()        <span class="hljs-comment"># 这里是个二维数组，第一维度对应集合中的每一个字段定义，除了自增的字段之外都要有相应的值</span>        entities = [            [embedding_result[i][<span class="hljs-string">&quot;doc_id&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field doc_id</span>            [<span class="hljs-built_in">float</span>(random.randrange(-<span class="hljs-number">20</span>, -<span class="hljs-number">10</span>)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field random</span>            [embedding_result[i][<span class="hljs-string">&quot;chunk&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field chunk</span>            [embedding_result[i][<span class="hljs-string">&quot;embeddings&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field embeddings</span>        ]        insert_result = collection.insert(entities)        logger.info(<span class="hljs-string">f&quot;insert_result <span class="hljs-subst">{insert_result.primary_keys}</span>&quot;</span>)        <span class="hljs-comment"># After final entity is inserted, it is best to call flush to have no growing segments left in memory</span>        collection.flush()</code></pre><h3 id="数据删除"><a class="markdownIt-Anchor" href="#数据删除"></a> 数据删除</h3><pre class="highlight"><code class="python">     <span class="hljs-keyword">def</span> <span class="hljs-title function_">delete_embeddings</span>(<span class="hljs-params">self, doc_ids: [<span class="hljs-built_in">int</span>]</span>):        collection = self.get_milvus_collection()        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:            query_res = collection.query(expr=<span class="hljs-string">&#x27;doc_id in &#x27;</span> + <span class="hljs-built_in">str</span>(doc_ids), output_fields=[<span class="hljs-string">&quot;id&quot;</span>], limit=<span class="hljs-number">30</span>)            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(query_res) == <span class="hljs-number">0</span>:                logger.warning(<span class="hljs-string">f&quot;Delete_embeddings entity is empty: doc_ids:<span class="hljs-subst">{doc_ids}</span>&quot;</span>)                <span class="hljs-keyword">break</span>            ids = []            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(query_res)):                ids.append(query_res[i].get(<span class="hljs-string">&#x27;id&#x27;</span>))            res = collection.delete(expr=<span class="hljs-string">&#x27;id in &#x27;</span> + <span class="hljs-built_in">str</span>(ids))            logger.info(<span class="hljs-string">f&quot;Delete_embeddings success: doc_ids:<span class="hljs-subst">{doc_ids}</span>, res: <span class="hljs-subst">{res}</span>&quot;</span>)        collection.flush()</code></pre><h3 id="查询数据"><a class="markdownIt-Anchor" href="#查询数据"></a> 查询数据</h3><p>查找与目标字符串相近的字符串chunk</p><pre class="highlight"><code class="python">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search_embeddings</span>(<span class="hljs-params">self, doc_ids: [<span class="hljs-built_in">int</span>], intput_text: <span class="hljs-built_in">str</span>, top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span></span>):        collection = self.get_milvus_collection()        vectors_to_search = self.get_embeddings_obj().embed_query(intput_text)        logger.info(<span class="hljs-string">f&#x27;search <span class="hljs-subst">{intput_text}</span> vectors success.&#x27;</span>)        search_params = {            <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>,            <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nprobe&quot;</span>: <span class="hljs-number">128</span>},        }        search_result = collection.search([vectors_to_search], <span class="hljs-string">&quot;embeddings&quot;</span>,                                   search_params,                                   limit=top_k,                                   output_fields=[<span class="hljs-string">&quot;chunk&quot;</span>, <span class="hljs-string">&quot;id&quot;</span>],                                   expr=<span class="hljs-string">&#x27;doc_id in &#x27;</span> + <span class="hljs-built_in">str</span>(doc_ids)                                   )        logger.info(<span class="hljs-string">f&#x27;<span class="hljs-subst">{intput_text}</span> search_embeddings_result&gt;&gt;&gt; <span class="hljs-subst">{search_result}</span>&#x27;</span>)        result = []        max_distance = <span class="hljs-number">1</span>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(search_result) == <span class="hljs-number">0</span>:            logger.warning(<span class="hljs-string">f&quot;<span class="hljs-subst">{intput_text}</span> search_embeddings_result is empty!!!&quot;</span>)            <span class="hljs-keyword">return</span> result        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(search_result[<span class="hljs-number">0</span>])):            hit = search_result[<span class="hljs-number">0</span>][i]            distance = <span class="hljs-built_in">float</span>(hit.distance)            <span class="hljs-comment"># if distance &gt; float(max_distance):</span>            <span class="hljs-comment">#     continue</span>            chunk = hit.entity.get(<span class="hljs-string">&#x27;chunk&#x27;</span>)            <span class="hljs-built_in">id</span> = hit.entity.get(<span class="hljs-string">&#x27;id&#x27;</span>)            result.append({<span class="hljs-string">&#x27;chunk&#x27;</span>:chunk, <span class="hljs-string">&#x27;chunk_id&#x27;</span>:<span class="hljs-built_in">id</span>, <span class="hljs-string">&#x27;distance&#x27;</span>:distance})            logger.info(<span class="hljs-string">f&quot;<span class="hljs-subst">{distance}</span> chuck <span class="hljs-subst">{chunk}</span>&quot;</span>)        <span class="hljs-keyword">return</span> result</code></pre>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 向量数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo主题添加数学公式渲染支持</title>
      <link href="/ruan-jian-bi-ji/hexo-zhu-ti-tian-jia-shu-xue-gong-shi-xuan-ran-zhi-chi/"/>
      <url>/ruan-jian-bi-ji/hexo-zhu-ti-tian-jia-shu-xue-gong-shi-xuan-ran-zhi-chi/</url>
      
        <content type="html"><![CDATA[<p>对于数学/物理工作者来说，一个常见的需求是想要在Hexo博客中支持复杂数学公式的渲染。MathJax 和 KaTeXKATEX 是两个常见的渲染引擎，MathJax 使用者多、兼容性好、但渲染速度慢，而 KaTeXKATEX 渲染速度快，且根号无错位，但有时有bug。本文给出基于Keep主题的 KaTeXKATEX 的配置方法。</p><h2 id="更换渲染器"><a class="markdownIt-Anchor" href="#更换渲染器"></a> 更换渲染器</h2><p>无论是基于<code>MathJax</code> 还是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi>a</mi><mi>T</mi><mi>e</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">KaTeX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，都要首先更换Hexo自带的渲染器，因为它不支持渲染复杂数学公式。</p><pre class="highlight"><code class>npm uni hexo-renderer-marked</code></pre><p>安装 hexo-renderer-markdown-it-plus 渲染器</p><pre class="highlight"><code class>npm i hexo-renderer-markdown-it-plus</code></pre><p>此渲染器默认包含且开启了 <code>@iktakahiro/markdown-it-katex</code> 插件，可渲染 11.1 版本以前的 KaTeXKATEX 公式。但 KaTeXKATEX 自 13.0 开始渲染机制发生了变化，需要更换为 <code>@andatoshiki/markdown-it-katex</code> 插件。</p><pre class="highlight"><code class>npm install katexnpm install @andatoshiki/markdown-it-katex</code></pre><p>并在根目录的 <code>_config.yml</code> 中添加如下内容,测试下来，不加下面这个也可行</p><pre class="highlight"><code class>markdown_it_plus:  # ...  plugins:    - plugin:      name: '@iktakahiro/markdown-it-katex'      enable: false    - plugin:      name: '@andatoshiki/markdown-it-katex'      enable: false</code></pre><p>接着执行</p><pre class="highlight"><code class>hexo cleanhexo generate</code></pre><p>以清除缓存并刷新插件配置。</p><h2 id="配置css"><a class="markdownIt-Anchor" href="#配置css"></a> 配置CSS</h2><p>插件安装好后，需要在每篇博客的 <code>&lt;head&gt;</code> 标签中包含 KaTeXKATEX 的CSS。考虑到国内的网络环境，可以选择360作为CDN</p><pre class="highlight"><code class>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://lib.baomitu.com/KaTeX/latest/katex.min.css&quot;&gt;</code></pre><p>若主要用途为国外访问，可以使用 jsDelivr</p><pre class="highlight"><code class>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css&quot;&gt;</code></pre><p>若每篇博客都要使用数学公式，可以将其加入主题预定义的 <code>head.ejs</code> 中。</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> hexo博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS系统升级后Navicat密码保存不了问题</title>
      <link href="/ruan-jian-bi-ji/macos-xi-tong-sheng-ji-hou-navicat-mi-ma-bao-cun-bu-liao/"/>
      <url>/ruan-jian-bi-ji/macos-xi-tong-sheng-ji-hou-navicat-mi-ma-bao-cun-bu-liao/</url>
      
        <content type="html"><![CDATA[<p>MacOS系统升级后Navicat 15或16版本会出现无法保存数据库密码问题，报&quot;AIled to save password error code -34018&quot;,每次重启都要重新编辑连接输入数据库密码，超级崩溃。</p><h1 id="尝试解决"><a class="markdownIt-Anchor" href="#尝试解决"></a> 尝试解决</h1><p>网上试了很多方法尝试解决，有什么删除Keychains的，有什么下载补充类库的，都无法解决。</p><p>例如这个：<a href="https://blog.csdn.net/max_zhanglei/article/details/114032161" target="_blank" rel="noopener">https://blog.csdn.net/max_zhanglei/article/details/114032161</a></p><p>原因是说：macOS Big Sur及更高版本的macOs系统都会有这个问题，按博主解决方法未能成功。</p><h1 id="最终解决"><a class="markdownIt-Anchor" href="#最终解决"></a> 最终解决</h1><p>最后放弃使用新版Navicat, 老版本也很香，完全不影响工作日常使用。</p><p>这里下载链接，直接下载即可，无需激活。</p><p><a href="https://xclient.info/s/navicat-premium.html#versions" target="_blank" rel="noopener">https://xclient.info/s/navicat-premium.html#versions</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219155022864.png" alt="image-20240219155022864"></p><p>我用<strong>12.1.27</strong> 版本安装使用成功，网传<strong>15.0.20.1</strong> 也可以，这个没试过大家可以自行尝试下看看。</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> Navicat </tag>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能技术发展史</title>
      <link href="/ren-gong-zhi-neng/ren-gong-zhi-neng/"/>
      <url>/ren-gong-zhi-neng/ren-gong-zhi-neng/</url>
      
        <content type="html"><![CDATA[<h1 id="人工智能"><a class="markdownIt-Anchor" href="#人工智能"></a> 人工智能</h1><h1 id="什么是人工智能"><a class="markdownIt-Anchor" href="#什么是人工智能"></a> 什么是人工智能</h1><p>指由人制造出来的机器所表现出来的智能。<em>人工智能</em>可以定义为模仿人类与人类思维相关的认知功能的机器或计算机，如学习和解决问题</p><ul><li>专家系统：基于专家知识库+推理引擎。比如使用预定的一些规则和逻辑，模拟人类专家进行决策的过程</li><li>启发式问题解决：比如评估小范围的解决方案，并可能涉及一些猜测，以找到接近最佳的解决方案。</li><li>自然语言处理：在自然语言中实现人机之间的交流。比如聊天机器人。</li><li>计算机视觉：自动生成识别形状和功能的能力。比如人脸识别、图像识别、语音识别（本质还是基于数据化之后的语音图谱）</li></ul><h1 id="如何实现这些智能"><a class="markdownIt-Anchor" href="#如何实现这些智能"></a> 如何实现这些智能</h1><h2 id="手动编写规则和逻辑"><a class="markdownIt-Anchor" href="#手动编写规则和逻辑"></a> 手动编写规则和逻辑</h2><p>手动编写各种规则，以响应特定的输出，类似IF/ELSE逻辑，更加复杂的就是一些数学函数规则。</p><p>比如情感问题专家系统，有一个预设好的问题和答案库，当用户输入某个问题时，返回对应问题的答案。</p><p>比如在早期的机器翻译，就是通过语法规则解析+关键词匹配来识别和理解用户的输入，并响应对应目标语言的语法规则和关键词生成翻译语言。</p><p>在比如我们公司的风控系统，根据输入特征结合预设规则返回风控结果等等。在一定程度上都能实现简单的类人类的一些智能。</p><h2 id="基于统计概率"><a class="markdownIt-Anchor" href="#基于统计概率"></a> 基于统计概率</h2><p>基于大量实际的例子进行概率统计预测，例如我们的手机输入法，个人常用的词组将会放在前面。</p><p>人们很快发现，对于实世界的复杂问题并不都可以通过预设规则很好地处理，</p><p>比如人脸识别、图像识别，一个人从早到晚、每天的情绪变化都会细微地影响你的人脸构成，而计算机又是极其“死脑筋”的，任何细微的变化都可能对同一个人识别失败，所以我们不可能通过预设所有情况很好地解决这类问题。</p><p>再比如自然语言处理，只通过预发解析和关键词匹配的出来的解释并不是一成不变的，语言中有很多歧义性(多义词)、容错性（错别字、顺序错误、语法错误）。这样下来我们实际使用的语言是灵活性极高的，并不能穷举完所有情况进行预设。例如下面这段话：</p><blockquote><p>他说：“她这个人真有意思(funy)。”她说：“他这个人怪有意思的(funy)。”于是人们以为他们有了意思(wish)，并让他向她意思意思（express）。他火了：“我根本没有那个意思(thought)！”她也生气了：“你们这么说是什么意思（Intention）？”事后有人说：“真有意思(funny)。”也有人说：“真没意思(nonsense)。”</p></blockquote><p>很难通过预设的一些语法和关键词进行很好的翻译对应的“意思”。当然自然语言处理发展已有半个世纪的发展。在机器学习之前的翻译翻译效果也一直不够理想。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219163614202.png" alt="image-20240219163614202"></p><h2 id="机器学习"><a class="markdownIt-Anchor" href="#机器学习"></a> 机器学习</h2><p>利用数据和算法让计算机自动学习模式、规律，并进行预测和分类。</p><p>就比如给一堆的数据：标注好的图片、标注好的语料。让计算机自动通过机器学习的过程不断总结规律直至预测和分类效果达到可接受的范围之内。从而得到能够预测和分类未知输入的能力。</p><p>过程类似这样。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219163634073.png" alt="image-20240219163634073"></p><p>就是让机器通过数学建模找到f(x)函数，使得他可以拟合我们现实世界中的任意复杂场景。</p><p>例如这样的线性函数，找到个f(x)函数使得到各个点的实际误差最小。</p><p>例如这样的类一元二次函数的点分布，找到一个抛物线使得到各个点的误差最小。</p><p>我们人类可以根据数学经验和已知的一些规律找到对于函数类型，是一元一次方程、一元二次方程、或者是指数函数，正余弦等等。</p><p>但是对于计算机来讲他怎么知道该用什么类型的函数来拟合呢。如果数据分布呈现不了任何规律，又改如何找对对于的函数进行拟合呢。</p><p>比如如这样的，这样的，甚至这样的。</p><h2 id="神经网络"><a class="markdownIt-Anchor" href="#神经网络"></a> 神经网络</h2><p>这个东西也叫通用函数逼近器，数学家已经证明，两层的神经网络足以拟合任何复杂函数。</p><h2 id="神经网络的类型"><a class="markdownIt-Anchor" href="#神经网络的类型"></a> 神经网络的类型</h2><p>CNN</p><p>RNN</p><p>DNN</p><h2 id="一个完整模型训练炼丹的过程"><a class="markdownIt-Anchor" href="#一个完整模型训练炼丹的过程"></a> 一个完整模型训练(“炼丹”)的过程</h2><p>无监督学习</p><p>有监督学习</p><p>微调</p><p>参考文献：</p><p>小白也能听懂的人工智能原理：<a href="https://www.aliyundrive.com/s/hXdxXyuuzdW" target="_blank" rel="noopener">https://www.aliyundrive.com/s/hXdxXyuuzdW</a> 提取码p2z7</p><p>Transformer的基本原理：<a href="https://blog.51cto.com/u_16161414/6483603" target="_blank" rel="noopener">https://blog.51cto.com/u_16161414/6483603</a></p><p>神经网络的基本原理：<a href="https://blog.51cto.com/u_16161414/6479769" target="_blank" rel="noopener">https://blog.51cto.com/u_16161414/6479769</a></p><p>神经网络初探——神经网络如何工作：<a href="https://zhuanlan.zhihu.com/p/64532465" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64532465</a></p><p>一文看懂四种基本的神经网络架构：<a href="https://www.jianshu.com/p/546dc40b52c8" target="_blank" rel="noopener">https://www.jianshu.com/p/546dc40b52c8</a></p><p>很好的大语言模型的入门：ChatGPT背后的语言模型简史：<a href="https://www.bmpi.dev/dev/deep-learning/nlp-language-models/" target="_blank" rel="noopener">https://www.bmpi.dev/dev/deep-learning/nlp-language-models/</a></p><p>图解Word2vec,是如何训练出来的：<a href="https://mp.weixin.qq.com/s/NMngfR7EWk-pa6c4_FY9Yw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/NMngfR7EWk-pa6c4_FY9Yw</a></p><p>如何通俗理解Word2Vec (23年修订版)</p><p><a href="https://blog.csdn.net/v_JULY_v/article/details/102708459" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/102708459</a></p><p>Transformer通俗笔记：从Word2Vec、Seq2Seq逐步理解到GPT、BERT：<a href="https://blog.csdn.net/v_JULY_v/article/details/127411638" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/127411638</a></p><p>图解GPT：<a href="https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A02-Transformer%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86/2.4-%E5%9B%BE%E8%A7%A3GPT.md" target="_blank" rel="noopener">https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/篇章2-Transformer相关原理/2.4-图解GPT.md</a></p><p>超大型人工智能：从GPT-&gt;GPT2-&gt;GPT3的发展历程+大规模预训练神经网络模型原理详解： <a href="https://zhuanlan.zhihu.com/p/591146772" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/591146772</a></p><p>提示词工程：<a href="https://www.51cto.com/article/749832.html" target="_blank" rel="noopener">https://www.51cto.com/article/749832.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 人工智能 </tag>
            
            <tag> 大语言模型 </tag>
            
            <tag> LLM </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通用大语言模型介绍、本地部署及微调</title>
      <link href="/ren-gong-zhi-neng/llma-ben-di-da-jian-bi-ji/"/>
      <url>/ren-gong-zhi-neng/llma-ben-di-da-jian-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="wget-后台下载"><a class="markdownIt-Anchor" href="#wget-后台下载"></a> wget 后台下载</h2><pre class="highlight"><code class>wget -b url# 查看wget logcat wget-logtail -f wget-log# wget指定文件名称wget url -o filename</code></pre><h2 id="sftp文件上传"><a class="markdownIt-Anchor" href="#sftp文件上传"></a> sftp文件上传</h2><pre class="highlight"><code class>sftp root@8.134.128.130 &lt;&lt;EOFput ./source/openai-demo*.jar /opt/openai-demo/byeEOF#查看本地的文件列表llslcd lscd</code></pre><h2 id="查看文件摘要"><a class="markdownIt-Anchor" href="#查看文件摘要"></a> 查看文件摘要</h2><pre class="highlight"><code class>sha256sum example.txt</code></pre><h2 id="git-lfs使用"><a class="markdownIt-Anchor" href="#git-lfs使用"></a> Git lfs使用</h2><pre class="highlight"><code class>安装 homebrewbrew install git-lfsgit lfs install下载安装 windows installer运行 windows installergit lfs installsudo yum install git-lfssudo apt-get install git-lfs# 切换到lfsgit lfs install# 列出git lfs管理的大文件git lfs list-files</code></pre><h2 id="conda使用"><a class="markdownIt-Anchor" href="#conda使用"></a> Conda使用</h2><pre class="highlight"><code class>conda create -n env_nameconda activate env_nameconda info --envs# 安装软件conda install xxx</code></pre><h2 id="查看显卡运行情况命令"><a class="markdownIt-Anchor" href="#查看显卡运行情况命令"></a> 查看显卡运行情况命令</h2><pre class="highlight"><code class>watch -n 0.5 nvidia-smi</code></pre><h2 id="安装环境依赖"><a class="markdownIt-Anchor" href="#安装环境依赖"></a> 安装环境依赖</h2><pre class="highlight"><code class>pip install -r requirement.txt</code></pre><h2 id="clash服务器端代理"><a class="markdownIt-Anchor" href="#clash服务器端代理"></a> Clash服务器端代理：</h2><p>使用Xflash作为梯子</p><p><a href="https://i.jakeyu.top/2021/11/27/centos-%E4%BD%BF%E7%94%A8-Clash-%E6%A2%AF%E5%AD%90/" target="_blank" rel="noopener">https://i.jakeyu.top/2021/11/27/centos-使用-Clash-梯子/</a></p><p><a href="https://www.jianshu.com/p/1702a352797d" target="_blank" rel="noopener">https://www.jianshu.com/p/1702a352797d</a></p><pre class="highlight"><code class>nohup ~/clash &gt; /dev/null 2&gt;&amp;1 &amp;nohup ~/clash &gt; ~/clash_out.log &amp;vim /etc/profilesource /etc/profileexport ALL_PROXY=socks5://127.0.0.1:7891export http_proxy=http://127.0.0.1:7890export https_proxy=http://127.0.0.1:7890#测试curl www.google.com</code></pre><h2 id="报错集锦"><a class="markdownIt-Anchor" href="#报错集锦"></a> 报错集锦</h2><h2 id="大语言模型大爆发"><a class="markdownIt-Anchor" href="#大语言模型大爆发"></a> 大语言模型大爆发</h2><p>开源大语言模型(LLM)汇总： <a href="http://www.dtmao.cc/NodeJs/75351.html" target="_blank" rel="noopener">http://www.dtmao.cc/NodeJs/75351.html</a></p><p>开源ChatGPT替代模型项目整理： <a href="https://zhuanlan.zhihu.com/p/618790279" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/618790279</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1deb2c972163d97bf177aa20222ac42a.png" alt="img"></p><h2 id="llma大语言模型large-language-model-llm"><a class="markdownIt-Anchor" href="#llma大语言模型large-language-model-llm"></a> LLMA（大语言模型，Large Language Model, LLM）</h2><p>大语言模型llma-13b:<a href="https://huggingface.co/decapoda-research/llama-13b-hf/tree/main" target="_blank" rel="noopener">https://huggingface.co/decapoda-research/llama-13b-hf/tree/main</a></p><p>LMFlow大语言模型微调：<a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md" target="_blank" rel="noopener">https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md</a></p><p>LLMA-Alpaca中文版：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca</a></p><p>LLMA-Alpaca中文版与原始llma模型合并：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/模型合并与转换</a></p><p>LLMA-Alpaca中文版模型训练过程：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/训练细节</a></p><p>大语言模型的下载和安装：<a href="https://ivonblog.com/posts/dalai-llama-installation/" target="_blank" rel="noopener">https://ivonblog.com/posts/dalai-llama-installation/</a></p><h2 id="chatglm"><a class="markdownIt-Anchor" href="#chatglm"></a> ChatGLM</h2><p><a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B</a></p><p>官方chatglm微调：<a href="https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md</a></p><p>第三方微调：<a href="https://github.com/ssbuild/chatglm_finetuning" target="_blank" rel="noopener">https://github.com/ssbuild/chatglm_finetuning</a></p><p>PTuning与LoRA微调方式：<a href="https://github.com/liucongg/ChatGLM-Finetuning" target="_blank" rel="noopener">https://github.com/liucongg/ChatGLM-Finetuning</a></p><p>制作数据集方案：<a href="https://github.com/hikariming/alpaca_chinese_dataset/blob/main/%E5%BE%AE%E8%B0%83%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B7%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%8A%9F%E6%96%B9%E6%A1%88.ipynb" target="_blank" rel="noopener">https://github.com/hikariming/alpaca_chinese_dataset/blob/main/微调使用自己数据集成功方案.ipynb</a></p><p>用Blog和聊天记录微调自己的ChatGLM模型：<a href="https://github.com/wdkwdkwdk/CLONE_DK" target="_blank" rel="noopener">https://github.com/wdkwdkwdk/CLONE_DK</a></p><p>使用langchat进行训练：<a href="https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59" target="_blank" rel="noopener">https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59</a></p><p>港科大开源的训练微调脚手架：<a href="https://github.com/OptimalScale/LMFlow" target="_blank" rel="noopener">https://github.com/OptimalScale/LMFlow</a></p><h2 id="微调"><a class="markdownIt-Anchor" href="#微调"></a> 微调</h2><p>ChatGPT等大模型高效调参大法——PEFT：<a href="https://zhuanlan.zhihu.com/p/613863520" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/613863520</a></p><p>（1）对于动则百亿级别的参数,如何更高效,低资源的微调大模型呢</p><p>（2）当样本量很小的时候，如何微调大模型能得到较好的效果呢</p><ul><li>LORA ：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2106.09685.pdf" target="_blank" rel="noopener">LORA</a> 算法是在 每层 transfomer block 旁边引入一个并行低秩的支路，支路的输入是transfomer block 的输入，</li><li>PREFIX_TUNING</li><li>P_TUNING/P_TUNING 2</li><li>PROMPT_TUNING</li></ul><h2 id="基于chatglm的p-tuning2微调"><a class="markdownIt-Anchor" href="#基于chatglm的p-tuning2微调"></a> 基于ChatGLM的P-Tuning2微调</h2><p>官方chatglm微调：<a href="https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md</a></p><h3 id="基于chatglm的lora微调"><a class="markdownIt-Anchor" href="#基于chatglm的lora微调"></a> 基于ChatGLM的Lora微调</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230423203743669.png" alt="image-20230423203743669"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230423205550920.png" alt="image-20230423205550920"></p><h2 id="langchain"><a class="markdownIt-Anchor" href="#langchain"></a> Langchain</h2><p>人工智能应用搭建的脚手架，提供了诸如在特定文档上进行问答、聊天机器人、智能代理等各类应用场景的快速搭建</p><p><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener">https://github.com/hwchase17/langchain</a></p><p><a href="https://github.com/arc53/docsgpt" target="_blank" rel="noopener">https://github.com/arc53/docsgpt</a></p><p><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide" target="_blank" rel="noopener">https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide</a></p><p>实现基于上下文的QA机器人：</p><p><a href="https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html</a></p><p><a href="https://python.langchain.com/en/latest/use_cases/question_answering.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/use_cases/question_answering.html</a></p><h1 id="人工智能领域软件汇总"><a class="markdownIt-Anchor" href="#人工智能领域软件汇总"></a> 人工智能领域软件汇总</h1><ul><li>transflow 神经网络框架</li><li>PyTorch 新兴神经网络框架</li><li>transformer  huggingface出品，类似于人工智能的运行框架和平台, 底层进一步对PyTorch/Transflow等进行封装,是人工智能模型标准定义</li><li>huggingface：<a href="https://huggingface.co/" target="_blank" rel="noopener">https://huggingface.co/</a>  是一个AI领域的GITHUB，上面管理的市训练好的模型(Model)、数据集（Dataset）、社区(Space)</li><li>Conda python环境隔离管理软件，因为各个python应用所需的依赖版本有时各有不同，为了防止冲突，可以通过conda进行依赖环境隔离</li><li>Cuda Nvidia的指令集，供给应用层使用GPU计算能力，也就是给ai的训练和推演提供算力支持</li><li>Git lfs 大文件git管理指令集，用于从：<a href="https://huggingface.co/" target="_blank" rel="noopener">https://huggingface.co/</a> clone下载模型文件</li><li>Langchain 人工智能应用搭建的脚手架，提供了诸如在特定文档上进行问答、聊天机器人、智能代理等各类应用场景的快速搭建</li></ul>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> LLama </tag>
            
            <tag> ChatGLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac好用的Markdown编辑器</title>
      <link href="/ruan-jian-bi-ji/mac-hao-yong-de-markdown-bian-ji-qi/"/>
      <url>/ruan-jian-bi-ji/mac-hao-yong-de-markdown-bian-ji-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="typora"><a class="markdownIt-Anchor" href="#typora"></a> Typora</h1>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业信息化和政务信息化</title>
      <link href="/ruan-kao/qi-ye-xin-xi-hua-he-zheng-wu-xin-xi-hua/"/>
      <url>/ruan-kao/qi-ye-xin-xi-hua-he-zheng-wu-xin-xi-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="信息系统工程"><a class="markdownIt-Anchor" href="#信息系统工程"></a> 信息系统工程</h1><p>以结构、元素、信息及反馈等进行分析，以达到最优设计、最优规划、最优管理和最优控制的目的。</p><p>系统工程的方法，霍尔提出的三维结构体系，以时间维、空间维、知识维组成的立体结构概括性表示出系统工程的各个阶段、各个步骤及所涉及到的知识范围。</p><p>时间维———是指工作的进度，而于一个具体的工作项目，从制定规划起到一直更新为止，全部过程可分为七个阶段：</p><ul><li>规划阶段——调研、程序设计阶段，目的紫玉谋求活动的规划和战略</li><li>拟定阶段——提出具体的规划方案</li><li>研制阶段——作出研制方案及生产计划</li><li>生产阶段</li><li>安装阶段</li><li>运行阶段</li><li>更新阶段</li></ul><h1 id="政府信息化与电子政务"><a class="markdownIt-Anchor" href="#政府信息化与电子政务"></a> 政府信息化与电子政务</h1><p>电子政务的三个主体：政府、企业及事业单位、大众</p><h1 id="企业的信息化与电子商务"><a class="markdownIt-Anchor" href="#企业的信息化与电子商务"></a> 企业的信息化与电子商务</h1><h2 id="企业信息化"><a class="markdownIt-Anchor" href="#企业信息化"></a> 企业信息化</h2><p>企业信息化是指通过IT技术的部署来提供去也的生产运维效率，从而降低经营成本。其中业务流程的管理与知识的挖掘是重要活动。</p><ol><li>企业信息化的是3个需求层次：战略需求、运作需求和技术需求</li></ol><ul><li>战略需求——组织信息化的目标是提升组织的竞争力、为组织的可持续发展提供一个支持环境。从而某种意义上来说信息化对组织不仅仅是服务的手段和实现现有战略的辅助工具；信息化可以报组织战略提升到一个新的水平，为组织带来新的发展契机。</li><li>运作需求——实现战略目标的需要、运作策略的需要、人才培养的需要。</li><li>技术需求——由于系统开发时间过长等问题在信息技术层面对系统的完善、升级、集成和整合提出了需求</li></ul><h2 id="企业资源规划erp"><a class="markdownIt-Anchor" href="#企业资源规划erp"></a> 企业资源规划——ERP</h2><p>商业智能——通过数据挖掘技术、知识等发现等技术分析和挖掘结构化的、面向特定领域的的数据仓库信息</p><p>ERP系统的三流：物流、资金流、信息流<br>ERP系统时对企业的物流、资金流、信息流进行全面集成的管理信息系统</p><p>ERP系统能够实现的企业决策计划：</p><ul><li>生产预测计划——对市场的需求进行比较准确的预测，是经营计划、生产计划大纲和主生产计划编制的基础</li><li>销售管理计划——对销售部门的相关业务进行管理，属于最高层计划的范畴，是企业决策层最重要的计划之一</li><li>生产计划大纲——根据经营计划生产目标制定</li><li>主生产计划——说明一段时期内生产什么，生产多少盒什么时候交货，它是ERP的主要工作内容。</li><li>物料需求计划是对主生产计划的各个项所需的制造件和全部采购件等计划</li><li>能力需求计划——是对物料需求计划所需的能力进行核算的一种计划管理方法，能够帮助尽早发现企业的生产能力瓶颈，及时补充生产力。</li></ul><p>ERP的信息流：</p><ul><li>需求信息——客户订单、生产计划、采购合同等</li><li>供应信息——入库单、完工报告单、库存记录、可供销售量和提货发货发运单等</li></ul><h2 id="客户关系管理crm"><a class="markdownIt-Anchor" href="#客户关系管理crm"></a> 客户关系管理——CRM</h2><p>客户关系管理（CRM）系统将市场营销的科学管理通过信息技术手段集成在软件商，能够帮助企业构建良好的客户关系。<br>CRM是将人力资源、业务流程与专业的技术进行有效的整合，最终为企业涉及到的客户或者消费者的各个领域提供完美的集成，是的企业可以更低成本、更高效率满足客户的需求。<br>其主要功能包括：</p><ul><li>销售自动化——是其中最为基本的模块</li><li>营销自动化——作为销售自动化的补充，包括营销计划的编制和执行、计划结果分析等。</li><li>客户服务支持——是系统的重要功能</li><li>商业智能——数据挖掘和处理，为企业决策做支撑。</li></ul><p>CRM系统与ERP系统在财务、制造、库存等环节进行连接，<strong>两种虽然不同但由于两者之间具有一定的关系，因此能够形成一定的闭环反馈结构</strong></p><h2 id="企业应用的集成"><a class="markdownIt-Anchor" href="#企业应用的集成"></a> 企业应用的集成</h2><p>企业应用集成有多种集成模式，构建统一标准的基础平台，将具有不同功能和目的而又独立运行的企业信息联合起来。目前市场上主流的集成模式有三种，分别是<strong>面向信息的集成</strong>、<strong>面向过程的集成</strong>、<strong>面向服务的集成</strong>。</p><ul><li>面向过程集成——强调处理不同应用系统之间的交互逻辑，与核心业务逻辑相分离，并通过不同应用系统之间的协作共同完成某项业务功能。</li><li>面向信息的集成<ul><li>内部信息集成<ul><li>技术平台集成——系统底层的体系结构、软件、硬件及异构网络的特殊需求受限必须得到集成。这个集成包括信息技术硬件的组成</li><li>数据集成，共享数据库，主动记录、数据映射，实现不同的系统数据交流和共享，</li><li>应用系统集成，应用系统集成是实现不同系统之间的相互操作，是的不同应用系统之间能够实现数据和方法的共享</li><li>业务过程的集成，业务过程集成，企业必须在各个业务系统中定义、授权和管理各种业务信息的交流，一遍改进操作、减少成本、提高响应速度。</li></ul></li><li>外部信息集成</li></ul></li><li>面向服务的集成</li></ul><p>集成方式：</p><ul><li>远程过程调用——基于同步的方式，效率较低，二期容易失败；</li><li>共享数据和文件传输——将应用的数据存储在一个共享数据库中，通过制定统一的数据库模式来处理不同应用的集成需求，共享数据库为不同的应用提供了统一的数据存储和格式定义。性能方面较差，系统不能保持即时数据同步，而容易造成应用于数据紧耦合；</li><li>消息传递方式——能够保证数据异步、立即、可靠传输</li></ul><p>集成平台提供的基本功能包括：</p><ul><li>数据通信服务：提供分布环境下的透明同步、异步通信的服务功能</li><li>信息集成服务：为应用提供透明的信息访问服务，实现不同数据库之间的数据交换、相互操作、分布数据管理和共享信息模型的定义</li><li>应用集成服务：通过高层应用编程接口实现对相应应用程序的访问，能够为应用提供数据交换和访问的操作，是的各个系统相互协作。</li><li>二次开发工具：帮助用户开发特定应用程序的支持工具</li><li>平台运行管理工具：是企业集成平台和运作的管理控制面板。</li></ul><p>电子数据交换——EDI<br>EDI的实施需要一个公认的标准和协议，将商务活动中涉及到的文件标准化和格式化；EDI通过计算机网络，在贸易伙伴之间进行数据交换和自动处理</p><p>企业门户是一个信息技术平台，可提供个性化的信息服务，为企业提供一个单一的访问企业各种信息资源和应用的程序入口。</p><p>分为3中门户类型：</p><ul><li>企业信息门户——企业信息门户强调为访问结构数据和无结构数据提供统一的入口，实现收集、访问、管理和无缝集成</li><li>企业知识门户——提供一个创造、搜集和传播企业知识的平台，通过企业知识门户，员工与工作团队中的其他成员取得联系，寻找能够提供帮助的专家。</li><li>企业应用门户——是一个用来提供企业的集中贸易能力、协同能力和信息管理能力的平台。它以商业流程和企业应用为核心，将商业流程中功能不同的应用模块通过门户集成在一起，提高公司在集中贸易的能力、协同能力和信息管理能力。</li></ul><h2 id="电子商务"><a class="markdownIt-Anchor" href="#电子商务"></a> 电子商务</h2><p>参与电子商务的实体有四类：客户（个人消费者或者集团）、商户（包括销售商、制造商和储运商）、银行（发卡行和收单行）以及认证中心</p><h1 id="知识管理和商业智能化"><a class="markdownIt-Anchor" href="#知识管理和商业智能化"></a> 知识管理和商业智能化</h1><h2 id="商业智能化"><a class="markdownIt-Anchor" href="#商业智能化"></a> 商业智能化</h2><p>商业智能化的核心技术包括：数据仓库、数据挖掘、联机分析处理。<br>商业智能化系统处理过程包括数据预处理、简历数据仓库、数据分析及数据展现：</p><ul><li>数据预处理——包括数据的抽取、转换、封装</li><li>数据仓库——是处理海量数据的基础</li><li>数据分析——包括联机分析处理和数据挖掘两部分<ul><li>联机分析——处理不仅进行数据汇总、聚集，同事还提供切片、切块、下钻、上卷和旋转等分析功能</li><li>数据挖掘——挖掘数据背后的隐藏知识，通过</li></ul></li><li>数据展现——数据的可视化</li></ul>]]></content>
      
      
      <categories>
          
          <category> 软考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java学习大纲</title>
      <link href="/hou-duan-jia-gou/java-xue-xi-da-gang/"/>
      <url>/hou-duan-jia-gou/java-xue-xi-da-gang/</url>
      
        <content type="html"><![CDATA[<p>任何学习都要有目标有规划，这是整个Java知识体系大纲，根据自己的知识体系认知画出来的，有很多还没有细化，也还有很多没有涉猎，比如大数据，列出这些好让自己学的有目标一些吧，也算是一个总结。</p><p>在线预览地址：<a href="http://naotu.baidu.com/file/a94181bfafe64d39874b524ce8df18c1?token=a8efb35e029a526f" target="_blank" rel="noopener">http://naotu.baidu.com/file/a94181bfafe64d39874b524ce8df18c1?token=a8efb35e029a526f</a></p><img title src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184207294.png" alt data-align="center" width="684">]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分库分表的分页查询</title>
      <link href="/hou-duan-jia-gou/fen-ku-fen-biao-de-fen-ye-cha-xun/"/>
      <url>/hou-duan-jia-gou/fen-ku-fen-biao-de-fen-ye-cha-xun/</url>
      
        <content type="html"><![CDATA[<h1 id="问题的提出"><a class="markdownIt-Anchor" href="#问题的提出"></a> 问题的提出</h1><p>我们知道，当我们的数据量达到一定数量时，需要将数据表进行水平拆分，从而满足大量数据的存储和查询，保证系统的可用性，但同时会出现另外一个问题就是，如果业务要查询“最近注册的第3页用户”，该如何实现呢？单库上，可以通过简单的sql实现分页查询</p><pre class="highlight"><code class>select * from t_user order by time limit 200,100</code></pre><p>分库分表后变成两个库后，分库依据是user_id，排序依据是time，单个分数据库层失去了time排序的全局视野，如果同样需要实现分页查询时该怎么办呢？</p><h1 id="全局视野法"><a class="markdownIt-Anchor" href="#全局视野法"></a> 全局视野法</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040381.png" alt></p><p>正常来讲，不管哪一个分库的第3页都不一定有全局第3页的所有数据，例如一下三种情况：<br>情况一：两个分库按照时间排序，数据各占一半，则每页取offset和limit的一般数据回来合并就可以了<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040402.png" alt="aaa"></p><p>情况二：所有数据都在一个库上，则取一个库的所有数据回来就可以了<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040384.png" alt="ccc"></p><p>情况三，那么一般情况是，每个分库的数据数据是随机的，但是一定是在全局offset=600之内<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040393.png" alt="bbb"></p><p>由于不清楚到底是哪种情况，所以必须每个库都返回3页数据，所得到的6页数据在服务层进行内存排序，得到数据全局视野，再取第3页数据，便能够得到想要的全局分页数据。</p><p>这种方法缺点是：当查询的页数增大时，每个分库所需返回的数据也越来成倍增加，降低了查询的性能</p><h1 id="业务折中"><a class="markdownIt-Anchor" href="#业务折中"></a> 业务折中</h1><h2 id="第一种折中的方案是"><a class="markdownIt-Anchor" href="#第一种折中的方案是"></a> 第一种折中的方案是</h2><p>对全局视野法的一种优化，即禁用制定页数的分页查询，必须通过下一页来实现分页查询的页数跳转，并且在每次查询下一页时将上一页的最大排序字段的值带上（这里就是时间time）,这样在每个分库查询数据时待上这个条件，可以优化查询速率。</p><h2 id="第二种折中的方案是"><a class="markdownIt-Anchor" href="#第二种折中的方案是"></a> 第二种折中的方案是</h2><p>数据库分库-数据均衡原理</p><p>使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况是一致的。</p><p>例如，在uid随机的情况下，使用uid取模分两库，db0和db1：</p><p>（1）性别属性，如果db0库上的男性用户占比70%，则db1上男性用户占比也应为70%</p><p>（2）年龄属性，如果db0库上18-28岁少女用户比例占比15%，则db1上少女用户比例也应为15%</p><p>（3）时间属性，如果db0库上每天10:00之前登录的用户占比为20%，则db1上应该是相同的统计规律</p><p>利用这一原理，要查询全局100页数据，offset 9900 limit 100改写为offset 4950 limit 50，每个分库偏移4950（一半），获取50条数据（半页），得到的数据集的并集，基本能够认为，是全局数据的offset 9900 limit 100的数据，当然，这一页数据的精度，并不是精准的。</p><p>根据实际业务经验，用户都要查询第100页网页、帖子、邮件的数据了，这一页数据的精准性损失，业务上往往是可以接受的，但此时技术方案的复杂度便大大降低了，既不需要返回更多的数据，也不需要进行服务内存排序了。</p><h1 id="二次查找法"><a class="markdownIt-Anchor" href="#二次查找法"></a> 二次查找法</h1><p>有没有一种方法既能满足业务要求，并且不需要折中，性能还高的方法呢？<br>接下来介绍一种“二次查找法”，不知道能不能讲的明白，我尽量吧。</p><p>为了方便举例，假设一页只有5条数据，查询第200页的SQL语句为select * from T order by time offset 1000 limit 5;</p><p>分五步：</p><h3 id="1-将select-from-t-order-by-time-offset-1000-limit-5-优化成select-from-t-order-by-time-offset-500-limit-5注意这里的5001000分表数量并将这个sql下发至每个分库分表中执行每个分库返回这个sql执行的结果"><a class="markdownIt-Anchor" href="#1-将select-from-t-order-by-time-offset-1000-limit-5-优化成select-from-t-order-by-time-offset-500-limit-5注意这里的5001000分表数量并将这个sql下发至每个分库分表中执行每个分库返回这个sql执行的结果"></a> 1. 将<code>select * from T order by time offset 1000 limit 5;</code> 优化成<code>select * from T order by time offset 500 limit 5</code>,注意这里的500=1000/分表数量，并将这个sql下发至每个分库分表中执行，每个分库返回这个sql执行的结果。</h3><h3 id="2-找到所有分库返回结果的time的最小值"><a class="markdownIt-Anchor" href="#2-找到所有分库返回结果的time的最小值"></a> 2. 找到所有分库返回结果的time的最小值</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040369.png" alt><br>第一个库，5条数据的time最小值是1487501123<br>第二个库，5条数据的time最小值是1487501223</p><p>故，三页数据中，time最小值来自第一个库，time_min=1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低</p><h3 id="3-查询二次改写"><a class="markdownIt-Anchor" href="#3-查询二次改写"></a> 3. 查询二次改写</h3><p>第一次改写的SQL语句是select * from T order by time offset 500 limit 5</p><p>第二次要改写成一个between语句，between的起点是time_min，between的终点是原来每个分库各自返回数据的最大值：</p><p>第一个分库，第一次返回数据的最大值是1487501523<br>所以查询改写为select * from T order by time where time between time_min and 1487501523</p><p>第二个分库，第一次返回数据的最大值是1487501699<br>所以查询改写为select * from T order by time where time between time_min and 1487501699</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040363.png" alt></p><p>从上面图片可以看出，DB1比第一次查出来的数据多了两行，应为查询的范围扩大了</p><h3 id="4-计算time_min这条记录在全局的offset"><a class="markdownIt-Anchor" href="#4-计算time_min这条记录在全局的offset"></a> 4. 计算time_min这条记录在全局的offset</h3><p>根据第一步查询的sql<code>select * from T order by time offset 500 limit</code> ,我们知道每个库的offset值了，将DB0中的最小time的数据虚拟到DB1中推算在DB1中的offset值=497<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040525.png" alt><br>从而我们得知time_min这条记录在全局的offset值=500+497=997</p><h3 id="5-根据第二次查询出来的结果集在内存中作排序已知time_min在全局中的offset997那么结果集排序之后也能推算出offset1000所在的记录从而获得sqlselect-from-t-order-by-time-offset-1000-limit-5的分页查询记录图片黄色部分"><a class="markdownIt-Anchor" href="#5-根据第二次查询出来的结果集在内存中作排序已知time_min在全局中的offset997那么结果集排序之后也能推算出offset1000所在的记录从而获得sqlselect-from-t-order-by-time-offset-1000-limit-5的分页查询记录图片黄色部分"></a> 5. 根据第二次查询出来的结果集，在内存中作排序，已知time_min在全局中的offset=997,那么结果集排序之后也能推算出offset=1000所在的记录，从而获得sql<code>select * from T order by time offset 1000 limit 5</code>的分页查询记录（图片黄色部分）</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040515.png" alt></p><p>总结：可以精确的返回业务所需数据，每次返回的数据量都非常小，不会随着翻页增加数据的返回量。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> 分库分表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>限流相关</title>
      <link href="/hou-duan-jia-gou/xian-liu-xiang-guan/"/>
      <url>/hou-duan-jia-gou/xian-liu-xiang-guan/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>在大流量场景，秒杀、抢购场景，一般会对网站做一些流量控制，牺牲一部分流量而保护系统而不至于系统直接down机。</p><h1 id="常见限流算法"><a class="markdownIt-Anchor" href="#常见限流算法"></a> 常见限流算法</h1><h2 id="固定计算限流"><a class="markdownIt-Anchor" href="#固定计算限流"></a> 固定计算限流</h2><p>就是统计固定时间内的流量数量，如果超过了就限制。这种很容易实现，利用AutomicLong统计，下一个统计周期后又清零重新计算。<br>这样会有以下问题：</p><ol><li>1s之内的前100ms就已经达到了,那么后900ms就是空闲的。</li><li>如果1s之内的后100ms和下一秒的前100ms,那么在这个前后1s内加起来的流量是限流的两倍，显然这没有达到“在任意1s内流量不超过限制”的控制，很多黑客利用这个缺陷攻击网站，从而拖垮服务器。</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239907.png" alt></p><h2 id="滑动窗口"><a class="markdownIt-Anchor" href="#滑动窗口"></a> 滑动窗口</h2><p>为了解决“计数限流”的缺陷，我们引入“滑动窗口”的计数方法。就是在计数限流的基础之上，将1个限流时间周期内切分成更小的单位计数，使得限制流量更加均分。<br>具体做法如下：</p><ol><li>将1s钟切成更细粒度200ms为计数单位，将请求时间点按取模的方式计算落到对应的计数格中，然后判断从当前计数格往前推1s(也就是5个计数格)的统计数总和当成当前流量的计数，如果超过阈值则限流，否则放行</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239739-1424159.png" alt></p><ol start="2"><li>随着请求时间的推进，计数窗口也会随之往前移动</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239638-20240605150010827.png" alt></p><ol start="3"><li>这样的好处是，优化了“固定计数法”的缺陷，即在任意时刻，都将都以更小粒度的计数方法往前累加计算，防止在单位时间内流量超过限额。如图：</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239708.png" alt></p><h2 id="漏桶算法"><a class="markdownIt-Anchor" href="#漏桶算法"></a> 漏桶算法</h2><p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会时，有一定的缓冲能力，超过最大缓冲时将直接拒绝。这个算法的特点就是，不管桶里面是空还是满，都以均匀的速度放行。下面是从网上找的图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239739.png" alt></p><h2 id="令牌桶算法"><a class="markdownIt-Anchor" href="#令牌桶算法"></a> 令牌桶算法</h2><p>令牌桶算法（Token Bucket）：是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。令牌桶算法示意图如下所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239758.png" alt></p><p>令牌桶算法与漏桶算法的区别在于如果在一段时间内都没有流量，而桶中的令牌数有随着时间流逝匀速增加，那么桶中将会缓冲一定数量的令牌，即使后面流量突然增加超过了限额，也会由于还有可用的令牌直接放行，无需要等待。以下是令牌桶算法相对于漏斗算法的一些优势：</p><ol><li><strong>突发流量的处理</strong>：令牌桶算法允许一定程度的突发流量，因为当令牌桶中有足够的令牌时，流量可以以超过平均速率的速度通过一段时间。这在实际网络环境中是有用的，因为网络流量往往是突发性的。相比之下，漏斗算法对流量的控制更为严格，流量以恒定的速率通过，不允许突发流量。</li><li><strong>灵活性和可配置性</strong>：令牌桶算法提供了更多的灵活性，因为可以独立调整令牌的生成速率和桶的容量，以适应不同的流量需求和网络条件。漏斗算法的配置相对简单，主要是固定的漏斗出口速率，这可能不足以适应复杂的网络环境和多样化的流量模式。</li><li><strong>性能</strong>：在高速网络环境中，令牌桶算法通常能够提供更好的性能，因为它允许在令牌可用时快速传输数据包，而不是强制每个数据包都以固定的速率通过。这意味着令牌桶算法可以更有效地利用可用的带宽，从而提高整体的网络性能。</li></ol><p>总的来说，令牌桶算法相对于漏斗算法的优势在于它对突发流量的支持、更高的灵活性和可配置性，以及在高速网络环境中更好的性能表现。这些特点使得令牌桶算法在实际应用中更受欢迎，特别是在需要处理突发流量和动态调整流量控制策略的场景中。</p><h1 id="限流实现"><a class="markdownIt-Anchor" href="#限流实现"></a> 限流实现</h1><h2 id="guava的ratelimiter实现"><a class="markdownIt-Anchor" href="#guava的ratelimiter实现"></a> Guava的RateLimiter实现</h2><p>在Guava的工具包中，<code>RateLimiter</code>就是居于<code>令牌桶算法</code>实现的内存限流。<br>其构造有如下几个：</p><pre class="highlight"><code class> //构造方法1  @VisibleForTesting  static RateLimiter create(SleepingTicker ticker, double permitsPerSecond) {    //实现类是Bursty    RateLimiter rateLimiter = new Bursty(ticker, 1.0 /* maxBurstSeconds */);    //根据permitsPerSecond每秒令牌数计算，每个令牌产生的毫秒数    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;  }  //构造方法2 static RateLimiter create(      SleepingTicker ticker, double permitsPerSecond, long warmupPeriod, TimeUnit unit) {    //实现类是一个平滑预热限流，就是如果流量突然暴增，即使有足够的令牌，也不会一下子全部放下，会加一些线性等待时间平滑过渡    RateLimiter rateLimiter = new WarmingUp(ticker, warmupPeriod, unit);    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;  }</code></pre><p>获取令牌</p><pre class="highlight"><code class>  public double acquire(int permits) {    checkPermits(permits);    long microsToWait;    //获取全局锁    synchronized (mutex) {        //根据当前时间算出还需要等待的时间        microsToWait = reserveNextTicket(permits, readSafeMicros());    }    ticker.sleepMicrosUninterruptibly(microsToWait);    return 1.0 * microsToWait / TimeUnit.SECONDS.toMicros(1L);  }</code></pre><p>下面是令牌桶算法的核心</p><pre class="highlight"><code class>  private long reserveNextTicket(double requiredPermits, long nowMicros) {    //根据当前时间算出可用令牌数及要出来这么多令牌的时间点    resync(nowMicros);    //看下还需要等多久    long microsToNextFreeTicket = nextFreeTicketMicros - nowMicros;    //看下当前要立即花费多少令牌    double storedPermitsToSpend = Math.min(requiredPermits, this.storedPermits);    //还剩多少令牌需要等待    double freshPermits = requiredPermits - storedPermitsToSpend;    //根据不同的实现，Bursty或者WarmingUp，返回额外需要等待的时间    long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend)        + (long) (freshPermits * stableIntervalMicros);    //重置获取这么多令牌要等到啥时候    this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;    //更新下还剩多少可用令牌    this.storedPermits -= storedPermitsToSpend;    //返回还需要等待的时间    return microsToNextFreeTicket;  }</code></pre><p>可以看到这个实现，并不是根据算法图一个生产者不断的往一个数组中添加令牌，一个消费者不断的取令牌，而是以时间线的方式，计算出当前获取令牌需要花费的时间及算出当前时间以设定的速度能够无产生多少令牌的方式实时计算的，简单并且没有额外的轮询操作，非常高效节省资源。</p><h2 id="使用semphore进行并发流控"><a class="markdownIt-Anchor" href="#使用semphore进行并发流控"></a> 使用Semphore进行并发流控</h2><p><code>Semphore</code> 是JUC里面的并发信号量实现，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。很适合多线程情况对有限资源的抢占控制。</p><h2 id="netflix-hystrix-熔断限流"><a class="markdownIt-Anchor" href="#netflix-hystrix-熔断限流"></a> Netflix Hystrix 熔断限流</h2><p>Spring Clound里的Hystrix能否实现根据一定的访问异常设置，对应用做到降级限流的的控制</p><h2 id="阿里的sentinel实现"><a class="markdownIt-Anchor" href="#阿里的sentinel实现"></a> 阿里的Sentinel实现</h2><p>Sentinel 是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。<br>GITHUB:<a href="https://github.com/alibaba/Sentinel" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel</a><br>其官方文档中也提到，其受到Guava RateLmiter的启发。</p><p>大家可能会问：Sentinel 和上面提到的Netflix Hystrix 有什么异同呢？<br>其官方文档有专门的说明：<br><a href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/Sentinel-与-Hystrix-的对比</a></p><h2 id="其他实现"><a class="markdownIt-Anchor" href="#其他实现"></a> 其他实现</h2><p>进行限流控制还可以有很多种方法，针对不同的场景各有优劣，例如通过AtomicLong计数器控制、Redis计数，使用MQ消息队列进行流量消峰等等都是可以的。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>流量控制在高并发场景是一个对系统保护必不可少的一个手段，能够牺牲一部分流量而保护整个应用的可用性，不止于发生雪崩情况。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos 下Redis 安装以及集群搭建</title>
      <link href="/ruan-jian-bi-ji/centos-xia-redis-an-zhuang-yi-ji-ji-qun-da-jian/"/>
      <url>/ruan-jian-bi-ji/centos-xia-redis-an-zhuang-yi-ji-ji-qun-da-jian/</url>
      
        <content type="html"><![CDATA[<p>1.下载redis安装包</p><pre class="highlight"><code class>cd /root/softwarewget http://download.redis.io/releases/redis-3.2.4.tar.gztar -zxvf redis-3.2.4.tar.gz　</code></pre><p>2.编译安装</p><pre class="highlight"><code class>#先确保安装了make命令#make是gcc的编译器，VPS买来必定要安装#安装：yum -y install gcc automake autoconf libtool make#安装g++:yum install gcc gcc-c++cd redis-3.2.4make &amp;&amp; make install</code></pre><p>3.将 redis-trib.rb 复制到 /usr/local/bin 目录下,能在任意目录访问到此命令</p><pre class="highlight"><code class>cd srccp redis-trib.rb /usr/local/bin/</code></pre><p>4.创建目录存放redis节点的配置文件</p><pre class="highlight"><code class>mkdir /opt/redis-cluster/#redis集群节点至少要6个mkdir 7000 7002 7003 7004 7005#复制redis.conf到各个节点目录cp redis-3.2.4/redis.conf /opt/redis-cluster/7000</code></pre><p>5.然后编辑 redis.conf修改每个节点的配置,修改以下属性</p><pre class="highlight"><code class>port  7000                                        //端口7000,7002,7003        bind 本机ip                                       //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群daemonize    yes                               //redis后台运行pidfile  /var/run/redis_7000.pid          //pidfile文件对应7000,7001,7002cluster-enabled  yes                           //开启集群  把注释#去掉appendonly  yes                           //aof日志开启  有需要就开启，它会每次写操作都记录一条日志　</code></pre><p>6.启动节点</p><pre class="highlight"><code class>redis-server redis_cluster/7000/redis.confredis-server redis_cluster/7001/redis.confredis-server redis_cluster/7002/redis.conf</code></pre><p>检查 redis 启动情况</p><pre class="highlight"><code class>[root@localhost 7005]# ps -ef|grep redisroot     23002     1  0 11:41 ?        00:00:05 redis-server 192.168.10.10:7000 [cluster]root     26165     1  0 11:45 ?        00:00:05 redis-server 192.168.10.10:7001 [cluster]root     26609     1  0 12:03 ?        00:00:04 redis-server 192.168.10.10:7002 [cluster]root     27943     1  0 13:46 ?        00:00:00 redis-server 192.168.10.10:7003 [cluster]root     28008     1  0 13:47 ?        00:00:00 redis-server 192.168.10.10:7004 [cluster]root     28031     1  0 13:48 ?        00:00:00 redis-server 192.168.10.10:7005 [cluster]root     28036 18197  0 13:48 pts/0    00:00:00 grep --color=auto redis</code></pre><pre class="highlight"><code class>#查看端口监听netstat -tnlp | grep redis</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage.png" alt></p><p>7.将redis节点加入集群</p><pre class="highlight"><code class>redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005</code></pre><p>运行以上命令时，必须要先安装ruby环境，因为这个命令时ruby写的<br>安装命令如下：</p><pre class="highlight"><code class>yum -y install ruby ruby-devel rubygems rpm-buildgem install redis</code></pre><p>重新运行命令如果出现以下图片则表示集群安装成功，记得中途还需输入yes<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222704158.png" alt></p><p>8.集群验证<br>简单说下redis集群的原理：<br>redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。</p><p>Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点。</p><p>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据。只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。</p><p>需要注意的是：必须要6个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。</p><p>所以使用redis-cli客户端命令连接redis时，随便指定集群中的任意节点都可以访问到整个集群的数据，运行命令是多加一个<code>-c</code>参数</p><pre class="highlight"><code class>redis-cli -h 192.168.10.10 -c -p 7002</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222711977.png" alt></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222715529.png" alt></p><p>到此安装完成。</p><h1 id="遇到问题"><a class="markdownIt-Anchor" href="#遇到问题"></a> 遇到问题</h1><p>遇到以下问题时：</p><pre class="highlight"><code class>[root@localhost 7004]# /soft/redis-3.2.4/src/redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005&gt;&gt;&gt; Creating cluster[ERR] Node 192.168.10.10:7005 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.</code></pre><p>解决方法：</p><pre class="highlight"><code class>#查找进程并kill掉[root@localhost 7005]# ps -ef|grep redis                             root     23753     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7000 [cluster]root     23758     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7001 [cluster]root     23763     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7002 [cluster]root     23768     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7003 [cluster]root     23778     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7005 [cluster]root     23846     1  0 16:34 ?        00:00:00 /soft/redis-3.2.4/src/redis-server 192.168.10.10:7004 [cluster]kill 23846#删除/opt/redis-cluster/7004/下除redis.conf的文件rm -f appendonly.aof  dump.rdb  nodes.conf或者rm -f !(redis.conf)#然后重新启动7004cd /opt/redis-cluster/7004/soft/redis-3.2.4/src/redis-server redis.conf/soft/redis-3.2.4/src/redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件开发方法</title>
      <link href="/ruan-kao/ruan-jian-kai-fa-fang-fa/"/>
      <url>/ruan-kao/ruan-jian-kai-fa-fang-fa/</url>
      
        <content type="html"><![CDATA[<blockquote><p>前言：软件开发方法是软件开发的方法学，旨在提供软件的质量，降低开发成本</p></blockquote><h1 id="1-软件生命周期"><a class="markdownIt-Anchor" href="#1-软件生命周期"></a> 1 软件生命周期</h1><ol><li>可行性研究和规划：通过可行性分析确认原件的必要性，价值点，初步确认软件的目标、范围、风险和开发成本等内容。</li><li>需求分析：需求分析是开发过程的重要阶段，初步确认软件开发的目标和范围，之后则要对软件的需求进行细致分析，确认最终要做成什么样子。这个过程极其重要，如果这个阶段出现分析错误和偏差将导致后续开发过程偏离真实需求越远，修正的成本越大。</li><li>概要设计：是程序员开发过程中的蓝图，包括确认系统架构、各个子系统依赖关系、数据库模型、编码规范、接口规约等内容</li><li>详细设计：详细设计师开发之前的最后设计，是在概要设计的基础上进行进行细化，如类设计。详细设计不是必要过程，在规模较小，功能结构简单的系统中可以省略。</li><li>实现：针对设计的单元模块进行开发，如一个过程、方法、函数，包括实现单元模块的单元测试</li><li>集成测试：对单元模块进行组装联调测试</li><li>确认测试：系统开发完后，需要验证是否和需求预期一致</li><li>软件使用和维护：软件投入试运行，并不断对过程中出现的问题进行维护修正，软件维护郭晨会贯穿整个软件的使用郭晨直至软件自然消亡。</li></ol><h1 id="2-软件开发模型"><a class="markdownIt-Anchor" href="#2-软件开发模型"></a> 2 软件开发模型</h1><p>计算机刚刚诞生的年代，是一种只有天才才能掌握的巩固，人们对软件知识的认知仅仅停留在程序层面。随着技术发展，软件复杂度的提高，意识到必须遵循一定的开发方法才能取得成功，于是出现了模式化的开发方法称为开发模型。</p><h2 id="21-瀑布模型"><a class="markdownIt-Anchor" href="#21-瀑布模型"></a> 2.1 瀑布模型</h2><p>特点：</p><ol><li>软件过程要经过需求分析、总体设计、详细设计、编码、调试、集成测试和系统测试阶段，开发阶段划分明确</li><li>再每一个阶段结算后都有不定的文档或者程序流入下一个阶段</li><li>每个阶段在发现问题时可以反馈给上一个阶段进行修正<br>适用场景：需求明确、稳定时</li></ol><h3 id="211-瀑布v模型"><a class="markdownIt-Anchor" href="#211-瀑布v模型"></a> 2.1.1 瀑布V模型</h3><p>同标准瀑布模型一样，保持了瀑布模型的阶段式文档驱动的特点，但是更强调软件产品的验证工作，即需求分析的记过将作为系统测试的标准，能够在设计初期得到验证，以此类推，总体设计对应了集成测试，详细设计对应了单元测试。</p><h3 id="212-瀑布模型的缺点"><a class="markdownIt-Anchor" href="#212-瀑布模型的缺点"></a> 2.1.2 瀑布模型的缺点</h3><ol><li>需求分析是一切活动的基础，如果需求分析出现偏差，将导致后续活动放大这个偏差。但事实是，由于用户、开发者立场、经验不同、知识领域不同，对同一事物的表述不同造成的理解偏差难于避免，导致后期维护工作繁重</li><li>难于适应需求变化，一旦需求变更要重头再来</li><li>从需求提出到最后看到产品是一个相当长的过程，不能及时给用户反馈，并验证是否是能够满足客户需求的软件。</li><li>瀑布模型是面向文档的开发模型，过程中将产生大量文档，大部分对客户没有意义，但却工作量繁重</li></ol><h2 id="22-演化模型"><a class="markdownIt-Anchor" href="#22-演化模型"></a> 2.2 演化模型</h2><p>演化模型是在瀑布模型难以一次性完全理解用户需求的基础上，对整个过程进行若干次的“瀑布模型”迭代，做到不断渐进、不断深入的过程</p><h2 id="23-螺旋模型"><a class="markdownIt-Anchor" href="#23-螺旋模型"></a> 2.3 螺旋模型</h2><p>螺旋模型是在瀑布模型和演化模型结合的基础上，还强调其他模型忽略的风险分析。<br>特点：</p><ol><li>螺旋模型对每一期都包含需求定义、风险分析、工程实现、和评审4个阶段，对整个过程进行螺旋式迭代</li><li>支持用户需求的动态变化，为用户参与软件开发的所有关键决策提供方便，降低软件开发风险</li></ol><p>缺点：</p><ol><li>螺旋模型的风险评估需要具有丰富风险评估经验和专业知识的人，否则将造成重大损失</li><li>过多的迭代次数会增加开发成本，延迟提交时间</li></ol><h2 id="24-增量模型"><a class="markdownIt-Anchor" href="#24-增量模型"></a> 2.4 增量模型</h2><p>演化模型是另外一种增量模型的形式。在系统架构成熟、风险较低时，可采用增量方式进行系统开发，可提前进行基础测试和系统测试，缩短出事版本的发布周期，提高用户对系统的可见度。<br>特点：</p><ol><li>增量模型，做好系统的分析和设计，对系统划分为若干不同的版本，每一个版本都是完成可用的系统，后一个版本是前一个版本的基础进行开发，扩展前一个版本的功能，同时保证每个版本增量均匀。</li><li>原型法，每一次发布都经历完成的生命周期，当用户需求很多不明确或者技术架构中很多不可知因素时，可采用原型增量法。在初始版本的原型并不考虑需求的合理性和系统稳定性，只为精准获取用户需求，一般会在后面的开发中抛弃这个原型进行完成的系统实现。</li></ol><h2 id="25-构件组装模型"><a class="markdownIt-Anchor" href="#25-构件组装模型"></a> 2.5 构件组装模型</h2><p>将系统划分为一组构件的集合，明确构件之间的关系。每个构件可以独立开发、自包容，可以是自己开发设计，也可以是第三方购买整合。最后进行构件组装的一个开发模型。<br>构件组装优点：</p><ol><li>构件自包容让系统扩展变得更加容易</li><li>良好的构件更容易重用，降低开发成本</li><li>构件力度较整个系统更小，更容易开发设计及安排工作更加灵活</li></ol><p>缺点：</p><ol><li>对构件设计需要经验丰富的架构设计师，设计不良的构件难以实现他的优点</li><li>考虑重用度是，往往会对其他方面设计做出让步，比如性能</li><li>构件组装应用是，要求程序员熟悉掌握构件，增加了开发人员的学习成本</li><li>第三方构件质量难以把控，将影响软件的质量。</li></ol><h1 id="3-统一过程模型"><a class="markdownIt-Anchor" href="#3-统一过程模型"></a> 3 统一过程模型</h1><p>统一过程（Unified Process, UP）是一种优秀的软件开发模型，可以有效地降低软件开发过程中的风险。这个开发模型的特点是每一个阶段的工作都不是绝对的，都是相互交叠配的的，但是每一个阶段都有侧重点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846811.png" alt></p><p>整个过程大致分为</p><ol><li>初始阶段，刚刚接入系统开发工作，侧重工作是明确系统目的，业务建模和需求工作</li><li>细化阶段，抽象软件逻辑模型，设计架构，侧重是分析设计工作</li><li>构件阶段，完成系统的构件，使之成为一个完整的实体，并进行测试和部署</li><li>交付阶段，软件系统需求已经完成，重点工作是对软件进行重构、修改、测试和部署</li></ol><p>整个工作内容整体包括：业务建模、需求、分析设计、实施、测试、部署、配置与变更管理、项目管理、环境。</p><p>其中“环境”是相对于其他工作难以理解的。环境工作很重要，也称之为环境管理。在软件开发过程中，需要为各种工作准备相应的工作环境，在工作环境中包含必须的工具、活动指南、活动流程规范、工作产品模板、基本的开发设施等。环境管理应该在工作流中得到应有的重视，每个开发团队都有自己的特点和活动准则规范，这种准则和规范是团队协作的基础，万万不能少，否则开发活动就会使放养式的管理。</p><p>** UP的生命周期**<br>分为4个里程碑</p><ol><li>目标里程碑。明确系统的目标和范围时达到这个里程</li><li>架构里程碑。当开发者确定稳定系统的架构时达到这个里程</li><li>能力里程碑。当系统已经足够稳定和成熟并完成了Alpha测试之后达到这个里程碑</li><li>发布里程碑。当完成系统的测试、完成系统的发布和用户培训工作之后达到这个里程碑</li></ol><p>UP的特点：</p><ol><li>UP是一个迭代的二维开发模型，每个生命后期都可以进行需求、设计、开发等</li><li>采用不同的迭代方式的UP可以演变为演化模型或增量模型</li><li>UP的迭代特点使得更容易控制开发风险</li><li>Up是迭代开发模型，但不属于敏捷开发模型。一般未经过裁剪的Up是一个重载过程</li><li>实际应用可根据具体问题进行UP的裁剪，从而使用各种规模的软件和开发团队</li></ol><p>架构师在UP活动中的作用<br>架构师除了需要建立系统的架构模型外，在UP活动中承担非常重要的角色，例如：</p><ol><li>同需求人员和项目管理人员密切协作</li><li>细化软件架构</li><li>保持整个架构的概念完整性，具体地说就是定义设计方法、设计指南、编码规范、平舌工作<br><strong>因此有人称UP是一个已加购书为中心的开发模型。</strong></li></ol><h1 id="4-敏捷开发方法"><a class="markdownIt-Anchor" href="#4-敏捷开发方法"></a> 4 敏捷开发方法</h1><p>2001年，17位“无政府主义者”共同发表了《敏捷软件开发宣言》：</p><blockquote><ol><li>尽早地、持续地向客户交付有价值的软件对开发人员来说是最重要的。</li></ol></blockquote><ol start="2"><li>拥抱变化，即使在开发的后期。敏捷过程能够驾驭变化，保持客户的竞争力。</li><li>经常交付可工作的软件，从几周到几个月，时间范围越小越好。</li><li>在整个项目中，业务人员和开发者紧密合作。</li><li>围绕士气高昂的团队进行开发，为团队成员提供适宜的环境，满足他们的需要，并给予<br>足够的信任。</li><li>在团队中，最有效率的、也是效果最好的沟通方式是面对面地交流。</li><li>可以工作的软件是进度首要的度量方式。</li><li>可持续地开发。投资人、开发团队和用户应该保持固定的节奏。</li><li>不断追求优秀的技术和良好的设计有助于提高敏捷性。</li><li>要简单，尽可能减少工作量。减少工作量的艺术是非常重要的。</li><li>最好的架构、需求和设计都来自于一个自我组织的团队。</li><li>团队要定期地总结如何能够更有效率，然后相应地自我调整</li></ol><p>这份宣言就是敏捷开发方法的灯塔</p><h2 id="41-敏捷开发方法实践之极限编程extreme-programming"><a class="markdownIt-Anchor" href="#41-敏捷开发方法实践之极限编程extreme-programming"></a> 4.1 敏捷开发方法实践之极限编程（eXtreme Programming）</h2><p>极限编程（XP）是一种轻量（敏捷）、高效、低风险、柔性、可预测、科学而且充满乐趣的软件开发方法。特点如下：</p><ol><li>在更短的周期内，更早地提供具体、持续的反馈信息。</li><li>迭代地进行计划编制。在最开始迅速形成总体计划，然后开发过程中不断迭代发展它</li><li>依赖自动化测试程序来监控开发进度，尽早地铺货缺陷</li><li>依赖口头交流、测试和源程序进行沟通</li><li>倡导持续的、演化式的设计</li><li>依赖于开发团队内部的紧密协作</li><li>尽可能达到程序员的短期利益和长期利益的平衡。即关注短期程序员的自主设计和参与感，同时帮助程序员长期的成长</li></ol><p>四大价值观：沟通、简单、反馈、勇气</p><ol><li>沟通。通常，程序员相对内向，不善言谈，项目中的许多问题都发生在缺乏良好的沟通上。而传统的开发方法中并不太在意这种口头的沟通，而是希望通过完善的流程和面面俱到的文档、报表、计划来代替，这同时就引入了效率不高的问题，往往一个小问题通过漫长的流程下来被放大。而XP方法认为，如果小组内成员无法做到持续的、无间断的交流，协作就无从谈起，XP鼓励大家进行口头的面对面交流快速解决问题，提高效率。</li><li>简单。XP方法的工作中秉承“够用即好”，实现尽可能简单化，不要过度设计。这一点看上去容易，但要做到其实很淡，因为在传统的开发过程中需要开发人员对未来做一些预先的规划，以便后续做扩展预留空间，这是一个平衡的过程，并不是一点都不考虑未来的可扩展性，所以比较难做到</li><li>反馈。传统的开发过程中缺乏对客户必要的反馈，整个开发过程像一个“黑盒子”，过程漫长，完全看不到效果和进度。容易造成最终偏离用户需求的系统软件。XP注重反馈的作用，通过持续的、明确的反馈来暴露软件当前的状态和问题，尽早地纠正一些可以避免的错误。</li><li>勇气。在XP方法中，要有勇气面对每时每刻的变化带来的挑战。由于提倡良好的沟通，会有更多的需求调整；由于提倡系统保持简单，需求变更导致的重构；由于提倡尽早反馈，更多地发现问题并纠正。而面对这些带来的挑战，我们更需要为之提高勇气。因为相比于沟通、简单和反馈带来的挑战，更多的我们是得到了良好的信息同步，尽早地发现了问题，更清晰地理解了用户需求，以及更简单地实现了系统软件。</li></ol><p>XP的四大价值观之下，隐藏着一种更深刻的东西，那就是尊重，对人的尊重。因为这一切都是建立在团队成员之间的相互关系、相互理解的基础之上。</p><h3 id="411-极限编程的十二个最佳实践"><a class="markdownIt-Anchor" href="#411-极限编程的十二个最佳实践"></a> 4.1.1 极限编程的十二个最佳实践</h3><ol><li><p>计划游戏。主要思想是先快速制定一份概要计划，然后随着项目细节的不断清醒，在逐步完善这份计划。“客户负责业务决策，开发负责计算决策”，也就是说系统的范围、下一次迭代发布的时间、用户股市的优先级应有客户决定，而每个用户故事所需的而开发时间、技术成本、如何组件团队、以及开发顺序应有开发团队决定。</p><blockquote><p>计划游戏开始，客户和开发同坐一屋子，每个人准备一支笔、一些用于记录用户需求的纸片，再准备一个白板就可以开始了。</p><ol><li>客户编写需求故事：由客户谈论系统应该完成什么功能，然后用自然语言词汇写在卡片上</li><li>开发人员进行评估：有客户按优先级将故事需求标注为必须有、希望有、如果有三类，然后又开发人进行估算，优先级由高到低。如果估算的时候感到故事需求太大，不容易估算或者超过2人/周，那么应该进行分解在进行评估</li><li>确定迭代周期：根据用户期望的需求优先级、期望发布的时间结合开发现有资源与用户协商，筛检出能够实现的需求，形成初步的需求计划。</li></ol></blockquote></li><li><p>小型发布。XP方法秉承“持续集成，小步快走”的哲学思维，也就是说每次发布的版本尽可能肖，当然前提是每个版本都有发布的商业价值，值得发布。</p></li><li><p>隐喻。相对而言，隐喻这个令人费解，什么时隐喻呢，字面意思是用来暗示字面意义不相似的事物之间相似的东西。对应到开发过程中就是，需要寻求共识，对系统理解、目标价值以等；还有就是发明共享词汇，通过规范项目中常用通用的业务专有名词，减少不必要的沟通；描述体系结构；并不是每一种情况都能找到合适的隐喻，没必要强求，而是顺其自然。</p></li><li><p>简单设计。强调简单的价值观，引出简单性假设原则。这里说的简单设计并不是忽略设计而是设计不应该一次完成，因为随着业务的变化，可能当时设想的可预知的未来根本就是不存在的，留有适当的扩展设计并满足现有需求的简单设计原则。</p></li><li><p>测试先行。是指注重测试用例程序的编写，不能因为没有时间，工作紧张为由忽略测试工作，这样就会由于没有良好的测试用例而化大把的时间在后续的联调维护阶段，实际上这个整体上市大大降低产能、效率埂底下的做法。</p></li><li><p>重构。重构是一种对待吗进行重写而不影响功能实现的的技术，XP要求在开发人员“问到代码的坏味道”时，就有重构代码的勇气。重构的目的是让代码降低因变化引起的风险、使得代码更加易于维护和阅读。</p></li><li><p>结对编程。一开始虽然会牺牲一些速度，但慢慢的，开发速度会逐步加快，究其原因是结对编程大大降低了沟通成本，提高了工作的质量，具体表现在：</p><ol><li>所有的设计决策确保不是一个人做出来的</li><li>系统的任何部分至少有2个人以上熟悉</li><li>不能能同时2个人都忽略测试项</li><li>阶段的动态性，是一个去也知识管理的好途径</li><li>代码总是能够保证评审通过</li><li>XP方法集成的吉他最佳实践能够是的结对编程更加容易进行</li><li>编码标准能够消除一些无谓的分歧</li><li>隐喻可以帮助结对伙伴更好沟通</li><li>简单设计能够是的伙伴更了解他们所从事的工作</li></ol><p>结对编程技术被誉为XP保持工作质量、强调人文主义的一个典型实践，能够是的开发团队之间的协作更加流畅、知识交流更加频繁、团队更加稳定。</p></li><li><p>集体代码所有制。有XP方法鼓励团队进行结对编程，而且编程组是动态搭配的，每个人会遇到不同的代码，代码所有制就不是局限于某一个人，而是集体所有制，团队中的每个人都有进行修改的权利，每个人都拥有全部代码，也都需要对全部代码负责。同时XP强调代码是谁该坏的就应该有谁来修复。</p></li><li><p>持续集成。持续集成是最佳实践的基本支撑条件。</p></li><li><p>每周工作40小时。这是一个让开发者开心、管理者反对的一个最佳实践。加班早已成为开发人员的家常便饭，也是管理者最常用的一种策略。而XP方法认为，加班会扼杀团队的积极性，最终导致项目失败，这也体现了XP方法是关注人的因素比关注过程的因素更多一些。这里说的40小时不是绝对的额，是指根据团队公司合理的工作时长。提倡追求有效的、高效的工作时间，而不是绝对的时长。</p></li><li><p>现场客户。为了保证开发出来的结果与客户的预想接近，XP方法认为最重要的是将客户请到现场，保持和客户的现场沟通，并让客户参与到开发决策中来。</p></li><li><p>编码标准。拥有编码标准可以避免团队无关细节的争论。不过这个标准不是越细越好，而是要能够确保代码清晰，便于交流的一个指导方针。</p></li></ol><p>XP方法最大价值在于项目中融会贯通地运用这12个最佳实践，而非单独使用。当然可以使用其中一些实践，单并不意味这就应用了XP方法。</p><h2 id="42-特征驱动开发方法"><a class="markdownIt-Anchor" href="#42-特征驱动开发方法"></a> 4.2 特征驱动开发方法</h2><p>FDD也是一个迭代的开发模型。FDD每一步都强调质量，不断地交付可运行的软件，并以很小的开发提供准确的项目进度报告和状态信息。同敏捷开发一样，FDD弱化了过程在软件开发的地位。</p><h3 id="421-fdd的角色定义"><a class="markdownIt-Anchor" href="#421-fdd的角色定义"></a> 4.2.1 FDD的角色定义</h3><p>FDD认为，有效的软件开发不可或缺的三个要素是：人、过程和技术。软件开发不能没有过程，也不能没有技术，但最重要的还是人。定义了6中关键角色：</p><ol><li>项目经理。项目开发的组织者，是团队的保护屏障，提供一个适宜的开发环境。</li><li>首席架构设计师。负责系统的架构设计</li><li>开发经理。负责团队日常的开发工作的安排，解决开发过程中的技术问题和资源冲突</li><li>主程序员。主程序员将带领小组完成特征的详细设计和构件工作，一般要求主程序员具有一定的工作经验，并能够带动小组工作。</li><li>程序员。若干个程序员在主程序员带领下完成小组的开发，按照特征开发疾患完成开发</li><li>领域专家。领域专家是指对业务精通的人，一般有客户、系统分析师担当。</li></ol><h3 id="422-fdd的最佳实践"><a class="markdownIt-Anchor" href="#422-fdd的最佳实践"></a> 4.2.2 FDD的最佳实践</h3><p>FDD最佳实践包括：领域对象建模、根据特征进行开发、类的个体所有、组成特征小组、审查、定期构造、配置管理、结果的可见性<br>其中最有特色的是个体所有，激活所有的而开发模型都是代码共有。但在FDD中，将类分配给特定的任何小组，分配给A小组的代码只能由A来维护，除A外的角色都不能修改它，只能使用它。<br>优点是：</p><ol><li>这个类的支配感会促使开发人员产生自豪感，从而更出色地完成任务。不过FDD也提到了类q</li><li>审查也是FDD中很具特设的一项实践。不少人认为审查是非常严格的软件过程特有的，然而FDD中明确将审查作为一项最佳实践。审查是一种很有效的发现缺陷的手段，但经常被忽视，国内的软件组织中很少有严格的审查制度保障软件质量。在开发阶段的代码审查机制能够很好的避免潜在的问题。</li></ol><p>缺点：</p><ol><li>项目依赖关系增强，形成代码黑盒，除了负责人没人能修改。</li></ol><h2 id="43-scrum"><a class="markdownIt-Anchor" href="#43-scrum"></a> 4.3 Scrum</h2><p>Scrum是一个用于开发和维护复杂产品框架，是一个增量的、迭代的开发过程。由若干个迭代周期组成，一个短的迭代周期成为Sprint,每个Sprint的建议周期在2到4周。在Scrum中，使用产品的Backlog来管理产品的需求，产品Backlog是一个按商业价值拍下的需求列表。<br>Scrum团队重产品的Backlog中挑选优先级最高的需求进行开发。<br>挑选的需求在sprint的计划会议上进行讨论、分析和估算得到相应的任务列表，称之为Sprint backlog.</p><h3 id="431-scrum的5个活动"><a class="markdownIt-Anchor" href="#431-scrum的5个活动"></a> 4.3.1 Scrum的5个活动</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846916.png" alt></p><ol><li><p>产品待办事项的梳理——Prodct Backlog. 产品待办事项通常会很多，也很宽泛，而且想法会变来变去、优先级也会变化，所以产品待办事项列表的梳理是一个贯穿整个Scrum项目的活动。梳理包括：整理需求、优先级排序、事项分解、归并以及商业价值分析等。待办事项的梳理最好是所有团队成员参与，因为有可能需要其他技术或者团队的参与，而不是单单产品经理。</p></li><li><p>Sprint计划会议。每个Sprint工作周期以Sprint计划会议作为开始，让团队共同选择和理解即将到来的Sprint工作事项. Sprint计划会议的成功十分依赖产品待办事项列表的质量。Sprint计划会议工作内容有两部分：</p><ol><li>需要完成那些工作：产品负责人介绍排好序的代办事项，让整个Scrum团队共同理解这些工作。而产品待办事项的数目完全有开发团队决定，开发团队要考虑当天产品的增量状态，团队过去的工作情况，当前生产力等，产品负责人不能强加更多的工作量。</li><li>如何完成工作：开发团队根据当前的“完成的定义”一起决定如何实现一个产品增量，进行任务分解，前几天的工作分解成小单元，每个单元不超过一天，之后的任务可以稍微大一些，以后再对它进行分解。总之产品和开发团队一起考虑斌讨论产品待办事项，确保每个人对事项的理解一致，最终产出待办事项列表就是“Sprint 待办事项列表”，称之为Sprint Backlog</li></ol></li><li><p>每日Scrum会议。开发团队自组织，通过每日Scrum会议来确认他们任然可以实现Sprint的目标，每个人说下三点内容：上一个工作日完成了什么、当前工作日计划完成什么、有什么阻碍或风险。一般不超过15分钟。</p></li><li><p>Sprint评审会议。一个Sprint周期结束时，Scrum团队和相关人员一起评审Sprint的产出，Sprint评审会议向每个人展示当前的产品增量情况，帮助大家了解我们目前的进度到哪里，讨论他们在Sprint过程中看到了什么、有什么想法，并一起探讨下一步如何更好的推进。</p></li><li><p>Sprint回顾会议。每个Sprint周期结束之后，Scrum团队开回顾会议，目的是回顾一下团队在流程人际关系及工作方面做得如何，识别出团队中做得好的与不好的，并找潜在可以改进的事项，为将来的Sprint提供改进的计划</p></li></ol><h3 id="432-scrum的5大价值观"><a class="markdownIt-Anchor" href="#432-scrum的5大价值观"></a> 4.3.2 Scrum的5大价值观</h3><ol><li>承若——愿意对目标负责</li><li>专注——把你的心思和能力都用到你承诺的工作上去</li><li>开放——Scrum把项目中的一切开放给每个人看，做到信息透明</li><li>尊重——每个人都有他独特的背景和经验，尊重每个人的特点</li><li>勇气——有勇气做出承诺，履行程度，接受别人的尊重</li></ol><h2 id="44-水晶方法"><a class="markdownIt-Anchor" href="#44-水晶方法"></a> 4.4 水晶方法</h2><p>水晶方法有七大体系特征：</p><ol><li>经常交付。没过一段时间或者几个月向用户交付可测试运行的代码，让用户有机会发现原来需求是否是他真正想要的，有机会将结果反馈到开发中。</li><li>反思改进。开发过程中难免会遇到一些技术难题、各种烦心事，会影响项目进度，所以我们应该经常在迭代中及时地进行反思和改进，从慌乱的日常开发中，抽一点时间来思考更为行之有效的方法。</li><li>渗透式交流。渗透式交流就是信息交流在团队成员中形成背景听觉，使得成员就像通过渗透一样获取相关信息。团队通过在一个共同的工作空间内，若其中一个成员提出问题，其他成员可以选择关注或不关注，也可以随时加入到讨论中来，选择性地获取相关交流的信息。</li><li>个人安全。当你勇敢指出了困扰你的问题时，你可以不用担心受到报复，应该有保护机制，鼓励大家发现和改正自身的缺点，而不是知而不言，这样就会对团队造成损害，不利于整个团队的协作和稳定。</li><li>焦点。也叫聚焦，明确知道要做什么，然后再安排时间，确保团队成员都清楚地了解他们自己最重要的任务是什么，确保他们能够充分利用时间去完成这些任务。</li><li>与专家用户简历方便的联系。与专家用户简历方便的联系能够给团队提供很好的帮助，例如对业务的专业理解，成品的质量和快速罚款，设计理念和需求背景，用户最新的需求等。</li><li>自动化测试。自动化测试是在开发在修改代码之后能够进行自动化测试，以便发现一些bug，让开发能够及时地进行修复，节省了整体的开发时间，提高效率。</li></ol><h2 id="45-其他敏捷方法开放式源码"><a class="markdownIt-Anchor" href="#45-其他敏捷方法开放式源码"></a> 4.5 其他敏捷方法——开放式源码</h2><p>开放式源码——是指以开放源码的方式运作，特别的就是开发人员可能地域分布很广，这和其他的敏捷方法不同，开放源码的一个好处就是排错的高度并行性，任何人都可以发现错误并修改代码提交给维护者。这里面体现的价值观就是猜测、合作和学习。</p><h1 id="5-软件重用"><a class="markdownIt-Anchor" href="#5-软件重用"></a> 5 软件重用</h1><p>软件产品和其他的产品不同，是抽象的，一旦产生就可以无限地复制，因此重复利用软件产品意义重大，可以节约大量的人力物力。软件重用包括：软件产品、源代码、文档、设计思想甚至领域知识。<br>常见的重用形式：</p><ol><li>源代码重用。这是简单最常见的重用形式，由于软件系统的复杂性，很难大规模地重用已有代码</li><li>架构重用。这个重用也很常见，随着软件架构风格和设计模式的推广和应用，架构重用已经对软件开发产生了重大影响</li><li>应用框架的重用。随着技术的发展，应用框架的重用变得越来越普遍，如AOP、EJB、Spring等应用框架技术</li><li>商业建模的重用。虽然软件领域各有不同，但是人们可以总结出常用的领域建模的方法，重用这些领域建模可以降低不确定性因素风险。</li><li>文档及过程的重用。有效地重用已有的文档有助于提高开发的效率</li><li>构件的重用。如第三方的组件，中间件等</li><li>软件服务的重用。随着web服务的提出，人们越来越关注服务的重用。例如SOA架构就是一个服务重用的实践，让一类功能收归到一个服务做不同业务软件的重用服务。</li></ol><h1 id="6-基于架构的软件设计"><a class="markdownIt-Anchor" href="#6-基于架构的软件设计"></a> 6 基于架构的软件设计</h1><p>基于架构的软件设计（Architecture-Based Software Design,ABSD）是一种架构驱动的设计方法，这种方法有3个基础：</p><ol><li>功能分解。在功能分解中，ABSD方法使用已有的基于模块内聚和耦合技术</li><li>通过选择架构风格来实现质量和业务需求</li><li>软件模板的使用。软件模板利用了一些软件系统的结构。</li></ol><p>ABSB模型是吧整个过程划分为：架构需求、设计、文档化、复审、实现和演化</p><h2 id="61-absb方法与生命周期"><a class="markdownIt-Anchor" href="#61-absb方法与生命周期"></a> 6.1 ABSB方法与生命周期</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846654.png" alt></p><h2 id="62-基于架构的软件开发模型"><a class="markdownIt-Anchor" href="#62-基于架构的软件开发模型"></a> 6.2 基于架构的软件开发模型</h2><p>基于架构的软件开发模型（Architecture-Based Software Design Model，ABSDM）把整个基于架构的软件过程划分为架构需求、架构设计、架构文档化、架构复审、架构实现和架构演化6个子过程：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846024.png" alt></p><ol><li>机构需求。是指用户对目标软件在系统功能、行为、性能、设计约束方面的期望。通过用户的需求，架构师根据技术环境和架构师经验标注出所需要的构件，最后进行需求的评审。必要时“需求获取——标识构件——需求评审”之间进行迭代。</li><li>架构设计。根据架构需求提出架构的模型、映射构件、分析构件相互作用、产生架构、设计评审</li><li>架构文档化。绝大多数架构都是抽象的，有一些概念的构件组成。为了开发人员更好地理解和实现架构，必须把架构进行文档化描述</li><li>架构复审。架构设计完成之后要安排一次由外部人员（用户和领域专家）参与的复审，其目的是识别潜在的风险，及早发现架构设计中的缺陷和错误，包括架构能否满足需求、质量需求是否得到体现、是否清晰、构件是否划分合理、文档标识是否明确、以及构架设计是否满足功能和性能要求等等</li><li>架构实现。开发人员根据复审后的架构文档，分析和实现其中的构件，然后组装测试的一个过程。</li><li>架构演化。在架构开发中，用户的需求可能变动，在开发完成正常运行后，也可能发生需求变化。那么就要相应地调整架构以适应新的软件需求。主要过程包括这7个步骤：需求变动归类、架构演化计划、构件变动、更新构件的相互作用关系、构件组装和测试、技术评审、技术评审，最后得出演化后的架构设计。</li></ol><h1 id="7-形式化方法"><a class="markdownIt-Anchor" href="#7-形式化方法"></a> 7 形式化方法</h1><p>形式化方法是指采用严格的数据方法对软件的描述、开发和验证的过程进行严格规约的一种方法，通过这种方式可以需求和定义人员与开发人员的理解偏差，避免模糊性和二义性。通过形式化描述进行需求分析的质量大大提高，很多自然语言描述无法避免的缺陷在需求分析阶段就会被发现并等到解决，从而降低了后期的开发和维护的成本。形式化描述可以通过计算计算进行自动处理（一些专业软件），进行一致性检查和证明。<br>一般一些安全要求较高的，如地铁、高铁、航空、核电等软件会考虑使用这种开发方法来保证系统的安全和可靠性。</p>]]></content>
      
      
      <categories>
          
          <category> 软考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Idea maven 插件安装</title>
      <link href="/ruan-jian-bi-ji/idea-maven-cha-jian-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/idea-maven-cha-jian-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>默认idea 是已经安装好了maven插件的，在File&gt;settings&gt;能搜索到maven的相关配置<br>但是有时候它会莫名其妙的不见了或消失<br>检查Plugins是否启用了maven<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183122891.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 8常用转换</title>
      <link href="/ruan-jian-bi-ji/java-8-chang-yong-zhuan-huan/"/>
      <url>/ruan-jian-bi-ji/java-8-chang-yong-zhuan-huan/</url>
      
        <content type="html"><![CDATA[<h1 id="1-list转map"><a class="markdownIt-Anchor" href="#1-list转map"></a> 1. List转Map</h1><pre class="highlight"><code class>/** * List -&gt; Map * 需要注意的是： * toMap 如果集合对象有重复的key，会报错Duplicate key .... *  apple1,apple12的id都为1。 *  可以用 (k1,k2)-&gt;k1 来设置，如果有重复的key,则保留key1,舍弃key2 */Map&lt;Integer, Apple&gt; appleMap = appleList.stream().collect(Collectors.toMap(Apple::getId, a -&gt; a,(k1,k2)-&gt;k1));</code></pre><h1 id="list分组成map"><a class="markdownIt-Anchor" href="#list分组成map"></a> List分组成Map</h1><pre class="highlight"><code class>//List 以ID分组 Map&lt;Integer,List&lt;Apple&gt;&gt;Map&lt;Integer, List&lt;Apple&gt;&gt; groupBy = appleList.stream().collect(Collectors.groupingBy(Apple::getId)); System.err.println(&quot;groupBy:&quot;+groupBy);{1=[Apple{id=1, name='苹果1', money=3.25, num=10}, Apple{id=1, name='苹果2', money=1.35, num=20}], 2=[Apple{id=2, name='香蕉', money=2.89, num=30}], 3=[Apple{id=3, name='荔枝', money=9.99, num=40}]}</code></pre><h1 id="3-map转list"><a class="markdownIt-Anchor" href="#3-map转list"></a> 3. Map转List</h1><pre class="highlight"><code class>List&lt;Long&gt; skuIdList = order.getItemList().stream().map(OrderItemDTO::getSkuId).collect(Collectors.toList());</code></pre><h1 id="4-统计求和"><a class="markdownIt-Anchor" href="#4-统计求和"></a> 4. 统计求和</h1><pre class="highlight"><code class>//计算 总金额BigDecimal totalMoney = appleList.stream().map(Apple::getMoney).reduce(BigDecimal.ZERO, BigDecimal::add);System.err.println(&quot;totalMoney:&quot;+totalMoney);  //totalMoney:17.48</code></pre><h1 id="5-最大值-最小值"><a class="markdownIt-Anchor" href="#5-最大值-最小值"></a> 5. 最大值、最小值</h1><pre class="highlight"><code class>Optional&lt;Dish&gt; maxDish = Dish.menu.stream().      collect(Collectors.maxBy(Comparator.comparing(Dish::getCalories)));maxDish.ifPresent(System.out::println); Optional&lt;Dish&gt; minDish = Dish.menu.stream().      collect(Collectors.minBy(Comparator.comparing(Dish::getCalories)));</code></pre><h1 id="6-过滤map"><a class="markdownIt-Anchor" href="#6-过滤map"></a> 6. 过滤Map</h1><pre class="highlight"><code class>//Map -&gt; Stream -&gt; Filter -&gt; MAPMap&lt;Integer, String&gt; collect = map.entrySet().stream().filter(x -&gt; x.getKey() == 2).collect(Collectors.toMap(x -&gt; x.getKey(), x -&gt; x.getValue()));</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java bean的Getter Setter 自动编译生成工具Lombok</title>
      <link href="/ruan-jian-bi-ji/java-bean-de-getter-setter-zi-dong-bian-yi-sheng-cheng-gong-ju-lombok/"/>
      <url>/ruan-jian-bi-ji/java-bean-de-getter-setter-zi-dong-bian-yi-sheng-cheng-gong-ju-lombok/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2><p>我们在开发过程中，通常都会定义大量的JavaBean，然后通过IDE去生成其属性的构造器、getter、setter、equals、hashcode、toString方法，当要对某个属性进行改变时，比如命名、类型等，都需要重新去生成上面提到的这些方法，那Java中有没有一种方式能够避免这种重复的劳动呢？答案是有，lombok插件</p><h2 id="idea插件安装lombok"><a class="markdownIt-Anchor" href="#idea插件安装lombok"></a> Idea插件安装lombok</h2><ol><li>File &gt; Settings &gt; Plugins &gt; Browse repositories… &gt; Search for “lombok” &gt; Install Plugin</li><li>在使用项目中引入lombok 的类库</li></ol><pre class="highlight"><code class>&lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.16.10&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;</code></pre><h2 id="使用"><a class="markdownIt-Anchor" href="#使用"></a> 使用</h2><p><strong>@Getter / @Setter</strong></p><p>可以作用在类上和属性上，放在类上，会对所有的非静态(non-static)属性生成Getter/Setter方法，放在属性上，会对该属性生成Getter/Setter方法。并可以指定Getter/Setter方法的访问级别。</p><p><strong>@EqualsAndHashCode</strong></p><p>默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。</p><p><strong>@ToString</strong></p><p>生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。</p><p><strong>@NoArgsConstructor, @RequiredArgsConstructor and @AllArgsConstructor</strong></p><p>无参构造器、部分参数构造器、全参构造器，当我们需要重载多个构造器的时候，Lombok就无能为力了。</p><p><strong>@Data</strong></p><p>@ToString, @EqualsAndHashCode, 所有属性的@Getter, 所有non-final属性的@Setter和@RequiredArgsConstructor的组合，通常情况下，我们使用这个注解就足够了。<br>  <br>  ## 原理<br>  该插件的原理是在编码过程中屏蔽bean的getter/setter 方法，在编译成class的时候插件自动根据注解生成对应的gettter/setter 方法，我们通过发编译源码发现</p><pre class="highlight"><code class>@Datapublic class Test {    private String id;    private String name;    public void test(){        this.getId();    }}</code></pre><p>编译后等价于</p><pre class="highlight"><code class>public class Test {    private String id;    private String name;    public void test() {        this.getId();    }    public Test() {    }    public String getId() {        return this.id;    }    public String getName() {        return this.name;    }    public void setId(String id) {        this.id = id;    }    public void setName(String name) {        this.name = name;    }    public boolean equals(Object o) {        if(o == this) {            return true;        } else if(!(o instanceof Test)) {            return false;        } else {            Test other = (Test)o;            if(!other.canEqual(this)) {                return false;            } else {                String this$id = this.getId();                String other$id = other.getId();                if(this$id == null) {                    if(other$id != null) {                        return false;                    }                } else if(!this$id.equals(other$id)) {                    return false;                }                String this$name = this.getName();                String other$name = other.getName();                if(this$name == null) {                    if(other$name == null) {                        return true;                    }                } else if(this$name.equals(other$name)) {                    return true;                }                return false;            }        }    }    protected boolean canEqual(Object other) {        return other instanceof Test;    }    public int hashCode() {        boolean PRIME = true;        byte result = 1;        String $id = this.getId();        int result1 = result * 59 + ($id == null?43:$id.hashCode());        String $name = this.getName();        result1 = result1 * 59 + ($name == null?43:$name.hashCode());        return result1;    }    public String toString() {        return &quot;Test(id=&quot; + this.getId() + &quot;, name=&quot; + this.getName() + &quot;)&quot;;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发环境准备</title>
      <link href="/ruan-jian-bi-ji/java-kai-fa-huan-jing-zhun-bei/"/>
      <url>/ruan-jian-bi-ji/java-kai-fa-huan-jing-zhun-bei/</url>
      
        <content type="html"><![CDATA[<p>JDK下载地址：<br><a href="https://github.com/frekele/oracle-java/releases" target="_blank" rel="noopener">https://github.com/frekele/oracle-java/releases</a></p><p>idea激活：<br><a href="https://juejin.im/post/5df8a5a5e51d4557f0460990" target="_blank" rel="noopener">https://juejin.im/post/5df8a5a5e51d4557f0460990</a></p><p>maven环境变量配置：<br><a href="https://www.cnblogs.com/tanjiyuan/p/11010998.html" target="_blank" rel="noopener">https://www.cnblogs.com/tanjiyuan/p/11010998.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Selenium</title>
      <link href="/ruan-jian-bi-ji/selenium/"/>
      <url>/ruan-jian-bi-ji/selenium/</url>
      
        <content type="html"><![CDATA[<h1 id="selenium安装环境搭建"><a class="markdownIt-Anchor" href="#selenium安装环境搭建"></a> Selenium安装环境搭建</h1><p><a href="https://www.zybuluo.com/mwumli/note/222253" target="_blank" rel="noopener">https://www.zybuluo.com/mwumli/note/222253</a></p><h2 id="遇到问题"><a class="markdownIt-Anchor" href="#遇到问题"></a> 遇到问题</h2><p>报-13权限问题时</p><pre class="highlight"><code class>sudo npm install --unsafe-perm -g polymer-cli</code></pre><p>adb找不到设备时</p><pre class="highlight"><code class>adb kill-serveradb start-serveradb devices</code></pre><h1 id="元素定位"><a class="markdownIt-Anchor" href="#元素定位"></a> 元素定位</h1><p>find_element_by_android_uiautomator<br><a href="https://blog.csdn.net/weixin_30824277/article/details/95229071" target="_blank" rel="noopener">https://blog.csdn.net/weixin_30824277/article/details/95229071</a></p><h1 id="三种等待方式详解"><a class="markdownIt-Anchor" href="#三种等待方式详解"></a> 三种等待方式详解</h1><p><a href="http://blog.csdn.net/ping523/article/details/53419622" target="_blank" rel="noopener">http://blog.csdn.net/ping523/article/details/53419622</a></p><p><a href="http://www.cnblogs.com/BigFishFly/p/6380024.html" target="_blank" rel="noopener">http://www.cnblogs.com/BigFishFly/p/6380024.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis批量删除命令</title>
      <link href="/ruan-jian-bi-ji/redis-pi-liang-shan-chu-ming-ling/"/>
      <url>/ruan-jian-bi-ji/redis-pi-liang-shan-chu-ming-ling/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Redis中有指定多个key批量删除的命令,却没有指定模糊key批量删除命令</p></blockquote><p>批量删除多个key</p><pre class="highlight"><code class>del key1 key2</code></pre><p>通过通配符&quot;*&quot;模糊匹配删除的lua脚本命令</p><pre class="highlight"><code class># 模糊删除eval &quot;local keys = redis.call('keys', ARGV[1]) for i=1,#keys,5000 do redis.call('del', unpack(keys, i, math.min(i+4999, #keys))) end return #keys&quot; 0 'key_*'</code></pre><p>其中<code>key_*</code>就是要模糊匹配的key</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker命令笔记</title>
      <link href="/ruan-jian-bi-ji/docker-ming-ling-bi-ji/"/>
      <url>/ruan-jian-bi-ji/docker-ming-ling-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="制作自己的镜像"><a class="markdownIt-Anchor" href="#制作自己的镜像"></a> 制作自己的镜像</h1><p>从互联网拉取镜像</p><pre class="highlight"><code class>docker pull centos:7</code></pre><p>启动容器</p><pre class="highlight"><code class>docker run -it -d centos:7 /bin/bash</code></pre><p>进入启动容器</p><pre class="highlight"><code class>docker exec -it -v /data/soft:/data/soft centos:7 /bin/bash</code></pre><p>在容器中安装jdk</p><pre class="highlight"><code class>yum -y list java*docker yum -y java-11-openjdk.x86_64</code></pre><p>将容器提交到镜像仓库</p><pre class="highlight"><code class>docker commit centos:7 okeeper:centos7  #将正在运行的容器打包为镜像</code></pre><p>将镜像导出为文件</p><pre class="highlight"><code class>docker save -o ./okeeper-centos7.tar okeeper:centos7</code></pre><h1 id="在java项目中配置maven自动构建镜像"><a class="markdownIt-Anchor" href="#在java项目中配置maven自动构建镜像"></a> 在java项目中配置maven自动构建镜像</h1>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker ES安装</title>
      <link href="/ruan-jian-bi-ji/docker-es-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/docker-es-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>参考docker安装Elasticsearch官方文档<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html</a></p><h1 id="获取镜像"><a class="markdownIt-Anchor" href="#获取镜像"></a> 获取镜像</h1><pre class="highlight"><code class>docker pull docker.elastic.co/kibana/kibana:7.16.0</code></pre><h1 id="docker-compose启动"><a class="markdownIt-Anchor" href="#docker-compose启动"></a> docker-compose启动</h1><h2 id="新建docker-composeyml文件"><a class="markdownIt-Anchor" href="#新建docker-composeyml文件"></a> 新建docker-compose.yml文件</h2><pre class="highlight"><code class>version: '2.2'services:  es01:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es01    environment:      - node.name=es01      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es02,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9200#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es01/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es01/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es01/logs:/usr/share/elasticsearch/logs#      - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9200:9200    networks:      - elastic  es02:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es02    environment:      - node.name=es02      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9201#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es02/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es02/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es02/logs:/usr/share/elasticsearch/logs #     - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9201:9200    networks:      - elastic  es03:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es03    environment:      - node.name=es03      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es02      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9202#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es03/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es03/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es03/logs:/usr/share/elasticsearch/logs#      - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9202:9200    networks:      - elastic  kib01:    image: docker.elastic.co/kibana/kibana:7.16.0    container_name: kib01    ports:      - 5601:5601    environment:      ELASTICSEARCH_URL: http://es01:9200      ELASTICSEARCH_HOSTS: '[&quot;http://es01:9200&quot;,&quot;http://es02:9200&quot;,&quot;http://es03:9200&quot;]'    networks:      - elastic  cerebro:    image: lmenezes/cerebro:latest    container_name: cerebro    ports:      - &quot;9000:9000&quot;    command:      - -Dhosts.0.host=http://es01:9200      - -Dhosts.1.host=http://es02:9200      - -Dhosts.2.host=http://es03:9200    networks:      - elasticvolumes:  data01:    driver: local  data02:    driver: local  data03:    driver: localnetworks:  elastic:    driver: bridge</code></pre><h2 id="启动"><a class="markdownIt-Anchor" href="#启动"></a> 启动</h2><pre class="highlight"><code class>docker-compose -f ./docker-compose.yml up d</code></pre><blockquote><p>有可能报错’failed to resolve host [es01] ’<br>This sample docker-compose.yml file uses the ES_JAVA_OPTS environment variable to manually set the heap size to 512MB. We do not recommend using ES_JAVA_OPTS in production. See Manually set the heap size.<br>解决办法，如果你用的市Mac左面版的docker,docker虚拟机内存默认是2G是不够的，调整到4G以上这个问题解决<br>![](…/images/docker ES安装/getImage-20220825184627503.png)</p></blockquote><h1 id="elasticsearch运维常用api"><a class="markdownIt-Anchor" href="#elasticsearch运维常用api"></a> elasticsearch运维常用api</h1><h2 id="查看实例健康状态"><a class="markdownIt-Anchor" href="#查看实例健康状态"></a> 查看实例健康状态</h2><pre class="highlight"><code class>http://localhost:9200/_cat/health?v</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222744486.png" alt></p><h2 id="查看集群健康状态"><a class="markdownIt-Anchor" href="#查看集群健康状态"></a> 查看集群健康状态</h2><pre class="highlight"><code class>http://localhost:9200/_cluster/health?pretty</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184627531.png" alt></p><h2 id="查询分片状态"><a class="markdownIt-Anchor" href="#查询分片状态"></a> 查询分片状态</h2><pre class="highlight"><code class>http://localhost:9200/_cat/shards/test*?v</code></pre><h1 id="elasticsearch的console常用api"><a class="markdownIt-Anchor" href="#elasticsearch的console常用api"></a> Elasticsearch的console常用api</h1><pre class="highlight"><code class></code></pre><h1 id="安装cerebro"><a class="markdownIt-Anchor" href="#安装cerebro"></a> 安装cerebro</h1><p>cerebro是Elasticsearch的可视化运维工具</p><p>docker 镜像获取</p><pre class="highlight"><code class> docker pull lmenezes/cerebro</code></pre><p>启动</p><pre class="highlight"><code class> docker run -d --name cerebro -p 9000:9000 045d7f40bf06</code></pre><p>cerebro可以看到每index的分片分布情况</p><p>浏览器打开：<a href="http://localhost:9000/" target="_blank" rel="noopener">http://localhost:9000/</a></p><h1 id="附件"><a class="markdownIt-Anchor" href="#附件"></a> 附件</h1><h2 id="问题一如果出现docker-容器假死需要强制stop时"><a class="markdownIt-Anchor" href="#问题一如果出现docker-容器假死需要强制stop时"></a> 问题一：如果出现docker 容器假死需要强制stop时</h2><pre class="highlight"><code class>停止所有的容器 docker stop $(docker ps -q)强制移除此容器 docker rm -f mysql1最后一招，强制重启docker服务service 方式重启docker服务sudo service docker restart关闭dockersudo service docker stop</code></pre><p>如果是Docker-Destop左面版，可以在设置中重启</p><h2 id="问题二elk出现unassigned_shards查看及删除"><a class="markdownIt-Anchor" href="#问题二elk出现unassigned_shards查看及删除"></a> 问题二：ELK出现unassigned_shards查看及删除</h2><p>ES的data节点异常关闭，会导致副本出现unassigned shard，致使索引状态变为yellow，甚至是red。</p><h3 id="解决办法1"><a class="markdownIt-Anchor" href="#解决办法1"></a> 解决办法1：</h3><pre class="highlight"><code class># 查询所有分片数据GET _cat/shards# 或者查询集群健康状态GET _cluster/health出现unassigned_shards大于0时表示有异常分片数据</code></pre><p>如果运气不好，遇到了主分片异常，上面的方法不管用，可以先用重试的方法尝试恢复</p><pre class="highlight"><code class>/_cluster/reroute?retry_failed=true</code></pre><p>一般data节点异常退出，该方法都能解决。</p><h3 id="解决办法2"><a class="markdownIt-Anchor" href="#解决办法2"></a> 解决办法2：</h3><p>若不起作用，可以尝试重新分配主分片，不过可能会有部分数据丢失。</p><pre class="highlight"><code class>POST /_cluster/reroute?pretty{    &quot;commands&quot; : [ {        &quot;allocate_stale_primary&quot; :            {              &quot;index&quot; : &quot;test&quot;,               &quot;shard&quot; : 3,              &quot;node&quot; : &quot;192.168.1.1_9200&quot;,              &quot;accept_data_loss&quot; : true            }        }    ]}</code></pre><h3 id="解决办法3"><a class="markdownIt-Anchor" href="#解决办法3"></a> 解决办法3：</h3><p>删除问题索引</p><pre class="highlight"><code class>curl -XDELETE localhost:9200/索引名称</code></pre><p>解决办法4：出现以上问题的原因除了同步异常外，还有一个原因可能是磁盘空间使用率大于85%。<br>es中有个配置<code>cluster.routing.allocation.disk.watermark.low</code>默认是85%，系统磁盘空间使用率大于85%将出现此问题</p><p>解决办法要么调整这个配置，要么清理磁盘</p><pre class="highlight"><code class>PUT /_cluster/settings{    &quot;transient&quot; : {        &quot;cluster.routing.allocation.disk.watermark.low&quot; : &quot;90%&quot;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>idea 突然闪退，内存溢出</title>
      <link href="/ruan-jian-bi-ji/idea-tu-ran-shan-tui-nei-cun-yi-chu/"/>
      <url>/ruan-jian-bi-ji/idea-tu-ran-shan-tui-nei-cun-yi-chu/</url>
      
        <content type="html"><![CDATA[<p>解决办法：到安装路径C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.4\bin<br>找到idea.exe.vmoptions配置修改Xmx 为合适大小1024/2048，然后启动此路径下的idea.exe</p><pre class="highlight"><code class>-Xms128m-Xmx1024m-XX:MaxPermSize=350m-XX:ReservedCodeCacheSize=240m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow</code></pre><p>** 如果你的系统是64位的，则就需要修改idea64.exe.vmoptions这个配置，然后启动idea64.exe**</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iterm2 rz sz 安装</title>
      <link href="/ruan-jian-bi-ji/iterm2-rz-sz-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/iterm2-rz-sz-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>一、本地rz sz安装<br><a href="https://github.com/aikuyun/iterm2-zmodem" target="_blank" rel="noopener">https://github.com/aikuyun/iterm2-zmodem</a></p><p>二、服务器端rz sz安装<br>yum install lrzsz</p><p>rz：从本地上传文件至服务器<br>sz filename：从服务器下载文件至本地</p><p>三、iTrm2配置<br>参考这里：<a href="https://github.com/aikuyun/iterm2-zmodem" target="_blank" rel="noopener">https://github.com/aikuyun/iterm2-zmodem</a></p><p>二、使用#<br>2.1 sz 命令发送文件到本地#<br>sz filename<br>2.2 rz 命令本地上传文件到服务器#<br>rz</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git重命名的坑</title>
      <link href="/ruan-jian-bi-ji/git-chong-ming-ming-de-keng/"/>
      <url>/ruan-jian-bi-ji/git-chong-ming-ming-de-keng/</url>
      
        <content type="html"><![CDATA[<p>如果使用git命令进行仅涉及大小写的重命名,git 默认是把你的动作忽略的，所以当你删掉本地代码，重新pull代码时，你会发现文件还是重命名之前的,神奇吧，记下这个坑，等着你们踩着坑来这看吧，坏笑/</p><p>解决方法如下：</p><ul><li>设置git库为大小写敏感（不建议）</li></ul><pre class="highlight"><code class>git config core.ignorecase false</code></pre><p>用这种方法进行重命名，用git status就可以识别出修改了，但是不推荐用这种方式，因为在更新这种修改的时候会有麻烦。</p><ul><li>使用git mv命令（仅当core.ignorecase为true时可用）</li></ul><pre class="highlight"><code class>$ git mv ABC.java Abc.java$ git status......renamed: ABC.java -&gt; Abc.java</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maven 包冲突 解决</title>
      <link href="/ruan-jian-bi-ji/maven-bao-chong-tu-jie-jue/"/>
      <url>/ruan-jian-bi-ji/maven-bao-chong-tu-jie-jue/</url>
      
        <content type="html"><![CDATA[<pre class="highlight"><code class>mvn dependency:tree -Dverbose -Dincludes=org.slf4j</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Jmeter进行Dubbo接口压测</title>
      <link href="/ruan-jian-bi-ji/shi-yong-jmeter-jin-xing-dubbo-jie-kou-ya-ce/"/>
      <url>/ruan-jian-bi-ji/shi-yong-jmeter-jin-xing-dubbo-jie-kou-ya-ce/</url>
      
        <content type="html"><![CDATA[<h1 id="软件准备"><a class="markdownIt-Anchor" href="#软件准备"></a> 软件准备</h1><h2 id="一-下载jmeter31"><a class="markdownIt-Anchor" href="#一-下载jmeter31"></a> 一、下载Jmeter3.1</h2><p>下载地址：<a href="https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-3.1.zip" target="_blank" rel="noopener">https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-3.1.zip</a><br>其他版本：<a href="https://archive.apache.org/dist/jmeter/binaries/" target="_blank" rel="noopener">https://archive.apache.org/dist/jmeter/binaries/</a></p><p>更高版本的Jmeter 5+好像有点问题，建议还是用这个版本吧</p><h2 id="二-下载dubbo官方的jmeter插件"><a class="markdownIt-Anchor" href="#二-下载dubbo官方的jmeter插件"></a> 二、下载dubbo官方的jmeter插件</h2><p>下载地址：<a href="https://gitee.com/ningyu/dist-jmeter-plugins-for-apache-dubbo/raw/master/2.7.7/jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar" target="_blank" rel="noopener">https://gitee.com/ningyu/dist-jmeter-plugins-for-apache-dubbo/raw/master/2.7.7/jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar</a><br>官方用户指南：<a href="https://github.com/thubbo/jmeter-plugins-for-apache-dubbo/wiki/%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97" target="_blank" rel="noopener">https://github.com/thubbo/jmeter-plugins-for-apache-dubbo/wiki/用户指南</a></p><h2 id="三-解压jmeter"><a class="markdownIt-Anchor" href="#三-解压jmeter"></a> 三、解压Jmeter</h2><p>将jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar放到<code>${JMETER_HOME}\lib\ext.</code>中</p><h2 id="四-启动jmeter"><a class="markdownIt-Anchor" href="#四-启动jmeter"></a> 四、启动Jmeter</h2><p><code>${JMETER_HOME}\jmeter.bat</code></p><h1 id="五-使用jmeter进行订单接口压测"><a class="markdownIt-Anchor" href="#五-使用jmeter进行订单接口压测"></a> 五、使用Jmeter进行订单接口压测</h1><h2 id="在测试计划中右键添加一个线程组设置压测的线程数及并发数"><a class="markdownIt-Anchor" href="#在测试计划中右键添加一个线程组设置压测的线程数及并发数"></a> 在测试计划中右键添加一个线程组，设置压测的线程数及并发数</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182246944.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247846.png" alt></p><h2 id="添加一个dubbo-simple测试任务"><a class="markdownIt-Anchor" href="#添加一个dubbo-simple测试任务"></a> 添加一个Dubbo Simple测试任务</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248427.png" alt></p><p>将被测试的dubbo api加入<code>${JMETER_HOME}\lib\ext.</code>中，否则paramType将找不到类，paramValue填入入参DTO的json对象，注意不能有格式，否则解析不出来，这是个坑<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248165.png" alt></p><h2 id="添加请求查看树方便查询每个请求的出入参线程组添加监听器查看结果树"><a class="markdownIt-Anchor" href="#添加请求查看树方便查询每个请求的出入参线程组添加监听器查看结果树"></a> 添加请求查看树，方便查询每个请求的出入参；线程组&gt;添加&gt;监听器&gt;查看结果树</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248034.png" alt></p><h2 id="添加测试结果汇总报告线程组添加监听器summary-report"><a class="markdownIt-Anchor" href="#添加测试结果汇总报告线程组添加监听器summary-report"></a> 添加测试结果汇总报告；线程组&gt;添加&gt;监听器&gt;Summary Report</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247230.png" alt></p><h2 id="开始压测点击启动"><a class="markdownIt-Anchor" href="#开始压测点击启动"></a> 开始压测，点击启动</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248268.png" alt></p><h2 id="结果查看压测过程中可以看到请求参数压测完之后可以压测结果一般需要经过多次压测且压测的线程和并发数多一点"><a class="markdownIt-Anchor" href="#结果查看压测过程中可以看到请求参数压测完之后可以压测结果一般需要经过多次压测且压测的线程和并发数多一点"></a> 结果查看，压测过程中可以看到请求参数，压测完之后可以压测结果，一般需要经过多次压测且压测的线程和并发数多一点</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247269.png" alt></p><h1 id="六-dubbo服务器状态查看"><a class="markdownIt-Anchor" href="#六-dubbo服务器状态查看"></a> 六、dubbo服务器状态查看</h1><ol><li>使用telnet进入dubbo的console界面</li></ol><pre class="highlight"><code class>telnet 192.168.1.131 32101后回车</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247523.png" alt><br><code>status -l</code> 查看线程状态<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247961.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Maven命令指定上传打包到私库</title>
      <link href="/ruan-jian-bi-ji/shi-yong-maven-ming-ling-zhi-ding-shang-chuan-da-bao-dao-si-ku/"/>
      <url>/ruan-jian-bi-ji/shi-yong-maven-ming-ling-zhi-ding-shang-chuan-da-bao-dao-si-ku/</url>
      
        <content type="html"><![CDATA[<p>我们一般在pom.xml中加入<code>distributionManagement</code></p><pre class="highlight"><code class>&lt;distributionManagement&gt;    &lt;repository&gt;      &lt;id&gt;internal.repo&lt;/id&gt;      &lt;name&gt;MyCo Internal Repository&lt;/name&gt;      &lt;url&gt;Host to Company Repository&lt;/url&gt;    &lt;/repository&gt;  &lt;/distributionManagement&gt;</code></pre><p>来指定setting.xml中的server私库地址，然后通过<code>mvn clean install deploy</code>打包上传</p><hr><p>但是为了子类不必要的应用，我们可以用<code>-DaltDeploymentRepository</code>来指定打包到私服的参数</p><pre class="highlight"><code class>mvn deploy -DaltDeploymentRepository=releases::default::http://198.11.174.75:8081/nexus/content/repositories/releases/</code></pre><p>上传本地jar到私库</p><pre class="highlight"><code class>mvn deploy:deploy-file -DgroupId=com.xy.Oracle -DartifactId=ojdbc14 -Dversion=10.2.0.4.0 -Dpackaging=jar -Dfile=E:\ojdbc14.jar -Durl=http://localhost:9090/nexus-2.2-01/content/repositories/thirdparty/ -DrepositoryId=thirdparty#上传小米push 到私有仓库mvn deploy:deploy-file -DgroupId=com.xiaomi -DartifactId=MiPush_SDK_Server -Dversion=2.2.18 -Dpackaging=jar -Dfile=lib/MiPush_SDK_Server_2_2_18.jar -Durl=http://198.11.174.75:8081/nexus/content/groups/public/</code></pre><p>单独构建上传模块 pingjuan-web，同时会构建上传 pingjuan-web</p><pre class="highlight"><code class>mvn clean install deploy -pl trade-center-api -ammvn clean install deploy -DaltDeploymentRepository=releases::default::http://198.11.174.75:8081/nexus/content/repositories/releases/ -pl trade-center-api -am</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抓包工具Charles安装、破解及使用</title>
      <link href="/ruan-jian-bi-ji/zhua-bao-gong-ju-charles-an-zhuang-po-jie-ji-shi-yong/"/>
      <url>/ruan-jian-bi-ji/zhua-bao-gong-ju-charles-an-zhuang-po-jie-ji-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>Charles是一款抓包必备的工具，支持Windows、Mac、手机的抓包测试，还能对https的SLL加密内容进行解密。</p><h1 id="下载安装"><a class="markdownIt-Anchor" href="#下载安装"></a> 下载安装</h1><ol><li>进入官网下载地址：<a href="http://www.charlesproxy.com/%EF%BC%8C%E7%82%B9%E5%87%BB%E9%93%BE%E6%8E%A5%E4%B8%8B%E8%BD%BD30%E5%A4%A9%E5%85%8D%E8%B4%B9%E8%AF%95%E7%94%A8%E7%89%88%E6%9C%AC%E3%80%82" target="_blank" rel="noopener">http://www.charlesproxy.com/，点击链接下载30天免费试用版本。</a><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037795.png" alt></li><li>在线破解：<br><a href="https://www.zzzmode.com/mytools/charles/" target="_blank" rel="noopener">https://www.zzzmode.com/mytools/charles/</a></li></ol><h1 id="基本使用"><a class="markdownIt-Anchor" href="#基本使用"></a> 基本使用</h1><h2 id="电脑抓包"><a class="markdownIt-Anchor" href="#电脑抓包"></a> 电脑抓包</h2><ol><li><p>打开Charles，默认是开启抓包代理的，可以看到电脑http请求的内容,你也可以将电脑的抓包代理给关掉，在Proxy&gt;enable MacOs proxy 勾选去掉<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037940.png" alt></p></li><li><p>设置https证书代理抓包，<br>安装证书：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038586.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037648.png" alt><br>打开百度<a href="https://www.baidu.com" target="_blank" rel="noopener">https://www.baidu.com</a> 测试，发现全是乱码：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038645.png" alt><br>鼠标点击右键添加Enable SLL Proxy,从新刷新页面，Google Chrome 默认把这个当成不安全证书了，使用FireFox浏览器可以添加例外强制打开：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038204.png" alt><br>可以看到Charles已经将https的内容通过Charles 证书加代理的方式能够看到明文请求信息了。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038795.png" alt></p></li></ol><h1 id="手机抓包"><a class="markdownIt-Anchor" href="#手机抓包"></a> 手机抓包</h1><ol><li><p>设置网络代理<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038117.png" alt><br>通过上面菜单找到Charles的代理服务器IP和端口<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038169.png" alt><br>保证你的手机和你的电脑是在同一个局域网内，打开手机的WLAN配置，ip为上图的30.117.52.174，端口为：12345<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038566.png" alt></p></li><li><p>如果想看到https的请求内容，还是得和电脑一样安装Charles证书，通过safari打开<a href="https://chls.pro/ssl" target="_blank" rel="noopener">https://chls.pro/ssl</a> 下载证书<br>手机–setting–&gt;General—&gt;Profiles &amp; Device Management —&gt;Charles Proxy CA…<br>将设置为信任。如图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038687.png" alt></p></li><li><p>接着就可以查看到手机上的网络请求数据了，如果是https点击右键Enable SLL Proxy，在重新刷新下就可以看到了。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>护眼神器Dark Reader</title>
      <link href="/ruan-jian-bi-ji/hu-yan-shen-qi-dark-reader/"/>
      <url>/ruan-jian-bi-ji/hu-yan-shen-qi-dark-reader/</url>
      
        <content type="html"><![CDATA[<p>在google应用市场中搜索Dark Reader，可以在网页中进行反色护眼<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182956835.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>磁盘空间满处理</title>
      <link href="/ruan-jian-bi-ji/ci-pan-kong-jian-man-chu-li/"/>
      <url>/ruan-jian-bi-ji/ci-pan-kong-jian-man-chu-li/</url>
      
        <content type="html"><![CDATA[<h1 id="查看当前目录磁盘使用情况"><a class="markdownIt-Anchor" href="#查看当前目录磁盘使用情况"></a> 查看当前目录磁盘使用情况</h1><pre class="highlight"><code class>df -lh</code></pre><h1 id="统计当前目录下的目录及文件磁盘使用从大到小排序"><a class="markdownIt-Anchor" href="#统计当前目录下的目录及文件磁盘使用从大到小排序"></a> 统计当前目录下的目录及文件磁盘使用从大到小排序</h1><pre class="highlight"><code class>du -h --max-depth=1</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>靠谱的maven仓库地址</title>
      <link href="/ruan-jian-bi-ji/kao-pu-de-maven-cang-ku-di-zhi/"/>
      <url>/ruan-jian-bi-ji/kao-pu-de-maven-cang-ku-di-zhi/</url>
      
        <content type="html"><![CDATA[<pre class="highlight"><code class>#阿里云maven&lt;mirror&gt;    &lt;id&gt;alimaven&lt;/id&gt;    &lt;name&gt;aliyun maven&lt;/name&gt;    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;#开源中国maven&lt;mirror&gt;      &lt;id&gt;nexus-osc&lt;/id&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;      &lt;name&gt;Nexus osc&lt;/name&gt;      &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;  &lt;/mirror&gt;</code></pre><blockquote><p>简单点来说，repository就是个仓库。maven里有两种仓库，本地仓库和远程仓库。远程仓库相当于公共的仓库，大家都能看到。本地仓库是你本地的一个山寨版，只有你看的到，主要起缓存作用。当你向仓库请求插件或依赖的时候，会先检查本地仓库里是否有。如果有则直接返回，否则会向远程仓库请求，并做缓存。你也可以把你做的东西上传到本地仓库给你本地自己用，或上传到远程仓库，供大家使用。<br>远程仓库可以在工程的pom.xml文件里指定，楼上两位已经列的很清楚了。如果没指定，默认就会把下面这地方做远程仓库，即默认会到<a href="http://repo1.maven.org/maven2%E8%BF%99%E4%B8%AA%E5%9C%B0%E6%96%B9%E5%8E%BB%E8%AF%B7%E6%B1%82%E6%8F%92%E4%BB%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E5%8C%85%E3%80%82" target="_blank" rel="noopener">http://repo1.maven.org/maven2这个地方去请求插件和依赖包。</a></p></blockquote><p>Xml代码</p><pre class="highlight"><code class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">snapshots</span>&gt;</span>          <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">snapshots</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>central<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>Maven Repository Switchboard<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>http://repo1.maven.org/maven2<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span>  </code></pre><p>本地仓库默认在你本地的用户目录下的.m2/repository目录下。</p><p>mirror就是镜像，主要提供一个方便地切换远程仓库地址的途径。比如，上班的时候在公司，用电信的网络，连的是电信的仓库。回到家后，是网通的网络，我想连网通的仓库，就可以通过mirror配置，统一把我工程里的仓库地址都改成联通的，而不用到具体工程配置文件里一个一个地改地址。<br>mirror的配置在.m2/settings.xml里。如：</p><pre class="highlight"><code class>&lt;mirrors&gt;    &lt;mirror&gt;      &lt;id&gt;UK&lt;/id&gt;      &lt;name&gt;UK Central&lt;/name&gt;      &lt;url&gt;http://uk.maven.org/maven2&lt;/url&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;    &lt;/mirror&gt;  &lt;/mirrors&gt;  </code></pre><p>这样的话，就会给上面id为central的远程仓库做了个镜像。以后向<code>central</code>这个仓库发的请求都会发到<code>http://uk.maven.org/maven2</code>而不是<code>http://repo1.maven.org/maven2</code>了。<br><code>&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</code>里是要替代的仓库的id。如果填*，就会替代所有仓库。</p><p>参考资料：<br><a href="http://maven.apache.org/guides/introduction/introduction-to-repositories.html" target="_blank" rel="noopener">http://maven.apache.org/guides/introduction/introduction-to-repositories.html</a><br><a href="http://maven.apache.org/guides/mini/guide-mirror-settings.html" target="_blank" rel="noopener">http://maven.apache.org/guides/mini/guide-mirror-settings.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自行搭建v2ray科学上网工具，支持mac、ios、windows</title>
      <link href="/ruan-jian-bi-ji/zi-xing-da-jian-v2ray-ke-xue-shang-wang-gong-ju-zhi-chi-mac-ios-windows/"/>
      <url>/ruan-jian-bi-ji/zi-xing-da-jian-v2ray-ke-xue-shang-wang-gong-ju-zhi-chi-mac-ios-windows/</url>
      
        <content type="html"><![CDATA[<h1 id="服务器搭建"><a class="markdownIt-Anchor" href="#服务器搭建"></a> 服务器搭建</h1><ol><li><p>购买海外VPS/ECS, 我这里用的是vultr，它家可以随时换IP、换服务器位置，无须另外收费，比较适合新手</p></li><li><p>安装v2ray服务端，有一键安装脚本，傻瓜式安装，安装时如果用的是shadowrocket客户端方式连接，安装时询问时这一步选择是即可</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%856.png" alt="img"></p></li></ol><p>详细步骤参考网上文章进行一键安装：</p><p><a href="https://xiaoheicn.top/v2ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC-233boy%E5%A4%A7%E7%A5%9E%E7%89%88%E6%9C%AC-%E5%8D%95%E7%94%A8%E6%88%B7/" target="_blank" rel="noopener">https://xiaoheicn.top/v2ray一键安装脚本-233boy大神版本-单用户/</a></p><h1 id="客户端下载"><a class="markdownIt-Anchor" href="#客户端下载"></a> 客户端下载</h1><p>因政策原因，国内apple id无法下载ssr的客户端。为了在你的iphone/ipad上下载可用的ss客户端，你需要一个境外apple id登录app store，然后再下载需要的软件。境外apple id请参考：<a href="https://v2xtls.org/%E5%A2%83%E5%A4%96apple-id%E4%BF%A1%E6%81%AF%E6%B1%87%E6%80%BB/" target="_blank" rel="noopener">境外apple id信息汇总</a>，切换apple id下载软件请参考：<a href="https://v2xtls.org/%E5%88%87%E6%8D%A2apple-id%E4%B8%8B%E8%BD%BD%E5%85%B6%E5%AE%83%E5%9B%BD%E5%AE%B6%E5%92%8C%E5%9C%B0%E5%8C%BA%E7%9A%84%E5%BA%94%E7%94%A8/" target="_blank" rel="noopener">切换apple id下载其它国家和地区的应用</a>。</p><p>app store中， <strong>免费</strong>的ssr ios客户端有：</p><ul><li>Mume（图标是一朵梅花，有红梅/黑梅两个版本，黑梅免费且内置免费节点）</li><li>Potatso Lite</li><li>NetShuttle(网际飞梭)</li><li>FastSocks</li><li>Sockswitch（没有中文界面）</li><li>shadowrock</li></ul><p><strong>免费ssr ios客户端个人推荐使用Mume和Potatso lite</strong>，简洁好用。</p><p><strong>付费</strong>的SSr ios客户端有：</p><ul><li>Shadowrocket（俗称小火箭，注意不是shadowrocket VPN）</li><li>pepi</li><li>Potasto 2</li><li>surge pro</li></ul><p><strong>付费的ssr ios客户端个人推荐Shadowrocket和pepi</strong>，两个应用都支持包括SS/SSR/V2Ray在内的等多种协议，功能强大且好用。</p><p>注意：有些shadowsocksr客户端已经下架，但app store中存在同名的应用，请注意区分，例如Waterdrop、MUME。</p><p>注意：上述列出的仅是客户端，安装后需要配置服务端信息才能科学上网。获取服务端信息请参考：<a href="https://v2xtls.org/%E8%8E%B7%E5%8F%96%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BF%A1%E6%81%AF/" target="_blank" rel="noopener">获取科学上网服务端信息</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——初识操作系统</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-chu-shi-cao-zuo-xi-tong/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-chu-shi-cao-zuo-xi-tong/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是操作系统"><a class="markdownIt-Anchor" href="#什么是操作系统"></a> 什么是操作系统</h1><p>操作系统是提供计算机用不与计算机硬件之间的使用接口，并能够管理计算机软件和硬件资源的一个复杂的系统软件，为用户的应用程序提供直接可用的运行环境，是应用程序的开发变得简单、高效。<br>试想一下如果没有操作系统，你将怎样写代码？<br>例如你要写一个实现<code>printf(&quot;hello world&quot;)</code>的功能，你要怎么实现呢？<br>无操作系统的环境下，你只能使用汇编语言直接操作硬件接口</p><pre class="highlight"><code class>xor ah,ah;//对ah、dl清零xor dl,dl;//软驱复位int13h;//BIOS功能调用int 13h中断... //此处省略n行代码mov cl,ah;//其实扇区号送cl寄存器mov dh,al;</code></pre><p>可以看出一个简单的功能，要实现一大段的代码，并且没有的计算机资源做统一的管理，极大的降低程序运行的效率和开发效率。</p><h1 id="操作系统的发展历史"><a class="markdownIt-Anchor" href="#操作系统的发展历史"></a> 操作系统的发展历史</h1><h2 id="无操作系统时代"><a class="markdownIt-Anchor" href="#无操作系统时代"></a> 无操作系统时代</h2><p>第一代计算机（1945~1955年）使用电子管作为主要电子器件，用插件版的链接先或穿孔片表示程序，没有用来存储程序的内存，无操作系统的。<br>我们熟知的那个庞然大物——人类第一台计算机&quot;艾尼阿克&quot;（ENIAC）就是这样的计算机，最初只能完成5000每秒的计算，耗电量在150千万每小时。程序的编程只能通过改变电路的链接方式来表示不同的算法，程序的运行与退出都需要人工的干预，这就是我们人类最初的计算机<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213223503151.png" alt></p><h2 id="单道批量处理计算机"><a class="markdownIt-Anchor" href="#单道批量处理计算机"></a> 单道批量处理计算机</h2><p>从第一代计算机开始大概经过了10年的发展，开始使用磁性存储设备，程序员在磁带上录入多批次的作业，交给计算机操作人员，放入计算机中批量载入计算机，计算机会一个一个计算并将结果输出到另外一个磁性设备。这一时期的操作系统就是单到批处理系统，内存红能主流移到用户作业，cup和内存资源被用户作业独占。程序是指令的集合，程序执行是cpu的依次、逐条执行指令的过程。相比于上一代计算机，减少了等待人工操作的时间，但是作业进行I/O时，CPU只能等待I/O完成而无事可做，cpu资源得不到充分利用</p><h2 id="多道批处理系统的特点"><a class="markdownIt-Anchor" href="#多道批处理系统的特点"></a> 多道批处理系统的特点</h2><p>为了解决上一代计算机的问题，有发展到了多道批处理系统。<br>与单道批处理系统相比，躲到批处理系统支持多道程序驻留内存，cpu不在因为某个进程等待I/O而空闲，而是可以去执行其他进程。</p><h2 id="分时操作系统"><a class="markdownIt-Anchor" href="#分时操作系统"></a> 分时操作系统</h2><p>分时操作系统运行多个用户通过终端同时使用计算机。分时操作系统需要解决的两个关键问题是及时接收和及时处理。分时操作系统为例保证每个用户终端的相应时间，使所有的用户任务直接进入内存，并在很短的时间内快速切换让每个任务都运行一遍，达到多个用户任务并行处理的目的。</p><h2 id="实时操作系统"><a class="markdownIt-Anchor" href="#实时操作系统"></a> 实时操作系统</h2><p>实时操作系统主要用户实时控制和实时信息处理领域。与分时系统相比，它具有多路性、独立性、及时性、交互性、可靠性几个特点。<br>实时系统比分时系统要求有更高的可靠性，必须能够在任务能够容忍的时间范围内处理完，否则可能带来巨大的经济损失设置生命安全。批处理系统、分时系统和实时系统是三种基本的草鞋系统类型，实时操作系统可能兼有三者货主其中两者的功能特征.</p><p>#操作系统的五大功能</p><h2 id="内存管理"><a class="markdownIt-Anchor" href="#内存管理"></a> 内存管理</h2><p>内存管理主要是为多道程序运行提供良好的环境，方便用户使用内存，提高内存的利用率，已经从逻辑上扩充内存以实现虚拟存储。包括内存分配、内存保护、地址映射、内存扩充功能。</p><h3 id="内存分配"><a class="markdownIt-Anchor" href="#内存分配"></a> 内存分配</h3><p>内存分配可分为静态分配和动态分配，静态是指按程序所需分配固定大小后不再变化，动态分配是指在系统运行中，根据进程的骑牛分配内存大小，是可以在运行时变化的。<br>为了实现内存分配，需要实现以下几个功能：</p><ol><li>适用于内存分配的数据结构，包含内存的使用情况，内存的空闲区大小，空闲区的起始地址，未内存分配实现提供依据。</li><li>内存分配功能。系统安装一定的内存分配算法分配内存空间。</li><li>内存回收。系统需要回收被释放的内存空间。</li></ol><h3 id="内存保护"><a class="markdownIt-Anchor" href="#内存保护"></a> 内存保护</h3><p>内存保护的任务：一是是操作系统内核的空间不会被用户随意访问，以保证系统的稳定安全。二是是没道用户程序都在自己的内存空间中运行，相对独立互不干扰。</p><h3 id="地址映射"><a class="markdownIt-Anchor" href="#地址映射"></a> 地址映射</h3><p>cpu执行程序的过程中，需要把程序的逻辑地址转变成物理地址，这个转换过程称为地址映射。</p><p>逻辑地址：是指一个程序编译后，通常会形成若干个目标程序，这些程序再经过链接而形成可装载的程序。这些程序中的指令和数据的地址都是相对于编译链接后的机器代码程序的起始地址计算的。称之为逻辑地址。</p><h3 id="内存扩充"><a class="markdownIt-Anchor" href="#内存扩充"></a> 内存扩充</h3><p>为了满足程序的更大内存需求，就要为其从逻辑上扩充更大的内存，需要实现以下功能：</p><ol><li>请求调入功能。运行系统在装入一部分用户程序是就启动该程序的运行，若在程序运行过程中发现要执行的指令货主要访问的数据没有载入内存，通过请求调入装入内存。</li><li>置换功能。在请求调入是，若发现内存空间不足，需要系统将内存中一部分内存换到外存中，以便腾出内存空间载入当前需要的内容。</li></ol><h2 id="进程管理"><a class="markdownIt-Anchor" href="#进程管理"></a> 进程管理</h2><p>进程管理主要包括：经常的组织和描述、进程的控制、进程的同步、进程同学及进程调度。例如进程的创建、销毁、唤醒、阻塞等操作。</p><h2 id="设备管理"><a class="markdownIt-Anchor" href="#设备管理"></a> 设备管理</h2><p>设备管理主要完成用户的I/O请求，未用户分配I/O设备。为了完成这些任务，设备管理需要具备以下功能：</p><ol><li>缓冲管理。</li><li>设备分配。分配用户I/O所需的设备。</li><li>设备处理。由设备驱动程序来实现cpu与设备控制之间的通讯。</li><li>设备独立性和虚拟设备。设备独立性功能是应用程序独立于物理设备。例如，用高级程序设计语言打印图形程序。</li></ol><h2 id="文件管理"><a class="markdownIt-Anchor" href="#文件管理"></a> 文件管理</h2><p>文件存储空间的管理、文件目录的管理、文件读写</p><h2 id="提供用户接口"><a class="markdownIt-Anchor" href="#提供用户接口"></a> 提供用户接口</h2><p>为了方便用户使用操作系统，操作系统向用户提供命令行和图形用户接口，向程序员提供应用程序与操作系统之间的接口。</p><h1 id="操作系统的体系结构"><a class="markdownIt-Anchor" href="#操作系统的体系结构"></a> 操作系统的体系结构</h1><p>操作系统的体系结构是一个复杂软件系统的高层结构，未软件系统提供了一个结构、行为和属性的高级抽象，包括系统元素的结构、元素拣的相互关系，以及指导元素集成的模式和约束。</p><h2 id="简单的监控程序模型"><a class="markdownIt-Anchor" href="#简单的监控程序模型"></a> 简单的监控程序模型</h2><p>最初的计算机并不存在操作系统这个概念，所有的任务都是直接运行与硬件上，程序员直接操作硬件系统。随着控制语言的出现，产生了简单的监控程序，能够保证任意时刻系统只能运行一个任务，保证对系统信息的互斥访问。</p><h2 id="单体结构模型"><a class="markdownIt-Anchor" href="#单体结构模型"></a> 单体结构模型</h2><p>在单体结构模型中，多有的软件和数据结构防止在一个逻辑模块中，对外出的用户程序提供一个完成的内核界面——系统调用。整个系统有若干个功能独立的子程序组成，运行任意一子程序调用其他子程序，因此它的特点是结构简单，便于理解和实现，而且系统所有的部分都集中在一个内核中，效期较高，缺点也很明显，各个子程序之间可以相互调用，系统结构关系复杂，容易引起循环调用和死锁。</p><h2 id="层次结构模型"><a class="markdownIt-Anchor" href="#层次结构模型"></a> 层次结构模型</h2><p>层次结构的基本思想是讲操作系统分解为多个晓得容易理解的层，系统功能被隔离在不同的层中，每一层提供对系统功能的部分抽象。在操作系统的层次结构中，各个模块都有相对固定的位置、相对固定的层次。层与层之间有间隔的接口定义，每一次值依赖于它下层提供的服务而工作，不能夸层随意访问。不过出于效率的考虑，有些系统运行夸层乡下调用。</p><h2 id="客户服务器模型与微内核结构"><a class="markdownIt-Anchor" href="#客户服务器模型与微内核结构"></a> 客户/服务器模型与微内核结构</h2><p>它的核心思想是功能外迁，即吧传统操作系统内核中的一些组成部分（如文件系统、网络、驱动程序等内核功能）放到内核之外作为一个独立的服务进程来实现，在微内核中只保留了操作系统最基本的功能，包括处理器调度、存储管理和消息通道等。</p><h2 id="动态可扩展结构模型"><a class="markdownIt-Anchor" href="#动态可扩展结构模型"></a> 动态可扩展结构模型</h2><p>采用UPCALL和DOWNLOAD技术。它试图将所有的传统操作系统内核中提供的抽象转移到用户控件，以操作系统库的形式提供服务，内核层只负责对物理设备的控制。应用程序可以从用户层库中得到并控件内核抽象，从而实现了操作系统的动态扩展。</p><h1 id="指令的执行"><a class="markdownIt-Anchor" href="#指令的执行"></a> 指令的执行</h1><h2 id="取指令和执行指令"><a class="markdownIt-Anchor" href="#取指令和执行指令"></a> 取指令和执行指令</h2><ol><li>取指令，在每个指令周期开会时，处理器从存储器中读取一条指令，在典型的固定长度指令处理器中，程序计数器（PC）保存有下一次要取的指令地址，每次取指令后都对PC作递增，使它能够按顺序读取吓一条指令，即位于下一个高端存储器地址的指令。</li><li>执行指令，取到指令被防止在处理器的指令寄存器IR中。指令中包含确定处理器将要采取动作的位，处理器解释指令并执行要求的动作，这些动作可分为4类：<br>2.1 处理器与存储器之间的指令或数据传送操作。<br>2.2 处理器与I/O设备质检的指令或数据传送操作<br>2.3 算数运算操作或逻辑运算操作<br>2.4 控制操作，即修改指令的执行顺序的操作。</li></ol><h2 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h2><p>程序执行过程是反复取指令和执行指令的过程。PC使用存有下一条指令的地址。指令的执行结果就是使寄存器或内存单元的值发生变化，指令执行的过程也就是存储体内容不断变化的过程。取指令和执行指令是有硬件完成的，不同硬件的体系结构支持不同的指令集合，为某一种硬件平台开发的操作系统不能直接在另外一中体系结构的硬件上运行。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——内存</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-nei-cun-guan-li/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-nei-cun-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="内存管理的目标"><a class="markdownIt-Anchor" href="#内存管理的目标"></a> 内存管理的目标</h1><ol><li>实现内存分配、内存回收等操作</li><li>提高内存的利用率和内存的访问速度<br>即充分利用现有的内存资源，为应用程序提供方便的内存使用方式和一个快速、安全且充分大的存储器</li></ol><h1 id="程序的链接和装入"><a class="markdownIt-Anchor" href="#程序的链接和装入"></a> 程序的链接和装入</h1><p>链接要解决的问题是将编译后的目标模块装配成一个可执行的程序，分为静态链接和动态链接</p><h3 id="1-程序链接"><a class="markdownIt-Anchor" href="#1-程序链接"></a> 1. 程序链接</h3><p><strong>静态链接</strong>：在程序运行之前，用链接程序将目标模块连接成一个完整的转入模块，任务：一是对逻辑地址进行修改，二是转换外部调用符号<br>优点：运行速度快 缺点：可执行文件较大，占用空间大，系统开销大，程序开发不够灵活，修改一个模块会导致整个程序重新连接</p><p><strong>动态链接</strong><br>可将某些目标模块的链接推迟到这些模块中的函数要被调用时再进行。<br>优点：节省内存和外存空间，方便程序开发<br>缺点：增加了运行时的开销，是程序运行时速度变慢</p><h3 id="2程序的装入"><a class="markdownIt-Anchor" href="#2程序的装入"></a> 2.程序的装入</h3><p>装入方式：绝对装入方式、可重定位装入（静态装入方式）和动态运行时装入方式</p><p><strong>绝对装入方式</strong>：编译程序已知程序在内存中的位置，编译时产生物理地址的目标代码，转入程序按照装入模块的物理地址将程序和数据装入内存<br><strong>可重定位装入方式</strong>：编译时不知道程序在内存中的位置，那么编译时就必须生成可重定位的代码，其中的地址都是逻辑地址，在程序转入内存时，再把逻辑地址映射为物理地址。程序装入时对目标称重的指令和数据地址修改的过程称之为重定位转入</p><p>静态装入方式的特点：1)编译程序使目标模块的地址从0开始<br>2) 程序装入时，装入程序根据内存的使用情况将装入模块的装入内存的某个位置，并对模块进行重定位。物理地址=有效的逻辑地址+程序在内存中的其实位置</p><p>动态运行时装入：当一个进程在被换出之前的内存地址与后来被从外存调入时的位置不同，这是地址映射延迟到进程执行时再进行。</p><h2 id="3连续分配的存储管理方式"><a class="markdownIt-Anchor" href="#3连续分配的存储管理方式"></a> 3.连续分配的存储管理方式</h2><ol><li>单一连续去分配方式<br>适合于单用户单任务系统，内存分为系统区和用户区</li><li>固定分区分配<br>将用户内存空间分配成若干固定大小的区域，每个区域运行一道用户程序；分区的数量固定的，大小也是固定的<br>每个分区大小相等的分配方式缺点是：内存利用率低，主要用于一个计算机去控制多个相同对象的场合，如冶炼炉<br>在一些实时系统中，固定分区的分配方式还是简单而有效的</li><li>动态分区分配方式<br>用户分区的数量和大小都是动态变化的<br>分配原理：系统初始只有一个大的空闲分区，当进程请求内存资源时，系统根据请求资源的大小分配一片空闲区域给进程，当运行一段时间后，空闲分区可能散布在不连续的区域，这时候系统会维护一个记录当前空闲分区的数据接口，当进程请求内存时，系统从所有空闲分区中找到一个合适大小的空间给进程。<br>数据结构：空闲分区表和空闲分区链<br>空闲分区链可以动态为每个分区建立一个节点，每个节点包括分区大小、分区起始地址、指向前一个空闲分区节点的指针、指向后一个空闲分区节点的指针。每一个节点占用的内存动态分配、动态回收。</li></ol><p><strong>动态分区分配算法</strong></p><ol><li>首次适应算法FF<br>要求空闲分区链以地址递增的顺序进行连接，每次从链首开始查找，低地址空间可能会被反复划分 缺点：造成空间浪费，内存碎片</li><li>循环首次适应算法NF<br>不在每次从链首开始查找，而是从上一次查找的空闲分区的下一个分区开始查找，每次应设置一个起始查找指针，指示下一次查找的分区</li><li>最佳适应算法BF<br>为了方便查找，把所有空闲区，按照空闲大小递增的顺序进行排列，总是把大小和进程请求的内存空间大小接近的空间分配给进程。<br>优点：避免了大材小用，提高了内存的利用率<br>缺点：容易留下难以使用的小空闲区</li></ol><h2 id="4-基于分页存储的管理方式"><a class="markdownIt-Anchor" href="#4-基于分页存储的管理方式"></a> 4. 基于分页存储的管理方式</h2><p>把进程的存储在内存中的物理地址不连续的区域，这种内存管理方式称为离散内存管理方式。<br>离散内存管理分配内存空间的管理方式有：<strong>分页存储管理，分段存储管理、段也式存储管理</strong></p><p><strong>页</strong>：将一个进程的逻辑地址空间分为若干个大小相等的片，，称之为页<br><strong>页框</strong>：将物理内存地址分成与页大小相同的若干个存储块，称之为页框</p><p><strong>业内碎片</strong>：进程的最后一页一般装不满一个叶框，而形成了不可利用的碎片称为页内碎片。</p><p><strong>页表</strong>：实现页号到页框的映射，在基本的分页制度中，每个进程有一个页表，进程的每一页在页表中有一个对应的页表项，页表在内存中连续存放。</p><p><strong>分页管理方式的地址结构</strong><br>页的存储结构：<br>页号P   页内偏移量W<br>若用m位标识逻辑地址，页大小为2的n次方，则用低n位表示页内偏移量w,用高位m-n位表示P</p><p>分页地址变换：实现逻辑地址到物理地址的转换<br>公式:物理地址=页框号x页框大小 + 页内偏移量</p><p>为了减少cpu在有效访问内存时间上的开销，提高内存的速度，引入了快表机制<br><strong>快表</strong>:也称转换后的缓冲是为了提高访问内存速度而采用的专用缓存，存放最近访问过的页表项。</p><h2 id="4-基于两级页表和多级页表的管理方式"><a class="markdownIt-Anchor" href="#4-基于两级页表和多级页表的管理方式"></a> 4. 基于两级页表和多级页表的管理方式</h2><p>页表再分页，就形成了两级或者多级页表<br>两级页表：将页表再分页，使得每个页表分页的大小与内存页框的大小相同<br>页目录号实际是一个索引值，根据p1从也木勒表项中找到页表所在的页框号，页号p2是页表中的偏移量，根据p2可以知道应该从也飙中的第p2项找到进程页所在的页框号。</p><h2 id="5-基于分页虚拟存储的系统"><a class="markdownIt-Anchor" href="#5-基于分页虚拟存储的系统"></a> 5. 基于分页虚拟存储的系统</h2><p>虚拟存储技术实现的基本思想是：只把进程的一部分装入内存，在进程执行的过程中，cpu访问内存如果发现所访问的内容不再内存中，则通过异常处理将所需的内容从外存调入内存。<br>虚拟存储技术的好处：</p><ol><li>提高内存的利用率</li><li>提高多道程序度</li><li>把逻辑地址空间和物理地址空间分开，程序员不用关心物理内存的容量对编程的限制。</li></ol><p><strong>虚拟存储技术的特征</strong></p><ol><li>离散性</li><li>多次性</li><li>对换性</li></ol><h2 id="6-页的分配策略"><a class="markdownIt-Anchor" href="#6-页的分配策略"></a> 6. 页的分配策略</h2><p>最少页框数：是指保证进程正常运行所需的最少页框数。操作系统为进程分配的页应该大于或者等于最少页框数</p><p>页分配策略：固定分配策略和可变分配策略<br>页置换策略：局部置换和全局置换。1)局部置换发生置换时，只从请求置换的进程本身的内存页中选择淘汰页，腾出内存空间 2)全局置换是指发生置换时，从所有进程的内存页中选择淘汰的页。<br>也有局部置换和全局置换组合的策略：1)固定分配局部置换 2可变分配局部置换 3)可变分配全局置换</p><p><strong>分配算法</strong></p><ol><li>平均分配算法n进程m页框，则分配INT[m/n]个页框，余数放入缓冲</li><li>按比例分配算法，为进程分配的页框数=进程页数/所有进程页数总和 * 总页框数</li><li>优先权的分配算法</li></ol><h2 id="7页调入策略"><a class="markdownIt-Anchor" href="#7页调入策略"></a> 7.页调入策略</h2><ol><li>系统可以在进程需要时将页调入内存，有利于内存的使用率，但是对系统的时间性能不利</li><li>采用预先调入页的策略，将预计不久后会被访问的页预先调入内存</li></ol><h2 id="8页置换算法"><a class="markdownIt-Anchor" href="#8页置换算法"></a> 8.页置换算法</h2><ol><li>最佳置换算法ORA:该算法选择以后永远不会被访问的页或者长时间不会被访问的页作为换出页</li><li>先进先出置换算法FIFO：最简单。当选择换出页时，选择进入内存时间最早的页（用指针指示当前调入新页时，应当淘汰的那个也在队列中的位置，换出后，指针指向下一个应该淘汰的页）</li><li>最久未使用的LRU置换算法：性能较好的算法，该算法是选择最久未使用的页换出。</li><li>其他置换算法：附件引用位算法、简单clock算法、改进型clock算法、最少使用置换算法、页缓冲算法</li></ol><h2 id="9分段存储管理"><a class="markdownIt-Anchor" href="#9分段存储管理"></a> 9.分段存储管理</h2><p>引入分段机制的优点是方便编程、分段共享、分段保护、动态链接以及存储空间的动态增长</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——进程调度与死锁</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-diao-du-yu-si-suo/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-diao-du-yu-si-suo/</url>
      
        <content type="html"><![CDATA[<h1 id="一-进程调度"><a class="markdownIt-Anchor" href="#一-进程调度"></a> 一、进程调度</h1><p>进程的调度室指按照某种策略或算法从就绪进程中为当前空闲的cpu选择在其上运行的新进程</p><h1 id="二-进程的调度算法"><a class="markdownIt-Anchor" href="#二-进程的调度算法"></a> 二、进程的调度算法</h1><p>##1. 时间概念<br><strong>周转时间</strong>是指从作业开始提交给系统开始，到作业完成为止系统的<br><strong>平均周转时间T</strong>=N各种作业的周转时间之和除以n<br><strong>带权周转时间</strong>=作业的周转时间/系统为它提供服务时间<br><strong>响应时间</strong>=用户从提交一个请求开始至系统首次响应的时间为止的一段时间<br><strong>截止时间</strong>=是指某个人物必须开始执行的最迟时间，或者必须完成的最迟时间</p><h2 id="2-调度算法优劣的准则"><a class="markdownIt-Anchor" href="#2-调度算法优劣的准则"></a> 2. 调度算法优劣的准则</h2><ul><li>周转时间短</li><li>响应时间快</li><li>截止时间保证</li><li>系统吞吐量高</li><li>CPU利用率好</li></ul><h2 id="3-调度算法"><a class="markdownIt-Anchor" href="#3-调度算法"></a> 3. 调度算法</h2><ol><li><p>先来先服务(FCFS),从就绪队首选择最先到达就绪队列的进程<br>优缺点：FCFS适合长进程，不利于短进程，适合CPU繁忙型的进程，不适合IO繁忙型的进程</p></li><li><p>短进程调度优先(SPF)，短进程优先算法有效降低进程的平均等待时间，提高系统的吞吐量</p></li><li><p>调度算法优先(SPL),分为非抢占式优先调度算法，抢占式优先权调度；优先权的调度类型：静态优先权和动态优先权</p></li><li><p>时间片轮转调度算法(RR),时间片大小确认考虑的因素：</p><ol><li>系统对响应时间的要求，响应时间越短，时间片取值应该越小。</li><li>就绪队列中的进程数</li><li>系统的处理能力</li></ol></li><li><p>多级队列调度，不同的队列优先权不同，调度算法也可能不同</p></li><li><p>多级反馈队列调度，队列优先权越高，时间片越短，时间片通常成倍增长。</p></li></ol><p>##实时系统中的调度</p><ol><li>提供必要的调度信息</li><li>系统处理能力强</li><li>采用抢占式调度机制</li><li>具有快速切换机制</li></ol><h2 id="死锁"><a class="markdownIt-Anchor" href="#死锁"></a> 死锁</h2><p>死锁是由于多个进程竞争共享资源引起的进程不能向前推进的僵死状态</p><p>产生死锁的原因：竞争死锁资源且分配资源的顺序不当<br>产生死锁的必要条件：</p><ol><li>互斥</li><li>请求保持</li><li>不剥夺</li><li>环路等待</li></ol><p>处理死锁的防范：</p><ol><li>预防死锁</li><li>避免死锁，资源分配的状态分为安全和不安全状态，不安全状态不一定产生死锁，但是系统进入安全状态一定不会产生死锁，这样就可以避免死锁的产生，银行家算法就是一种系统避免系统死锁的一种检测算法，其基本思想是：一个进程提出资源请求后，系统进行资源的试分配。然后检测此次分配是否处于安全状态，若安全则按分配方案分配资源，否则不进行分配资源。</li><li>检测并解除死锁</li><li>忽略死锁</li></ol><p>某系统中有3个并发进程，都需要同类资源4个，试问该系统保证不会发生死锁的最少资源数是______<br>如果一个进程有m个资源它就能够结束，不会使自己陷入死锁中。因此最差情况是每个进程有m-1个资源并且需要另外一个资源。如果留下有一个资源可用，那么其中某个进程就能够结束并释放它的所有资源，使其它进程也能够结束。所以避免死锁的条件是：r≥p(m-1)+1。带入上述条件公式：<em><em>r≥3</em>(4-1)+1=10</em>*。所以答案为10个。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——进程管理</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-guan-li/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="一-进程的概念"><a class="markdownIt-Anchor" href="#一-进程的概念"></a> 一、进程的概念</h1><ol><li>进程是允许并发的程序在某个数据集合上运行的过程</li><li>进程是<strong>正文段</strong>、<strong>用户数据段</strong>和<strong>进程控制块</strong>共同组成的执行环境。</li></ol><h1 id="二-进程与程序的区别"><a class="markdownIt-Anchor" href="#二-进程与程序的区别"></a> 二、进程与程序的区别</h1><ol><li>程序是静态的，进程是动态的</li><li>程序是永久的，进程是暂时存在的</li><li>程序和进程存在的实体不同。程序是指令的集合，进程是由正文段、用户数据段、进程控制块组成</li></ol><h1 id="三-进程与程序的关系"><a class="markdownIt-Anchor" href="#三-进程与程序的关系"></a> 三、进程与程序的关系</h1><p>进程是程序的一次执行，进程总是对于一个特定的程序，一个程序可以对于多个进程</p><h1 id="四-进程的组成部分"><a class="markdownIt-Anchor" href="#四-进程的组成部分"></a> 四、进程的组成部分</h1><h2 id="正文段"><a class="markdownIt-Anchor" href="#正文段"></a> 正文段</h2><p>正文段存放被执行的激情指令</p><h2 id="用户数据"><a class="markdownIt-Anchor" href="#用户数据"></a> 用户数据</h2><p>用户数据段存放进程在执行时要操作的用户数据</p><h2 id="进程控制块"><a class="markdownIt-Anchor" href="#进程控制块"></a> 进程控制块</h2><p>是操作系统管理进程所使用的数据结构<br>进程控制块是实体的一部分，是操作系统重要的数据结构，进程控制块中记录了操作系统所需要的，用户描述进程情况以及控制运行所需要的全部信息，进程控制块是操作系统感知进程存在的唯一标志。</p><h1 id="五-进程管理"><a class="markdownIt-Anchor" href="#五-进程管理"></a> 五、进程管理</h1><ol><li>进程的状态信息：就绪态、执行态、阻塞态</li><li>进程的组织方式：链接方式、索引方式、进程队列</li><li>进程的控制：进程的创建—阻塞—唤醒—终止</li><li>进程的创建条件：1) 用户登录 2)作业调度 3)提供服务 4)应用请求</li><li>阻塞条件： 1)请求系统服务 2)数据尚未到达 3)无工作可做 4)启动某种操作</li></ol><h2 id="操作系统内核"><a class="markdownIt-Anchor" href="#操作系统内核"></a> 操作系统内核</h2><p>操作系统内核是指系统与硬件密切相关、执行频率高的模块，一般常驻内存。</p><h3 id="操作系统内核的功能"><a class="markdownIt-Anchor" href="#操作系统内核的功能"></a> 操作系统内核的功能</h3><ol><li><p>支持功能<br>支撑功能包括：中断处理、时钟管理和原语操作，其中原语操作是一组在执行过程中不能中断的操作</p></li><li><p>资源管理功能<br>资源管理功能包括：进程的管理、存储器管理和设备管理</p></li></ol><p>####中断</p><p>中断时改变计算机执行指令的顺序的一种事件，这种事件与cpu芯片内外部硬件电路参数的电信号对应。</p><p><strong>中断的目的</strong>：能够有效提高cpu的利用率，改善系统性能，支持系统的异步性。例如在引用中断机制之前，采用的是发福轮询的方式来检测本次I/O是否结束。</p><p><strong>中断的类型</strong>：</p><ol><li>同步中断：当指令执行时由cpu控制段元产生的，如除法出错，调试、溢出、浮点出错等</li><li>异步中断（外部中断）：是由其他硬件设备随机产生的，可分为外部可屏蔽中断（I/O设备产生）和外部不可屏蔽中断(紧急事件产生，硬件故障等)</li></ol><p><strong>引起中断的原因</strong>：1)人为设置中断 2)程序性事故 3)I/O设备 4)硬件故障 5)外部事件</p><h2 id="时钟管理"><a class="markdownIt-Anchor" href="#时钟管理"></a> 时钟管理</h2><p>计算机很多活动都是有定时测量来控制的，两种定时测量 1) 保存当前的系统事件和日期 2)维持定时器，操作系统依靠时钟硬件和时钟驱动程序完成上述两种测量</p><p><strong>时钟硬件</strong>：按照指定时间间隔产生时钟中断，测量逝去的时间，并触发与时间有关的操作<br><strong>时钟软件</strong>：维护日期和时间，递减当前进程在一个时间片内的剩余执行时间，对cpu的使用情况记账，递减报警计算器</p><p><strong>时钟源</strong>：实时时钟（RTC/CMOS）/OS时钟</p><h2 id="系统调用与一般函数"><a class="markdownIt-Anchor" href="#系统调用与一般函数"></a> 系统调用与一般函数</h2><p>系统调用是一群实现定义好的模块，他们提供一条管道让应用程序或用户能由此得到核心程序的服务。系统调用时系统程序与用户程序之间的接口。</p><p>系统调用与一般函数的区别：</p><ol><li>系统调用运行在系统态，一般函数运行在用户态</li><li>系统调用与一般函数的执行过程不同，系统调用中断时，有系统找到对于的系统调用子程序</li><li>系统调用要进行[中断处理],比一般函数多一些系统开销</li></ol><h2 id="进程同步"><a class="markdownIt-Anchor" href="#进程同步"></a> 进程同步：</h2><p>操作系统同步机制的主要任务就是保证在多任务共享系统资源的情况下，程序能够得到正确的结果。同时，同步机制需要解决进程执行的协调问题。</p><p>进程同步有两个作用</p><ol><li>对具有共享资源的进程，保住以互斥的方式访问临界资源。临界资源必须以互斥的方式访问共享资源</li><li>对具有相互合作关系的进程，要保证相互合作的各个进程协调执行</li></ol><p><strong>同步机制遵循的准则</strong>： 1)空闲让进 2)忙则等待 3)有限等待 4) 让权等待</p><h2 id="信号量机制"><a class="markdownIt-Anchor" href="#信号量机制"></a> 信号量机制</h2><p>信号量机制对不同共享资源设置称之为信号量的变量，用信号量的取值标识资源的使用情况，或某种事件的发生</p><h3 id="整形信号量机制"><a class="markdownIt-Anchor" href="#整形信号量机制"></a> 整形信号量机制</h3><p>用整形来标记资源的使用情况。若整形量&gt;0,说明有资源可用；若整形量&lt;=0，说明资源忙，进程必须等待。</p><h3 id="记录型信号量机制"><a class="markdownIt-Anchor" href="#记录型信号量机制"></a> 记录型信号量机制</h3><p>除了用整形来标记资源的使用情况外，额外使用一个记录进程队列来存储等待资源的进程。这样就不存在“忙等”，而是通过有可用资源时的回调触发</p><h3 id="and型信号量的机制"><a class="markdownIt-Anchor" href="#and型信号量的机制"></a> AND型信号量的机制</h3><p>基本思想是将进程在整个运行过程中所需要的所有资源一次性的全部分配给进程，待进程使用完后再一起释放。</p><h1 id="六-线程"><a class="markdownIt-Anchor" href="#六-线程"></a> 六、线程</h1><p>在操作系统中，进程是进行资源分配和独立执行的基本单位，为了进一步提高程序的并发性，减少系统的开销，在操作系统中引入了线程的概念。<br>线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程在运行中断性，也有就绪、执行、阻塞三种状态。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高性能无锁阻塞队列——Disruptor</title>
      <link href="/xue-xi/gao-xing-neng-wu-suo-zu-sai-dui-lie-disruptor/"/>
      <url>/xue-xi/gao-xing-neng-wu-suo-zu-sai-dui-lie-disruptor/</url>
      
        <content type="html"><![CDATA[<p>这是我年初在公司内部技术分享讲Disruptor的PPT,整理下放到博客里面。</p><h1 id="什么是disruptor"><a class="markdownIt-Anchor" href="#什么是disruptor"></a> 什么是Disruptor</h1><p>Disruptor 是一个用于在线程间通信的高效低延时的消息组件，它像个增强的队列，能够在无锁的情况下实现异步并发操作,它是纯内存组件。</p><p>它的特点如下：</p><ul><li>高性能、无锁，实现每秒千万级别的异步业务处理能力</li><li>它除了能实现队列基本功能，还能实现顺序消费，或者复杂的并行和依赖结合的消费方式</li><li>能实现一对多、多对一、多对多的广播或抢占试消费</li></ul><h1 id="为什么高性能快速"><a class="markdownIt-Anchor" href="#为什么高性能快速"></a> 为什么高性能，快速？？？</h1><ul><li>使用RingBuffer数据结构，实现内存复用，减少重新分配空间带来的时间空间损耗</li><li>使用CPU底层CAS（Compare And Swap :比较并交换）指令和内存屏障实现读写无锁化，并使用读写指针序列缓存行补齐方式达到真正的读写分离</li><li>阻塞等待策略，使用Busy Spin(疯狂死循环)，是多核架构最快的通讯方式，同时也是最耗cpu的通讯方式，典型的牺牲硬件来换取速率</li></ul><h1 id="disruptor数据结构"><a class="markdownIt-Anchor" href="#disruptor数据结构"></a> Disruptor数据结构</h1><p>Disruptor底层是一个固定大小的环形数组，每个读或写线程自己维护一个可读可写序列对象Sequence,并保证每个序列在不同的内存缓存行中（cache line）,避免伪共享，实现真正的无锁的读写分离，如图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418757.png" alt><br>假设环形数组长度为L=8</p><p>当生产者写入一个元素时，对应写的Sequence下标w++;<br>当消费者读取一个元素时，对应读的Sequence下标r++;<br>当且r &lt; w &lt; r+L时，数组正常写入及消费<br>当且w=r时，数组为空，消费者阻塞，生产者可以从w+1%L的位置开始重复写入<br>当且w=r+L时，数组写满，生产者阻塞，消费者可以从r+1%L的位置开始读取</p><blockquote><p>关于<strong>缓存行伪共享</strong><br>我们知道CPU为了加快访问内存数据，设置了很多CPU高速缓存，当CPU要访问一个内存数据时，先从主内存中缓存一个Cache Line(缓存行，CPU高速缓存存取数据的最小单位是一个缓存行，Hotspot JVM最小单位是64字节，而有的是128字节，不同虚拟机对此处理不一样)，而当一个缓存内的某个变量值改变时，其他缓存了此变量相邻的变量也将将失效，因为它们在一个缓存行中。这就是所谓的内存伪共享，虽然两个线程引用的变量不同，但是由于使用的是同一个缓存行的变量，也将受影响，从而影响CPU的执行速率。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418828.png" alt><br>在Disruptor中，为了实现真正的读写分离互不影响，也就是用于读写分离的两个Sequence对象使用缓存行填充的“笨方法”来避免这种伪共享。实现的方法就是将一个Sequence对象填充满一个缓存行，而避免其他无关的对象变量影响其使用速率。<br>实现原理：<br>我们知道一个在Java中一个对象的在内存中的大小取决于这个对象的成员变量大小，如下<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418735.png" alt><br>需要使用一个long类型的成员变量value，一个long类型是8个字节，除了这个long类型value的下标外，定义14个long类型的变量p1、p2…p15，再加上一个对象的对象头大小是8字节,所以最终一个对象在在内存中的大小刚好是128字节，如果是64字节的 Line Cache就占用两个缓存行，128字节的Line cache就占用一个缓存行，在多线程情况下，排除了无关对象对这个Sequence对象的更新缓存失效影响。由于JDK7开始JVM会对对象的无效变量（未使用的变量）作优化处理，这里使用继承的方式，否则这种方式的缓存行填充是无效的，从JDK8开始已经原生支持缓存行填充，只需要一个注解:</p></blockquote><pre class="highlight"><code class>@Contendedpublic class VolatileLong {    public volatile long value = 0L;  }</code></pre><blockquote><p>并且在java启动参数中设定<code>XX:-RestrictContended</code>，<code>@Contended</code>注释才会生效。</p></blockquote><h1 id="disruptor的其他特性"><a class="markdownIt-Anchor" href="#disruptor的其他特性"></a> Disruptor的其他特性</h1><h2 id="disruptor-并行消费的结果依赖等待"><a class="markdownIt-Anchor" href="#disruptor-并行消费的结果依赖等待"></a> Disruptor 并行消费的结果依赖（等待）</h2><p><img src="https://leanote.com/api/file/getImage?fileId=5a27e543ab644163f00002e7" alt></p><p>从中图可以看出需求是介样子的：生产者生产数据经过C1,C2处理完成后再到C3。<br>假设如下场景：<br>1、交易网关收到交易(P1)把交易数据发到RingBuffer中，<br>2、负责处理增值业务的消费者C1和负责数据存储的消费者C2负责处理交易<br>3、负责发送JMS消息的消费者C3在C1和C2处理完成后再进行处理。<br>使用以下代码就可以实现：</p><pre class="highlight"><code class>disruptor.handleEventsWith(new EventHandleOne(),new EventHandleTow()).then(new EventHandleThree());</code></pre><h1 id="disruptor与arrayblockingqueue-linkedblockingqueue的比较"><a class="markdownIt-Anchor" href="#disruptor与arrayblockingqueue-linkedblockingqueue的比较"></a> Disruptor与ArrayBlockingQueue、LinkedBlockingQueue的比较</h1><table><thead><tr><th>-----</th><th>Disruptor</th><th>ArrayBlockingQueue</th><th>LinkedBlockingQueue</th></tr></thead><tbody><tr><td>实现原理</td><td>固定大小的环形的ringbuffer存放元素</td><td>固定大小的数组存放元素，通过插入、取出两个下标协同循环使用数组</td><td>用链表存放元素，大小不固定</td></tr><tr><td>锁</td><td>无锁，多生产者之间有sequence竞争，采用比锁轻量的CAS操作</td><td>有锁，且读和写是同一个锁，锁粒度最大</td><td>有锁，读锁和写锁分开</td></tr><tr><td>gc</td><td>元素重用，gc较少</td><td>元素重用，gc较少</td><td>元素不重用，gc较多</td></tr><tr><td>其他</td><td>考虑cpu cacheline，避免false sharing，多种等待策略，可根据具体情况选用。比如自旋、wait、自旋一定时间然后wait等。</td><td>等待时线程wait，条件满足时，notify，线程切换较多</td><td>等待时线程wait，条件满足时，notify，线程切换较多</td></tr><tr><td>适用场景</td><td>1、性能最好2、消费者其实是一种广播的方式，即每个元素，每个消费者都要消费</td><td>1、多并发时性能不好。2、典型消费者-生产者模式，一个元素只给一个消费者消费</td><td>1、并发性比ArrayBlockingQueue好，但gc较多。2、典型消费者-生产者模式，一个元素只给一个消费者消费</td></tr><tr><td>一对一消费</td><td>16,355,904 tps/sec</td><td>4,641,233 tps/sec</td><td>4,633,706 tps/sec</td></tr><tr><td>三对一消费</td><td>15,499,070 tps/sec</td><td>8,055,421 tps/sec</td><td>5,997,361 tps/sec</td></tr><tr><td>10对一消费</td><td>17,624,251 tps/sec</td><td>4,310,716 tps/sec</td><td>5,670,863 tps/sec</td></tr><tr><td>100对一消费</td><td>16,952,026 tps/sec</td><td>537,634 tps/sec</td><td>5,701,254 tps/sec</td></tr><tr><td>10000对1消费</td><td>10,060,362 tps/sec</td><td>84,906 tps/sec</td><td>5,252,101 tps/sec</td></tr></tbody></table><p>大家感兴趣可以运行测试代码，Disruptor 性能测试代码：<a href="https://github.com/okeeper/disruptorTest.git" target="_blank" rel="noopener">https://github.com/okeeper/disruptorTest.git</a></p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>凡事都不是选最好的，而是要选适合自己的。<br>同样，我们系统也要根据我们业务需要选择适合的技术。Disruptor，总结就是：如果非业务性能特殊需要，无必要使用Disruptor，如每秒600万订单处理，大多时候我们的JDK5的java.util.concurrent包已经够我们使用了，因为Disruptor会增加我们的成本（学习成本、维护成本以及硬件资源消耗）。</p><p>参考文章:<a href="http://www.importnew.com/19896.html" target="_blank" rel="noopener">剖析Disruptor为什么会这么快(2)：神奇的缓存行填充</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> Disruptor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP及HTTPS的理解</title>
      <link href="/xue-xi/http-ji-https-de-li-jie/"/>
      <url>/xue-xi/http-ji-https-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="http"><a class="markdownIt-Anchor" href="#http"></a> HTTP</h1><p>HTTP全称叫超文本传输协议(HyperText Transfer Protocol),是用于WWW(万网)服务器与浏览器客户端的一种通讯协议</p><h2 id="tcpip"><a class="markdownIt-Anchor" href="#tcpip"></a> TCP/IP</h2><p>关于计算机通讯，需要了解的一些背景知识，TCP/IP.<br>我们经常说TCP/IP，为什么要一起说，因为这两者有着密切的关系，其实它包含两个协议：</p><ul><li>TCP: TCP 负责将数据包在数据传送之前将它们分割为 IP 包，然后在它们到达的时候将它们重组</li><li>IP：负责将TCP分隔的IP包发送传输到指定ip的机器上，IP包之间的传输不保证顺序性，在TCP重组时才还原数据顺序</li></ul><p>所以说TCP/IP是传输协议的上下层关系。</p><h2 id="关于http"><a class="markdownIt-Anchor" href="#关于http"></a> 关于HTTP</h2><p>而HTTP则是在TCP/IP基础上的进一步封装的协议，属于应用层协议.网络传输的协议关系图如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529465.png" alt></p><p>网络传输的协议，两边刚好是相反的:<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529221.png" alt></p><h2 id="http原理"><a class="markdownIt-Anchor" href="#http原理"></a> HTTP原理</h2><p>HTTP请求主要分为以下几个步奏：</p><ol><li>域名解析，查找对应DNS服务器域名解析找到对应的IP</li><li>封装TCP/IP通讯数据包，建立连接（3三次握手协议），HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能，才能进行更层协议的连接</li><li>封装HTTP请求数据包，请求头信息，请求参数等。</li><li>等待服务器响应，服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码</li><li>一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码<br>Connection:keep-alive<br>TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求，这就是长连接的原理</li></ol><p>关于HTTP的超时时间，<code>connectTimeout</code>、<code>requestConnectTimeout</code>、<code>readTimeout</code>、<code>socketTimeout</code></p><ul><li><code>connectTimeout</code> 是指上面的第2步，建立TCP/IP连接的超时时间</li><li><code>requestConnectTimeout</code> 是指上面第3步，发送请求头发送http请求的超时时间</li><li><code>readTimeout</code> 是指从发送http请求开始等待响应内容的总超时时间,指上面步骤的第4步</li><li><code>socketTimeout</code> 响应内容有可能是分成几个socket数据包传输的，而这个socketTimeout的意思就是每个socket传输的超时时间</li></ul><p>例如下图：<br>readTimeout设为6s,socketTimeout设为4秒，发送http报文之后响应<br>时间超时为6s,响应内容abc分三次socket传输,每次间隔超时时间为4s，所以总共花费6s是不会抛出<code>socket timeout</code><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529343.png" alt></p><h2 id="java中使用http"><a class="markdownIt-Anchor" href="#java中使用http"></a> JAVA中使用http</h2><p>Java 访问http通过</p><h1 id="https"><a class="markdownIt-Anchor" href="#https"></a> HTTPS</h1><p>HTTPS简单的说就是，http的安全版</p><h2 id="https基本原理"><a class="markdownIt-Anchor" href="#https基本原理"></a> HTTPS基本原理</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184528912.png" alt></p><p>过程大致如下：</p><ol><li>SSL客户端通过TCP和服务器建立连接之后（443端口），并且在一般的tcp连接协商（握手）过程中请求证书。<br>即客户端发出一个消息给服务器，这个消息里面包含了自己可实现的算法列表和其它一些需要的消息，SSL的服务器端会回应一个数据包，这里面确定了这次通信所需要的算法，然后服务器向客户端返回证书。（证书里面包含了服务器信息：域名。申请证书的公司，公共秘钥）。</li><li>Client在收到服务器返回的证书后，判断签发这个证书的公共签发机构，并使用这个机构的公共秘钥确认签名是否有效，客户端还会确保证书中列出的域名就是它正在连接的域名。</li><li>如果确认证书有效，那么生成对称秘钥并使用服务器的公共秘钥进行加密。然后发送给服务器，服务器使用它的私钥对它进行解密，这样两台计算机可以开始进行对称加密进行通信。</li></ol><p>参考文章：<br>HTTPS介绍：<a href="https://imququ.com/post/how-to-decrypt-https.html" target="_blank" rel="noopener">https://imququ.com/post/how-to-decrypt-https.html</a><br><a href="http://blog.csdn.net/hguisu/article/details/8680808" target="_blank" rel="noopener">http://blog.csdn.net/hguisu/article/details/8680808</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> HTTPS </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo源码学习</title>
      <link href="/xue-xi/dubbo-yuan-ma-xue-xi/"/>
      <url>/xue-xi/dubbo-yuan-ma-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="dubbo-provider暴露源码分析"><a class="markdownIt-Anchor" href="#dubbo-provider暴露源码分析"></a> Dubbo Provider暴露源码分析</h1><p>Dubbo服务端的服务暴露及初始化</p><ol><li><code>org.apache.dubbo.config.spring.ServiceBean#afterPropertiesSet</code> 开始spring 容器初始化好属性后，回调这个方法开始初始化Provider</li><li>前面一堆是初始化<code>ApplicationConfig</code>、<code>Module</code>、<code>Registry</code>(注册中心)、<code>ConfigCenter</code>(配置中心)、<code>Monitor</code>（监控中心）、<code>Metrics</code>(监控项)、<code>Service</code>(服务bean)</li><li>接着找到<code>org.apache.dubbo.config.ServiceConfig#doExportUrls;</code><ol><li>主要看 <code>org.apache.dubbo.config.ServiceConfig#doExportUrlsFor1Protocol</code></li><li>这个方法主要是构建Invoker代理，然后用<code>Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker);</code> 通过SPI加载默认<code>DubboProtocol</code>.</li><li>进入<code>org.apache.dubbo.rpc.DubboProtocol#export</code>之后我们看到一个<code>openServer</code>调用,初始化一个Server</li><li>进入<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#openServer</code>，主要调用<code>createServer</code></li><li>进入<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#createServer</code>,调用了一个静态方法<code>Exchangers#bind()</code></li><li>进入<code>org.apache.dubbo.remoting.exchange.Exchangers#bind</code>,入参是当前要暴露服务的URL和一个<code>requestHandler</code>, requestHandler实现在 <code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#requestHandler</code>里</li><li>进入<code>Exchangers#bind</code>,调用了 <code>org.apache.dubbo.remoting.exchange.Exchangers#getExchanger(org.apache.dubbo.common.URL)</code>获取当前暴露服务URL的个性化<code>Exchanger</code>配置，默认加载<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger</code></li><li>进入<code>HeaderExchanger</code>,有两个方法实现分别为<code>bind</code>和 <code>connect</code>,看样子一个事用于Server端暴露服务，一个事用于Client来请求服务</li><li>主要看<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger#bind</code>,调用了<code>Transporters#bind()</code>，这里吧requestHandler进行包装成了一个<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code></li><li>进入<code>org.apache.dubbo.remoting.Transporters#bind()</code>，看到默认加载的是nett4的<code>org.apache.dubbo.remoting.transport.netty4.NettyTransporter#bind()</code>,而这个实现主要是new了一个<code>org.apache.dubbo.remoting.transport.netty4.NettyServer#NettyServer</code>,到此一个Provider的Invoker代理就绑定到NettyServer里可以对外提供服务了</li><li>在<code>NettyServer</code>的构造方法中，调用了<code>org.apache.dubbo.remoting.transport.dispatcher.ChannelHandlers#wrap</code>,将HeaderExchangeHandler进行一个<code>Dispatcher</code>的分发，默认实现是<code>org.apache.dubbo.remoting.transport.dispatcher.all.AllDispatcher</code>,除此之外还有<code>ConnectionOrderedDispatcher</code>、<code>DirectDispatcher</code>、<code>ExecutionDispatcher</code>、<code>MessageOnlyDispatcher</code>，这里不做展开</li><li>在AllDispatcher中的dispatch实现是<code>AllChannelHandler</code>,所有类型的请求都可以接受处理</li><li>进入<code>org.apache.dubbo.remoting.transport.dispatcher.all.AllChannelHandler#received</code>,我们看到它将接收到的请求丢到一个<code>ExecutorService</code>线程池中异步处理，这里就是Dubbo线程处理的核心了</li><li>我们回到第6步，这里说到默认的handler是<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#requestHandler</code>, 这个requestHandler被6.3包装成了<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code></li><li>进入<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code>,这是NIO请求的处理handler,我们了解NIO的Channel是双向通信的，所以当接收到请求时和响应时都会进入到<code>received</code>,当出现异常时进入<code>caught</code><ol><li>我们先来看<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#received</code>,主要判断是请求还是响应，如果是请求判断是否是否有响应，如果是<code>towWay</code>通信，即有响应结果的请求，进入<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#handleRequest</code></li><li>在这里调用了一开始传入的requestHandler#reply,实在在<code>org.apache.dubbo.remoting.exchange.support.ExchangeHandlerAdapter</code>，这里就是具体调用找到具体要请求的Provider的Invoker，异步请求并返回一个Feature，然后在当前received方法中进行异步等待，等待响应结果完成send进channel进行响应</li></ol></li></ol></li><li>发布到注册中心</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> Dubbo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Unicode  UTF-8 、UTF-16字符集编码的理解</title>
      <link href="/xue-xi/guan-yu-unicode-utf-8-utf-16-zi-fu-ji-bian-ma-de-li-jie/"/>
      <url>/xue-xi/guan-yu-unicode-utf-8-utf-16-zi-fu-ji-bian-ma-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="最近学习nio文件读写的时候就生成了一个疑问程序怎么知道文件使用了什么编码因为底层程序看到的都是二进制的字节码如"><a class="markdownIt-Anchor" href="#最近学习nio文件读写的时候就生成了一个疑问程序怎么知道文件使用了什么编码因为底层程序看到的都是二进制的字节码如"></a> 最近学习NIO文件读写的时候，就生成了一个疑问，程序怎么知道文件使用了什么编码，因为底层程序看到的都是二进制的字节码如：</h1><pre class="highlight"><code class>中文 | utf-8二进制编码人   | 11100100 10111010 10111010 </code></pre><p>程序怎么知道通过这是一个通过3个字节编码的<code>人</code>字呢，于是查询了相关资料：</p><p>要解释这个问题，我们先来了解下ASCII码、GB2312、GBK、Unicode编码的关系和定义</p><h1 id="1-asscii码见ascii码对照表"><a class="markdownIt-Anchor" href="#1-asscii码见ascii码对照表"></a> 1. ASSCII码,见<a href="http://tool.oschina.net/commons?type=4" target="_blank" rel="noopener">ASCII码对照表</a></h1><p>是一种使用一个字节(8位二进制)表示字母、数字和字符的一种编码，如字母<code>A</code>表示为使用十进制值为<code>65</code>的表示，转换为二进制就是<code>1000001</code>,我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。<br>上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为ASCII码，一直沿用至今。<br>ASCII码一共规定了128个字符的编码，比如空格&quot;SPACE&quot;是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。</p><h1 id="2-gb2312-全称是gb2312-80信息交换用汉字编码字符集-基本集是中国标准化组织发布的见gb2312编码规则"><a class="markdownIt-Anchor" href="#2-gb2312-全称是gb2312-80信息交换用汉字编码字符集-基本集是中国标准化组织发布的见gb2312编码规则"></a> 2. <code>GB2312</code> ，全称是GB2312-80《信息交换用汉字编码字符集 基本集》，是中国标准化组织发布的，见<a href="http://www.qqxiuzi.cn/zh/hanzi-gb2312-bianma.php" target="_blank" rel="noopener">GB2312编码规则</a></h1><p>在计算机只有英文的时代，可能使用<code>ASCII</code>码就已经够了，但是随着计算机的普及和全球化，别国的语言肯定也是要计算机编码化的，所以就出现了<code>GB2312</code>编码规则。<code>GB2312</code>是使用固定两个字节来表示简体中文和英文、数字、中文符号、英文符号的一种编码规则。所以如果使用<code>GB2312</code>编码时，英文也是使用两个字节来编码的，这无疑是一种浪费</p><p>而<code>GBK</code>则是在<code>GB23312</code>的基础上添加了繁体中文的扩展</p><h1 id="3-unicode"><a class="markdownIt-Anchor" href="#3-unicode"></a> 3. <code>Unicode</code></h1><p>正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。<br>可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码。</p><p>再次强调一下,Unicode只是为全世界的每一个文字符号都定义了一个数值对照</p><h1 id="4-utf-8"><a class="markdownIt-Anchor" href="#4-utf-8"></a> 4. <code>UTF-8</code></h1><p>为什么会有<code>UTF-8</code>编码，我们来看下<code>Unicode</code>编码的定义和存在的问题：</p><p>需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。<br>比如，汉字&quot;严&quot;的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。<br>那么第一个问题：怎么样使用二进制的表示来存储我们的编码呢，是和GBK一样使用固定的字节来存？如果这样的话就必须以最长的字节表示为单位，那么应为字母、数字都得使用3个字节或者4个字节来存储，这显然是不能够接受的，这对存储空间是极大的浪费。<br>根据第一个问题，我们是否能够使用变长的存储方式来存unicode编码呢，如果可以，怎么在读取的时候区分一个字符是使用一个字节表示（比如字母、数字），还是使用3个字节表示的中文呢？</p><p>所以最初期，由于存在Unicode存在这些问题的存在<br>它们造成的结果是：1）出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。<br>2）Unicode在很长一段时间内无法推广，直到互联网的出现。</p><p>我们来看下<code>UTF-8</code>是怎么实现unicode编码的。<br>UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。<br>UTF-8的编码规则很简单，只有二条：<br>1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。<br>2）对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。</p><pre class="highlight"><code class>Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）--------------------+---------------------------------------------0000 0000 ~ 0000 007F | 0xxxxxxx0000 0080 ~ 0000 07FF | 110xxxxx 10xxxxxx0000 0800 ~ 0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000 ~ 0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</code></pre><p>跟据上表，解读UTF-8编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。<br>下面，还是以汉字&quot;严&quot;为例，演示如何实现UTF-8编码。<br>已知&quot;漲&quot;的unicode是<code>\u6f32</code>,6f32二进制为<code>110111100110010</code>，根据上表，可以发现4E25处在第三行的范围内（0000 0800 ~ 0000 FFFF），因此&quot;漲&quot;的UTF-8编码需要三个字节，即格式是<code>1110xxxx 10xxxxxx 10xxxxxx</code>。然后，从<code>漲</code>的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，&quot;漲&quot;的UTF-8编码是1110<code>0110</code> 101<code>11100</code> 10<code>110010</code>，转换成十六进制就是<code>e6bcb2</code>。<br>所以理论上讲UTF-8 可以表示2^31个字符，所以还有很多符号表情可以开发编入unicode中。</p><p><em>其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。</em></p><p>#5. 使用java打印出所有中文代码</p><pre class="highlight"><code class>   下标         中文    unicode          unicode十进制值           unicode二进制      utf-8编码二进制            utf-8十六进制      长度字节数    0          葦     \u6f32                28466                110111100110010    11101000 10010001 10100110           e891a6          3    1          葧     \u6f33                28467                110111100110011    11101000 10010001 10100111           e891a7          3    2          葨     \u6f34                28468                110111100110100    11101000 10010001 10101000           e891a8          3    3          葩     \u6f35                28469                110111100110101    11101000 10010001 10101001           e891a9          3    4          葰     \u6f36                28470                110111100110110    11101000 10010001 10110000           e891b0          3    5          葱     \u6f37                28471                110111100110111    11101000 10010001 10110001           e891b1          3    6          葲     \u6f38                28472                110111100111000    11101000 10010001 10110010           e891b2          3    7          葳     \u6f39                28473                110111100111001    11101000 10010001 10110011           e891b3          3    8          葴     \u6f3a                28474                110111100111010    11101000 10010001 10110100           e891b4          3    9          葵     \u6f3b                28475                110111100111011    11101000 10010001 10110101           e891b5          3</code></pre><p>java代码如下：</p><pre class="highlight"><code class>  @Test    public void writeAllChinese() {        int start = 0x6f32;        int index = 0;        System.out.printf(&quot;%5s %10s %10s %20s %20s %15s %20s %10s\n&quot;,&quot;下标&quot;,&quot;中文&quot; ,&quot;unicode&quot; ,&quot;unicode十进制值&quot; ,&quot;unicode二进制&quot; , &quot;utf-8编码二进制&quot;, &quot;utf-8十六进制&quot; ,&quot;长度字节数&quot;);        while (start &lt; 0x6f32 + 10) {            String unicode = &quot;\\u&quot; + Integer.toHexString(start);            char c = (char) Integer.parseInt((start+&quot;&quot;),16);            String chinese = String.valueOf(c);            byte[] bytes = chinese.getBytes();            System.out.printf(&quot;%5s %10s %10s %20s %30s %30s %15s %10s\n&quot;,index,chinese ,unicode ,start ,Integer.toBinaryString(start) , getBinaryString(bytes), Integer.toHexString(Integer.valueOf(getBinaryString(bytes).replace(&quot; &quot;,&quot;&quot;),2)) ,bytes.length);            start++;            index++;        }    }    public static String getBinaryString(byte bytes[]) {        String s = &quot;&quot;;        for(byte b : bytes) {            /**             * 由于java 虚拟机为了方便整数的加减，使用了补码(反码+1)来表示,方便数值的符号直接参与二进制的加减，这样省去了很多计算步骤             * 所以在java中使用String#getBytes()返回的字节数值是反码的表示方法；             * 又由于Int 在java中表示是4个字节32位的，在控制台进行输出的时候，jvm把11001111之前进行了补补全然后再取补码，等到的就是11111111111111111111111110111110             * 所以需要在使用 与 运算将取 反码  0xff = 11111111             */            s = s + Integer.toBinaryString(b &amp; 0xff) +  &quot; &quot;;            //s = s + Integer.toBinaryString(b) +  &quot; &quot;;        }        return s;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> Unicode </tag>
            
            <tag> 字符集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态壁纸接口</title>
      <link href="/2019-11-28-dong-tai-bi-zhi-jie-kou/"/>
      <url>/2019-11-28-dong-tai-bi-zhi-jie-kou/</url>
      
        <content type="html"><![CDATA[<h1 id="新浪动态壁纸接口"><a class="markdownIt-Anchor" href="#新浪动态壁纸接口"></a> 新浪动态壁纸接口</h1><p>说明：<a href="https://www.nulltm.com/tag/%E9%9A%8F%E6%9C%BA" target="_blank" rel="noopener">随机</a>图片<a href="https://www.nulltm.com/tag/%E5%A3%81%E7%BA%B8" target="_blank" rel="noopener">壁纸</a><a href="https://www.nulltm.com/tag/api" target="_blank" rel="noopener">api</a>，调用的是<a href="https://www.nulltm.com/tag/%E6%96%B0%E6%B5%AA" target="_blank" rel="noopener">新浪</a>api，速度不用担心，图片资源也很多</p><p>电脑动漫图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=dongman" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=dongman</a></p><p>电脑美女图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=meizi" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=meizi</a></p><p>电脑随机动漫妹子：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=suiji" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=suiji</a></p><p>手机动漫图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=m_dongman" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=m_dongman</a></p><p>手机美女图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=m_meizi" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=m_meizi</a></p><p>手机随机动漫妹子：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?m_lx=suiji" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?m_lx=suiji</a></p><p>手机电脑自动判断，电脑显示适合电脑的壁纸，手机显示适合手机的壁纸 <a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/zsy.php" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/zsy.php</a></p><p>api现在已经有几千张图了，每天都在增加，大家可以玩玩</p><h1 id="必应动态壁纸接口"><a class="markdownIt-Anchor" href="#必应动态壁纸接口"></a> 必应动态壁纸接口</h1><p>必应在国内的名气不是很大，很多人不知道。必应是美国微软的搜索引擎，类似与百度。不过，有个地方很有趣，必应的首页背景图，每日一换，从不重复。都是团队精选的世界各地的风景、人文类的美图，配有相关文字描述。还是挺有意思的，不过好像只能保存近10多日的数据，超期就无法访问了。</p><p>首先，第一个接口：<a href="http://cn.bing.com/HPImageArchive.aspx?format=js&amp;idx=0&amp;n=1" target="_blank" rel="noopener">http://cn.bing.com/HPImageArchive.aspx?format=js&amp;idx=0&amp;n=1</a></p><p>可以获得当日的必应壁纸无水印高清图片的路径以及版权等信息。具体返回格式如下：</p><pre class="highlight"><code class="json"><span class="hljs-punctuation">{</span>    <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">{</span>        <span class="hljs-attr">&quot;startdate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;20181118&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;fullstartdate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;201811181600&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;enddate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;20181119&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;url&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;urlbase&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;copyright&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;锡安国家公园内的维尔京河，美国犹他州 (© Justinreznick/Getty Images)&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;copyrightlink&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://www.bing.com/search?q=%E9%94%A1%E5%AE%89%E5%9B%BD%E5%AE%B6%E5%85%AC%E5%9B%AD&amp;form=hpcapt&amp;mkt=zh-cn&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;quiz&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/search?q=Bing+homepage+quiz&amp;filters=WQOskey:%22HPQuiz_20181118_NarrowsZion%22&amp;FORM=HPQUIZ&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;wp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;hsh&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;a2d2b96a5c113e78bc7a0f8a508cbf73&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;drk&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;top&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;bot&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;hs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span>    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;tooltips&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>        <span class="hljs-attr">&quot;loading&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;正在加载...&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;previous&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;上一个图像&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;next&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;下一个图像&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;walle&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;此图片不能下载用作壁纸。&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;walls&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;下载今日美图。仅限用作桌面壁纸。&quot;</span>    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span></code></pre><p>在url的路径上，拼上域名即可拿到图片：</p><p><a href="https://cn.bing.com/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg%EF%BC%88%E5%A6%82%E6%9E%9C%E8%BF%99%E4%B8%AA%E6%89%93%E4%B8%8D%E5%BC%80%EF%BC%8C%E8%AF%B7%E8%AE%A4%E7%9C%9F%E9%87%8D%E8%AF%BB%E7%AC%AC%E4%B8%80%E6%AE%B5%E6%9C%80%E5%90%8E%E5%87%A0%E5%8F%A5%E3%80%82%EF%BC%89" target="_blank" rel="noopener">https://cn.bing.com/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg（如果这个打不开，请认真重读第一段最后几句。）</a></p><p>值得注意的是，接口里的idx=后面的数字为0是今日的壁纸数据，1 2  3  4  5…依次是昨日、前日…   数字是-1是明日的数据。</p><pre class="highlight"><code class="json"><span class="hljs-punctuation">{</span>    <span class="hljs-attr">&quot;date&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;November 19&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;峡谷秘境&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;attribute&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;美国，锡安国家公园&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;para1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;今天是美国犹他州锡安国家公园成立99周年的日子，一直以来，它是美国访问量最大的国家公园之一。这里到处都是令人惊叹的西南风景，包括锡安峡谷。壁纸中的地方叫做纳罗斯水道，它是一条穿过峡谷十分狭窄的小径，有的地方甚至只能勉强过一个人，而且有时需要淌着水行走。虽然这个时候水有点冷，但是这里的景色，一个转弯一个惊喜。&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;para2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;provider&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;© Justinreznick/Getty Images&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;imageUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://hpimges.blob.core.chinacloudapi.cn/coverstory/watermark_narrowszion_zh-cn9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;primaryImageUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://hpimges.blob.core.chinacloudapi.cn/coverstory/watermark_narrowszion_zh-cn9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Country&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;美国&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;City&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;锡安国家公园&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Longitude&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;-112.946625&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Latitude&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;37.306900&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Continent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;北美洲&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;CityInEnglish&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Zion National Park&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;CountryCode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;US&quot;</span><span class="hljs-punctuation">}</span></code></pre><p>如果在后面加?d=20181111则是提取2018年11月11日的壁纸故事。这个时间可以从20140501-至今.</p><p><a href="https://cn.bing.com/cnhp/coverstory?d=20181118" target="_blank" rel="noopener">https://cn.bing.com/cnhp/coverstory?d=20181118</a></p><p>有了这些，你就可以搭建一个壁纸站了，每日抓取官方壁纸数据展示，个人觉得，把这些保存下来还是挺有意义的。我前几日借用这两个接口写了一个简单的壁纸站，如果你实在懒得去弄的话，可以随时访问下载哦！最后留个链接，点击这里吧！必应壁纸</p><p>附：</p><p>如果你的网站想要每天更换壁纸壁纸，又不想写接口。下面这几个我写的接口就适合你了！</p><p><a href="https://api.neweb.top/bing.php" target="_blank" rel="noopener">https://api.neweb.top/bing.php</a>   -----必应当日壁纸</p><p><a href="https://api.neweb.top/bing.php?type=future" target="_blank" rel="noopener">https://api.neweb.top/bing.php?type=future</a>   ------必应明日壁纸</p><p><a href="https://api.neweb.top/bing.php?type=rand" target="_blank" rel="noopener">https://api.neweb.top/bing.php?type=rand</a>   -----近7日随机壁纸</p><p>图片demo：（分别是明天、今天、随机的必应壁纸）</p><p>使用方法：</p><pre class="highlight"><code class="html"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://api.neweb.top/bing.php&quot;</span> <span class="hljs-attr">alt</span>=<span class="hljs-string">&quot;必应壁纸&quot;</span>&gt;</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始使用Solidity编写以太坊智能合约并使用Nodejs SDK访问以太坊网络</title>
      <link href="/qu-kuai-lian/cong-ling-kai-shi-shi-yong-solidity-bian-xie-yi-tai-fang-zhi-neng-he-yue-bing-shi-yong-nodejs-sdk-fang-wen-yi-tai-fang-wang-luo/"/>
      <url>/qu-kuai-lian/cong-ling-kai-shi-shi-yong-solidity-bian-xie-yi-tai-fang-zhi-neng-he-yue-bing-shi-yong-nodejs-sdk-fang-wen-yi-tai-fang-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="nodejs安装"><a class="markdownIt-Anchor" href="#nodejs安装"></a> Nodejs安装</h1><p>Nodejs 版本建议8.0以上<br>官网：<a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a><br>官网下载安装包:<a href="https://nodejs.org/dist/v8.12.0/node-v8.12.0-x64.msi" target="_blank" rel="noopener">https://nodejs.org/dist/v8.12.0/node-v8.12.0-x64.msi</a><br>安装参考：<a href="https://blog.csdn.net/qq_26562641/article/details/72235585" target="_blank" rel="noopener">https://blog.csdn.net/qq_26562641/article/details/72235585</a></p><p>配置淘宝镜像：</p><pre class="highlight"><code class>npm config set registry https://registry.npm.taobao.org</code></pre><h1 id="新建一个hello-world只能合约的访问"><a class="markdownIt-Anchor" href="#新建一个hello-world只能合约的访问"></a> 新建一个Hello World只能合约的访问</h1><ol><li><p>使用IDEA安装nodejs插件，在插件列表搜索</p></li><li><p>新建一个node工程项目，File&gt;New Project 选择Node.js and NPM<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544126.png" alt><br>默认有很多其他的目录，我们删除其他目录，只保留如下的目录：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155543961.png" alt><br>或者使用<code>npm init</code>命令初始化一个nodejs工程</p></li><li><p>安装solidity编译器依赖，用于编译Solidity，才能被nodejs使用到</p><pre class="highlight"><code class>npm install --save solc</code></pre></li><li><p>安装以太坊的访问SDK web3.js</p><pre class="highlight"><code class>npm install --save web3</code></pre><p>报错解决：</p><blockquote><ol><li>报<code>gyp ERR! configure error gyp ERR! stack Error: Command failed: C:\Users\yan6\AppData\Local\Programs\Pytho n\Python37-32\python.EXE -c import sys; print &quot;%s.%s.%s&quot; % sys.version_info[:3];</code><br>原因：安装脚本中用到了Python2的语法，你的环境变量中配置的Python3所以报这个错<br>解决：修改python的环境变量，将Python3改成Python2，如果没有到官网下载一个Python2</li><li>报<code> error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1)</code></li></ol><pre class="highlight"><code class>MSBUILD : error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1) 安装 .NET Framework 2.0 SDK；2) 安装 Microsoft VisualStudio 2005；或 3) 如果将该组件安装到了其他位置，请将其位置添加到系统路径中。 [D:\workspace\idea_workspace\blockchian1\node_modules\scrypt\build\binding.sln]MSBUILD : error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1) 安装 .NET Framework 2.0 SDK；2) 安装 Microsoft VisualStudio 2005；或 3) 如果将该组件安装到了其他位置，请将其位置添加到系统路径中。 [D:\workspace\idea_workspace\blockchian1\node_modules\scrypt\build\binding.sln]</code></pre><p>解决办法,按装全局windows相关组件：</p><pre class="highlight"><code class>npm install --global --production windows-build-tools </code></pre></blockquote></li><li><p>安装ganache,ganache是用来在本地测试用的测试以太坊网络</p><pre class="highlight"><code class>npm install -g ganache-cli</code></pre></li><li><p>新建一个Solidity脚本，<code>Hello.sol</code></p><pre class="highlight"><code class>pragma solidity ^0.4.17;contract Hello {    string public name;    function Hello(string _name) public {        name = _name;    }    function setName(string _name) public {        name = _name;    }    function getName() public view returns(string ) {        return name;    }}</code></pre></li><li><p>编写一个solidity的编译脚本compile.js</p><pre class="highlight"><code class>const path = require('path');const  fs = require('fs');const solc = require('solc');const srcpath = path.resolve(__dirname,'contracts', 'Hello.sol');const source = fs.readFileSync(srcpath, 'utf-8');//console.log(source);const result = solc.compile(source,1);//console.log(result);module.exports = result.contracts[':Hello'];</code></pre></li><li><p>在tests下新建一个本地Hello World测试类,<code>Web3Test.test.js</code></p><pre class="highlight"><code class>const  assert = require('assert');//约定规范，如果变量是大写const Web3 = require('web3');//内存里面的以太坊测试环境const  ganache = require('ganache-cli');const web3 = new Web3(ganache.provider());//执行编译脚本，并将编译结果引入进来const {interface,bytecode} = require('../compile');/** * 测试一个Hello World智能合约 * @returns {Promise.&lt;void&gt;} */testGetSet = async ()=&gt; {    let accounts = await web3.eth.getAccounts();    //部署也是一个交易命令，所以需要花gas    const abi = JSON.parse(interface);    const contract = new web3.eth.Contract(abi);    const result = await contract.deploy({        data:bytecode,        arguments:['Hello World']    }).send({        from:accounts[0],        gas: 1500000,        gasPrice: '30000'    });    console.log('deploy success:' + result.options.address);    //测试查询    assert.equal(await result.methods.getName().call(),'Hello World');    await result.methods.setName('hahaha').send({        from:accounts[0],        gas:100000    });    assert.equal(await result.methods.getName().call(),'hahaha');    console.log('测试智能合约成功');}/** * 测试以太坊转账 * @returns {Promise.&lt;void&gt;} */testTrade = async ()=&gt; {    let accounts = await web3.eth.getAccounts();    let b0 = await web3.eth.getBalance(accounts[0]);    let b1 = await web3.eth.getBalance(accounts[1]);    //发送交易    console.log('开始转账：account0:' + b0 + ' account1:' + b1);    await web3.eth.sendTransaction({        from:accounts[0],        to:accounts[1],        value:'1000000000000000'    });    b0 = await web3.eth.getBalance(accounts[0]);    b1 = await web3.eth.getBalance(accounts[1]);    //发送交易    console.log('转账成功：account0:' + b0 + ' account1:' + b1);}testGetSet();testTrade();</code></pre></li></ol><blockquote><p>以上代码<code> const {interface,bytecode} = require('../compile');</code><br>这句话的意思是将Hello.sol编译后的导入到当前的node上下文，interface就是编译后的一些方法定义，bytecode就是最终部署到以太坊网络的二进制数据</p></blockquote><ol start="9"><li>测试运行<pre class="highlight"><code class>node `Web3Test.test.js</code></pre>运行结果：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544126-1414144.png" alt></li></ol><h1 id="将代码提交到以太坊rankeby测试网络"><a class="markdownIt-Anchor" href="#将代码提交到以太坊rankeby测试网络"></a> 将代码提交到以太坊rankeby测试网络</h1><ol><li><p>安装truffle-hdwallet-provider<br>组件官方文档：<a href="https://www.npmjs.com/package/truffle-hdwallet-provider" target="_blank" rel="noopener">https://www.npmjs.com/package/truffle-hdwallet-provider</a></p><pre class="highlight"><code class> npm install truffle-hdwallet-provider</code></pre></li><li><p>使用truffle-hdwallet-provider：</p><pre class="highlight"><code class>//线上的测试环境var HDWalletProvider = require(&quot;truffle-hdwallet-provider&quot;);var mnemonic = &quot;这里是你的以太坊钱包私钥助记词&quot;; // 12 word mnemonic//使用infura在线的providervar provider = new HDWalletProvider(mnemonic, &quot;https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5&quot;);const web3 = new Web3(provider);</code></pre><blockquote><p>上面用到的provider_url：<a href="https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5%E6%98%AFinfura%E7%9A%84%E5%9C%A8%E7%BA%BFurl,%E5%88%B0https://rinkeby.infura.io%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AA%E8%B4%A6%E5%8F%B7%E5%B9%B6%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AArinkeby%E7%9A%84%E6%B5%8B%E8%AF%95PROJECT%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%BE%97%E5%88%B0%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95provider_url%E4%BA%86%EF%BC%8C%E7%BD%91%E7%BB%9C%E4%B8%8D%E5%A5%BD%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E7%BF%BB%E5%A2%99" target="_blank" rel="noopener">https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5是infura的在线url,到https://rinkeby.infura.io注册一个账号并添加一个rinkeby的测试PROJECT就可以得到一个测试provider_url了，网络不好可能需要翻墙</a></p></blockquote></li><li><p>新增一个测试代码进行测试交易,<code>EtherOnlieRinkebyTest.test.js</code></p><pre class="highlight"><code class>//约定规范，如果变量是大写const Web3 = require('web3');//线上的测试环境var HDWalletProvider = require(&quot;truffle-hdwallet-provider&quot;);var mnemonic = &quot;这里是你的以太坊钱包私钥助记词&quot;; // 12 word mnemonic//使用infura在线的providervar provider = new HDWalletProvider(mnemonic, &quot;https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5&quot;);const web3 = new Web3(provider);/** * 测试web3 */testSend = async ()=&gt; {        let accounts = await web3.eth.getAccounts();        console.log(accounts);        let account0 = accounts[0];        let account1 = '0x5828eb46D40795Da76429553845DfA622F062CB2';        let b0 = await web3.eth.getBalance(account0);        let b1 = await web3.eth.getBalance(account1);        console.log('开始转账：address0:' + account0 + ' :' + b0 + ' address1:'+account1 + ' account1:' + b1);        const tx = web3.eth.sendTransaction({            from:account0,            to:account1,            value: web3.utils.toWei('1', 'ether'),            data: web3.utils.toHex('I love you ,xiao man ju')        },async (err,address)=&gt;  {            console.log(&quot;转账成功,address:&quot; + address);            b0 = await web3.eth.getBalance(account0);            b1 = await web3.eth.getBalance(account1);            let tx = await web3.eth.getTransaction(address);            console.log('tx:'+ JSON.stringify(tx) +' 转账成功：address0:'+account0+':' + b0 + ' address1:'+account1+' account1:' + b1);        });       }testSend();</code></pre></li><li><p>使用nodejs运行测试代码</p><pre class="highlight"><code class>node EtherOnlieRinkebyTest.test.js</code></pre><p>输出结果如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544225.png" alt></p></li></ol><p>到此从开发到上传到访问以太坊rinkeby测试网络已经完成。</p><h1 id="nodejs测试框架"><a class="markdownIt-Anchor" href="#nodejs测试框架"></a> Nodejs测试框架</h1><p>上面我们测试一个node脚本是直接使用node命令直接运行，对于实际开发应用中如果想做到自动化测试用例的运行，需要用到类型java里面Junit测试框架的东西，这个东西在node里面叫Mocha</p><ol><li><p>安装mocha</p><pre class="highlight"><code class>npm install --save mocha</code></pre></li><li><p>修改<code>package.json</code>，将scripts.test改成<code>mocha</code></p><pre class="highlight"><code class>{  &quot;name&quot;: &quot;blockchian1&quot;,  &quot;version&quot;: &quot;1.0.0&quot;,  &quot;description&quot;: &quot;&quot;,  &quot;main&quot;: &quot;app.js&quot;,  &quot;directories&quot;: {    &quot;test&quot;: &quot;test&quot;  },  &quot;dependencies&quot;: {    &quot;mocha&quot;: &quot;^5.2.0&quot;,    &quot;solc&quot;: &quot;^0.4.25&quot;  },  &quot;devDependencies&quot;: {},  &quot;scripts&quot;: {    &quot;test&quot;: &quot;mocha&quot;  },  &quot;author&quot;: &quot;&quot;,  &quot;license&quot;: &quot;ISC&quot;}</code></pre><blockquote><p>配置了scripts.test 为mocha命令，<code>npm run test</code>访问的就是mocha的测框架</p></blockquote></li><li><p>mocha测试，<code>MochaTest.test.js</code>, describe就是基本的mocha测试骨架，it是测试用例</p><pre class="highlight"><code class>const assert = require('assert');/** * ecs6 mocha测试 */class Test {    say() {        return 'hello';    }    happy() {        return 'haha';    }}//开始写mocha测试框架let dog;beforeEach(()=&gt;{    dog = new Test();})describe('第一个mocha测试用例',()=&gt; {    it('测试hello()',()=&gt;{        //const  dog = new Test();        let say = dog.say();        console.log(say);        assert.equal(say,'hello');    })    it('测试happy()',()=&gt;{        let happy = dog.happy();        console.log(happy);        assert.equal(happy,'haha');    })})</code></pre></li></ol><blockquote><p>以上用到了assert组件，这个类似java里面的Assert断言，默认在node上下文已将安装，直接依赖使用即可</p></blockquote><ol start="4"><li>运行测试用例<pre class="highlight"><code class>npm run test</code></pre>这个test访问的就是我们之前修改的<code>package.json</code>里面的test命令mocha，类似maven构建时的测试，它将运行项目上下文中的所有实现了mocha的测试用例</li></ol>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>区块链技术之比特币运作原理</title>
      <link href="/qu-kuai-lian/qu-kuai-lian-ji-zhu-zhi-bi-te-bi-yun-zuo-yuan-li/"/>
      <url>/qu-kuai-lian/qu-kuai-lian-ji-zhu-zhi-bi-te-bi-yun-zuo-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是比特币"><a class="markdownIt-Anchor" href="#什么是比特币"></a> 什么是比特币</h1><p>点对点的传输的一个去中心化的电子现金系统。每个节点都共同维护一个区块链形式存储的交易记录，每个比特币节点遵守同一个比特币网络协议，并基于密码学原理加密每一笔交易记录和区块，实现每一笔交易不可逆、防篡改、去中心化的、数据可监管溯源的电子现金交易系统。</p><h2 id="比特币特点"><a class="markdownIt-Anchor" href="#比特币特点"></a> 比特币特点</h2><ul><li>比特币最初由中本聪2008年发明</li><li>比特币发行和交易不依赖中央机构</li><li>比特币的发行总量不会超过2100万个</li><li>只要能够联网，安装比特币客户端，任何人都能接入到这个比特币网络</li><li>比特币的账户地址是匿名的</li><li>任何国家或者机构无法监管或者操纵这个比特币网络</li><li>比特币是基于现代密码学实现的点对点交易的分布式超级账本</li></ul><h1 id="比特币行情"><a class="markdownIt-Anchor" href="#比特币行情"></a> 比特币行情</h1><p>比特币从诞生以来已经翻了好几万倍了，比特币的第一笔交易是一个程序员用50btc买了披萨，第一批持有比特币的人估计早已经是千万富翁，但是神奇的比特币之父中本聪的创始区块及它的账户的其他比特币都还没有发生转账交易。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508680.png" alt></p><h1 id="区中心化的比特币网络"><a class="markdownIt-Anchor" href="#区中心化的比特币网络"></a> 区中心化的比特币网络</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage.png" alt></p><p>这个比特币网络大致是这个样子的，节点分为以下几类：</p><ul><li>全数据节点：保存了完整的区块链所有交易信息</li><li>矿工节点：负责打包新的交易数据制作新的区块</li><li>轻客户端节钱包节点：只保留自己关心交易数据</li></ul><h1 id="什么是区块链"><a class="markdownIt-Anchor" href="#什么是区块链"></a> 什么是区块链</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508350.png" alt><br>区块链有以下几个特点：</p><ul><li>区块链本质是一个分布式的超级账本，整个比特币网络各个节点仅仅认可和维护记录一样且长度最长的区块链</li><li>每个区块由区块头（上一个区块的hash值，当前区块的高度，出块的时间等）+ 交易记录列表 组成</li><li>所有经过验证符合比特币协议的交易记录都会被“矿工”打包进新的区块，然后广播给所有其它节点。</li></ul><p>每一个新的区块的都有一个指向上一个区块的hash值，所以这条链被形象的称之为<strong>区块链</strong></p><h1 id="什么是挖矿"><a class="markdownIt-Anchor" href="#什么是挖矿"></a> 什么是挖矿</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508575.png" alt><br>上图是传统的煤矿挖矿的矿工，比特币的“挖矿”当然不是这个挖矿。<br>比特币的挖矿是指：将接收到全网的交易记录打包制作到一个新区块并广播至其它节点的过程，由于这个过程通常不是那么容易，需要不停的hash计算符合标准的随机数才能生效新区块，平均全网每10分钟才能有计算出这样的随机数，所以形象的形容为比特币的“挖矿”</p><h2 id="挖矿的原理"><a class="markdownIt-Anchor" href="#挖矿的原理"></a> 挖矿的原理</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508972.png" alt><br>挖矿的过程如下：</p><ol><li>每个矿工节点都共同监听最新的交易数据，并做合法性校验，将符合校验的交易打包进新的区块中</li><li>在新的区块中添加给矿工账户转账的一笔交易，给矿工自己加上相应的比特币奖励和交易记录收取的手续费</li><li>最后一步用新区块的所有内容+一个随机数做SHA-256计算出hash值，使得这个hash值的二进制数符合一定规则，才能向全网广播这个新的区块</li></ol><p>那么接下来我们思考下以下三个问题：</p><ol><li>整个网络那么多矿工谁都有打包制作的权利，怎么解决并发问题？</li><li>这种“苦力活”如果没人做怎么办？</li><li>如果这个矿工“不老实”怎么办？</li></ol><h3 id="1-整个网络那么多矿工谁都有打包制作的权利怎么解决并发问题"><a class="markdownIt-Anchor" href="#1-整个网络那么多矿工谁都有打包制作的权利怎么解决并发问题"></a> 1. 整个网络那么多矿工谁都有打包制作的权利，怎么解决并发问题？</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508157.png" alt><br>在比特币的协议中规定，给挖矿过程增加了一定的难度，使得矿工挖矿并不是那么容易，一般是全网的所有矿工节点的所有算力一起计算10分钟才能制作出一个合法的新区块。<br>有了这个规定，这个比特币网络就有充足的时间让大部分节点同步最新的区块数据，而减少并发问题。这个挖矿的难度在比特币中就叫工作量证明机制（Proof-of-Work，PoW）。</p><p>刚刚提到的10分钟，为什么是10分钟，是怎么保证的？</p><p>先来回答下为什么是10分钟，而不是15分钟、2分钟、8分钟，中本聪在设计比特币机制时，考虑到新区块数据在全世界节点的广播同步有一定的网络延迟，于是为了尽量避免“矿工A和矿工B在不知道对方都计算出结果的情况下同时发送计算结果”的事情，规定了制作新区款的难度，这个难度难到平均每个矿工需要花10分钟挖出一个区块，于是设计了一个这样的值：理论平均出块时间=10分钟。至于为什么是10分钟，那总得取一个值吧，综合考量就定了10分钟。</p><p>是怎么保证全网的平均出块时间一直保证在10分钟，不会随着计算能力的提升，就不需要10分钟了吗？</p><p>比特币规定，每挖完2016个区块，数学题的难度会自动的根据这2016个区块的实际挖出时间，动态地做出调整。</p><p>也就是说，每2016个区块的难度都是一样的，接下来的2016个区块的难度，根据前2016个区块的难度以及前2016个区块的整体实际挖矿时间综合决定，这里有个计算公式如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508078.png" alt><br>可以看出10分钟不是绝对值，有的矿工可能运气好一些、3分钟、5分钟就能找到符合标准的新区块，有的矿工运气差一些，可能需要20分钟、30分钟才能找到符合标准的新区块，由于有了这个标准的动态调整，总能保证全网的平均出块时间在10分钟左右。<br>具体这个难度是什么，我们看下面公式：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508135.png" alt><br>而上面的这个目标值b就是和挖矿难度系数有关的值，目前的难度就是SHA-256【制作新区款的所有内容+一个随机数】的hash值的二进制值至少前72位为零，也就是最坏的结果是至少需要计算2^72次才能找到这个随机数，你可以认为这个72就是一个难度系数值</p><p>有了这个工作量证明机制就能保证一定全网在同一时刻只有一个矿工制作成符合标准的新区块吗，答案是否定的，那么如果出现这个情况，比特币网络是怎么处理的？</p><p>E矿工和F矿工分别基于d区块制作出了新的区块并广播至其他节点，如下图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508546.png" alt></p><p>同时收到e区块和f区块的节点会先同时保留这些区块，直到下一个区块基于其中一个区块制作出更长的区块链</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508291.png" alt></p><p>比特币协议规定只保留最长的区块链，较短的支链中的交易记录重新变为待确认交易重新发送至矿工节点作确认</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508312.png" alt></p><p>如果下一个区块碰巧又分别有两个新的区块基于e区块和f区块制作新区块，比特币网络的做法和上面的是一样的，先同时保留这些支链，直到最长的区块链出现，较短的区块的交易记录变为待确认交易重新发送至别人矿工节点。</p><h3 id="2-这种苦力活如果没人做怎么办"><a class="markdownIt-Anchor" href="#2-这种苦力活如果没人做怎么办"></a> 2. 这种“苦力活”如果没人做怎么办？</h3><p>比特币网络规定每成功生成一个新的区块，给相应的BTC给矿工账号作为奖励，并将新区块中的交易的手续费也归矿工所有，通过这个奖励机制大家就很乐意去干这个“苦力活”了。</p><p>这个奖励最初是50比特币，今后每产生21万个区块，比特币数量都会依次减半。直到第33次减半时，每个块产生0.0021个新比特币直接减为0个，最终比特币总量维持在2100万个。我们知道比特币大约每10分钟产生一个区块，而21万个10分钟接近4年。<br>最终这个比特币网络的矿工只能通过收取交易的手续费来维持他们的成本和收益<br>这个交易的手续费是可以交易方自己定的<br>但是矿工有权利优先选择手续费较高的记账或者拒绝，只要矿工们达成共识。</p><h2 id="挖矿工具矿机"><a class="markdownIt-Anchor" href="#挖矿工具矿机"></a> 挖矿工具——矿机</h2><p>挖矿的矿机从最初的使用PC个人电脑挖矿到专业的挖矿矿池，算力变得越来越强，挖矿的成本也越来越高，门槛越来越高。<br><strong>CPU挖矿→GPU挖矿→专业矿机挖矿→矿池挖矿</strong><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508408.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508413.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508512.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508831.png" alt></p><h1 id="比特币是如何进行交易的"><a class="markdownIt-Anchor" href="#比特币是如何进行交易的"></a> 比特币是如何进行交易的</h1><p>比特币交易符合以下几个特点：</p><ul><li>交易数据包含交易输入和交易输出，其中交易输入的金额总和必须&gt;=输出金额总和</li><li>挖矿奖励属于一个特殊的交易（称为coinbase交易），可以没有输入。</li><li>在比特币没有余额概念，只有分散到区块链里的UTXO（未花费交易记录）</li><li>UTXO是交易的基本单元，不能在分割。</li></ul><h2 id="比特币转账"><a class="markdownIt-Anchor" href="#比特币转账"></a> 比特币转账</h2><p>比特币的交易记录主要由以下几部分组成：</p><ul><li>交易的输入，是指向上一笔交易的hash值</li><li>交易的输入解锁脚本，能够证明这笔钱你有权动用</li><li>交易的输出，交易的输出对方账户</li><li>交易输出的加锁脚本，是的对方必须提供证明是转给他的，才有权动用</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508663.png" alt><br>上表格中：<br>记录1是个特殊的交易记录，是比特币矿工的奖励记录，给A账户转账10BTC，所以没有交易输入，这个交易记录叫coinbase<br>记录2:A使用记录1转给他的钱用来支付给B,并加锁这个转账<br>记录3：B收到这个转账时，提供自己的签名和公钥，证明确实是转给他的，B再用这笔转账支付10BTC给C</p><p>从上面的交易得知，<strong>我们把以上交易记录中可以用来当下一笔交易的未使用记录，称之为未花费记录（UTXO）</strong></p><p>我们再来看下面这个记录：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509067.png" alt></p><p>记录2中A需要支付5BTC给B，但是交易输入记录1是10BTC的，所以将自己的账户添加到交易输出中找回5BTC</p><p>记录4由于A需要支付10BTC，所以交易输入是两笔5BTC的交易记录。</p><p>从上面的交易可以看出,<strong>比特币系统中没有账户的概念，只有交易记录，一笔未花费交易记录不能拆开使用，如果要只需花费一部分，通过在交易输出添加一笔给自己转账的记录，类似现金找零。</strong></p><h3 id="如何防止同一笔前用两次"><a class="markdownIt-Anchor" href="#如何防止同一笔前用两次"></a> 如何防止同一笔前用两次</h3><p>A账号用【记录1】当做输入支付给10BTC给“B账号”，接着又用【记录1】当做输入支付给10BTC给“C账号”,<br>相当于10BTC用了两次。如下图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508784.png" alt></p><p>我们分情况来看同一笔交易输入支付给了不同的人：<br>**情况1：**两条交易记录打包在同一个区块中：那么以先收到的交易是合法的，后收到的交易是非法的<br>**情况2：**两条交易记录先后被打包进不同区块的同一主链中：那么当矿工验证交易合法性时，是从以往合法的所有区块的所有交易中查找验证的，先收到的交易是合法的，后收到的是非法的<br>**情况2：**两条交易记录先后被打包进不同区块的不同支链中：<br>A矿工在之前主链基础上制作新区款，先收到交易1；<br>B矿工在之前主链基础上制作新区款，先收到交易2。<br>那么矿工在做合法性验证时都认为是合法的，此时比特币网络发生分叉，随着之后新区款制作，根据比特币协议规定，将保留区块长度最长的链，较短的支链将丢弃，其中的交易记录重新变为未确认交易等待下一个新区块的合法性校验，此时校验不通过的交易将丢弃。</p><h2 id="真实的比特币交易数据的结构"><a class="markdownIt-Anchor" href="#真实的比特币交易数据的结构"></a> 真实的比特币交易数据的结构</h2><pre class="highlight"><code class>{   &quot;lock_time&quot;:0,   &quot;size&quot;:259,   &quot;version&quot;:1,   &quot;vin_sz&quot;:1,   “hash”:“2514161c059ac18bf2eff1e05c4628e322d846e930fd6dd4b24805ea59dc4913”,//这笔交易的ID   &quot;vout_sz&quot;:2,   “inputs”:[//这笔交易的的来源交易，也称输入交易，可能有多个      {         &quot;prev_out&quot;:{“hash”:“4f40655c4ab1a029bc41bc547f79556a0dc48d22df7202778fad592791c77fcd”,//上一笔交易的交易ID“index”:0 //在上一笔交易的输出列表的下标位置         },         “script”:“493046022100cd6795ebcd1b6b87833a4ad812733d3804065d34bafee24da181a770892272b902210088cd2484952ad2572f9bfb2874643dbb4b3c492b749e79d8177a14eb4a3bc61a014104bbf2b84900b6f898548687aefba86cc06da6f4656a71e45fa55128b501455b5486cb09705cfa23c1899fe46d4355c9058bb2de4f1a7f1a01ff27e00b306f7356” //解锁上一笔交易输出的参数      }   ],    “out”:[//这笔交易的交易对手方，也称交易输出，也可以有多个      {   //交易输出的锁定脚本，只有交易对方提供正确的自己的签名及公钥才能证明这笔钱是转给他的，才有资格进行下一次的转账交易         “script_string”:“OP_DUP OP_HASH160 f9d49c5cf3e120ad1be60b67d868603a8fc945d2 OP_EQUALVERIFY OP_CHECKSIG”,         &quot;address&quot;:&quot;1PmyxDv5VvGoSAKMr1DQcWB6sHPx1ZbgWe&quot;,         “value”:88994500000,//转多少钱，单位是聪，1亿聪=1BTC         &quot;script&quot;:&quot;76a914f9d49c5cf3e120ad1be60b67d868603a8fc945d288ac&quot;      },      {         &quot;script_string&quot;:&quot;OP_DUP OP_HASH160 088465c1f0c8b3b3da06f7073a921d6b95b22f49 OP_EQUALVERIFY OP_CHECKSIG&quot;,         &quot;address&quot;:&quot;1n31g4rKiEeXnZEZR6VZwm3LggLicEqEC&quot;,         &quot;value&quot;:1000000000,         &quot;script&quot;:&quot;76a914088465c1f0c8b3b3da06f7073a921d6b95b22f4988ac&quot;      }   ]}</code></pre><h2 id="比特币的脚本语言"><a class="markdownIt-Anchor" href="#比特币的脚本语言"></a> 比特币的脚本语言</h2><pre class="highlight"><code class>OP_DUP OP_HASH160 f9d49c5cf3e120ad1be60b67d868603a8fc945d2 OP_EQUALVERIFY OP_CHECKSIG</code></pre><p>上面是比特币交易中的交易输入解锁脚本，输入两个参数：<sig> <pubk> 使得<pubk>的HASH160值等于9d49c5cf3e120ad1be60b67d868603a8fc945d2，接着使用<pubk>验证<sig>签名，验证同步则表示该交易输入合法有效，就像用户名密码一样。</sig></pubk></pubk></pubk></sig></p><p>比特币脚本语言是非图灵完备脚本语言，就是说它不能实现复杂的逻辑。<br>比特币脚本语言的执行是遵循先进后出的原因，即它的变量读取是堆栈式，如下图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509028.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508906.png" alt></p><h2 id="最终的结构"><a class="markdownIt-Anchor" href="#最终的结构"></a> 最终的结构</h2><p>比特币就是通过每一个区块都有上一个区块的指正，每个区块中包含通过验证的合法交易组成的链式结构，并让所有节点同步这份数据，形成不可逆，串改成本巨大的分布式超级账本，称之为区块链<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509220.png" alt></p><h1 id="比特币的价值及存在问题"><a class="markdownIt-Anchor" href="#比特币的价值及存在问题"></a> 比特币的价值及存在问题</h1><p>比特币的价值在于，金融危机发生的时候，货币超发，法币贬值，社会财富缩水；<br>而比特币不依赖中央机构管理，期价值完全由供给关系决定，<br>当旧的法定货币崩溃时，人们便会涌向比特币，把比特币作为新的资产避风港——“21世纪版的黄金”<br>比特币是目前区块链技术落地最成功的项目，虽然比特币目前实际用的更多的是黑产（赌博、洗钱、黑客敲诈、传销），但是开创了人们对区块链技术无限探索和想象；</p><p>但同样存在着问题：</p><ul><li>由于有新区块难度限制，每秒处理交易数不足7/sec，交易确认时间长大几小时甚至几天交易确认时间长大几小时甚至几天</li><li>巨大的能源消耗（这也是比特币防篡改的代价）</li><li>随着计算机算力的提升，构建数字货币的密码学可能会被攻破</li><li>投机性强，泡沫大</li><li>算力集中，随着挖矿难度增加，只有少数几个矿池能够维持挖矿成本，失去去中心化初衷</li></ul><h1 id="区块链的应用"><a class="markdownIt-Anchor" href="#区块链的应用"></a> 区块链的应用</h1><p>基于区块链的记录不可逆、去中心化、全民监管的特点来构建一个信任网络，降低<br>社会协同合作成本，主要应用如下：</p><ul><li>企业融资：企业可以通过发行代币的方式对投资者承诺未来能够通过代币购买</li><li>公共实物：居于区块链上的登记的信息不可篡改，能够很方便的证明你的信息合法性</li><li>公益：在当前大环境下，听到慈善、公益，心里就不是滋味——信息不透明、 监督困难；利用区块链技术能够追踪每一笔善款的去向</li><li>供应链：结合物联网实现对物品信息的区块链管理，做到每个每个商品从生产到消费者的每一个环节，做到正品溯源；</li><li>供应链金融：代理商可以低成本的通过货物抵押向供应商赊账，并利用区块链智能合约技术保证物品出售时自动回款给供应商</li><li>物流：通过区块链技术做到CP间的信息信任，较少物流环节的信息交换成本，并通过区块链加密技术做到信息的保护。</li></ul><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><ul><li>区块链为信息时代的去中心化信息交易提供了良好的解决思路</li><li>区块链只是一种解决问题的技术，一定是结合实际场景落地才能有好的未来，否则就是技术人和投机者的一场狂欢。</li><li>炒币有风险，入市需谨慎</li></ul><h1 id="了解区块链的一些网站"><a class="markdownIt-Anchor" href="#了解区块链的一些网站"></a> 了解区块链的一些网站：</h1><p>区块链相关导航：<a href="https://www.feixiaohao.com/daohanglist/" target="_blank" rel="noopener">https://www.feixiaohao.com/daohanglist/</a><br>比特币富豪排行榜：<a href="http://bitop.top/" target="_blank" rel="noopener">http://bitop.top/</a><a href="http://bitop.top/" target="_blank" rel="noopener">http://bitop.top/</a>)</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RokectMQ 和Kafka对比</title>
      <link href="/xue-xi/rocketmq-vs-kafka/"/>
      <url>/xue-xi/rocketmq-vs-kafka/</url>
      
        <content type="html"><![CDATA[<h1 id="rokectmq-和kafka对比"><a class="markdownIt-Anchor" href="#rokectmq-和kafka对比"></a> RokectMQ 和Kafka对比</h1><table><thead><tr><th>对比项</th><th>Kafka</th><th>RocketMQ</th><th>总结</th></tr></thead><tbody><tr><td>部署架构</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562836313289_5.png" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562836232412_3.webp" alt="img"></td><td>1. Zookeeper对应NameServer,NameServer没有用强一直的watch来监听各个节点可靠性，而是使用心跳机制。<br>2. RocketMQ没有用ZK做高可用负载，原因是Broker在RocketMQ中就是物理概念，一台机器就是一个broker,Broker-Master和Broker-Slave关系在部署初始化是确认，运行过程中无需负载的选主切换，当然RMQ也就不支持在Broker-Master挂掉是自主选主Slave为master,需要手动切换。</td></tr><tr><td>行3架构拓扑图</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562837115046_7-1574933554003.png" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562837123812_9.png" alt="img"></td><td>1.kafka的partition对应rmq的queue<br>2.都可以为topic指定对应的分区数量<br>3.通过topic创建命令来说明topic、partition和broker<br>(Master/Slave)的关系<br>kafka:<br> <em>sh bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic mytopic</em> <br>roketmq:<br> <em>sh /root/rocketmq/bin/mqadmin updateTopic -c defaultCluster -readQueueNums/writeQueueNums 3 -t mytopic</em> <br>可以看出不一样的是kafka需要指定<br>–replication-factor来说明这个topic一个master需要几个slave，而rmq不需要，因为这个Master/slave拓扑结构是在配置写死的<br>4. Kafka的Master/slave是逻辑结构，可以是同一台机器，而rmq不行，必须在初始化时就在配置文件中写死，要么是不同机器，要么是同一机器的不同进程（可以是端口不一样），是对应的物理结构。kafka可实现在通过zk自动Slave升级成Master<br>5. Rmq之所以没有用zk做主备自动切换，也是为了简化整个系统的复杂度，无需过多的关心选主和一致性的问题，同时也为了保证消息的不乱序消费，造成业务异常。</td></tr><tr><td>消息存储</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562838493614_11.jpeg" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562838500422_13.jpeg" alt="img"></td><td>1.kafka和rmq都是用文件形式来持久化消息2. kafka为每个partiion单独文件存储；而rmq不是所有的topic的所有queue的数据存储在commitlog中（默认按1G大小存储，超过时新建一个文件，按文件大小偏移量命名），并每个topic的每个queue用consumerqueue小文件存储消费位点信息，可以通过消费位点到commitlog快速定位到对应的数据行。rocketmq这样做的好处是：文件顺序写，小文件随机读。优化了kafka当topic较多时的性能问题。那么rmq是怎么做到的：<br> - producer消息先投递到commitlog,异步最终一致写入consumerqueue - 由于是一个文件，根据linux文件写入缓存页批量写的机制，写入非常迅速，因为没有多个文件的资源竞争<br>- 随机读，因为cosumerqueue中的数据非常少，能够一次性读取很多数据，访问速度和内存相当，通过预读取机制这部分性能可以忽略不计，对于commitlog这个大文件虽然是随机读，但是整体是有序的，还是可以充分利用PageCache的性能，再加上文件内存映射技术，很好的保障了在很多topic下的读写性能。</td></tr><tr><td>性能</td><td>单机写入TPS约在百万条/秒，消息大小10个字节</td><td>RocketMQ单机写入TPS单实例约7万条/秒，单机部署3个Broker，可以跑到最高12万条/秒，消息大小10个字节</td><td>1. Kafka的TPS跑到单机百万，主要是由于Producer端将多个小消息合并，批量发向Broker <br> 2. RocketMQ为什么没有这么做？Producer通常使用Java语言，缓存过多消息，GC是个很严重的问题Producer调用发送消息接口，消息未发送到Broker，向业务返回成功，此时Producer宕机，会导致消息丢失，业务出错Producer通常为分布式系统，且每台机器都是多线程发送，我们认为线上的系统单个Producer每秒产生的数据量有限，不可能上万。缓存的功能完全可以由上层业务完成。</td></tr><tr><td>数据可靠性</td><td>Kafka使用异步刷盘方式，异步Replication</td><td>RocketMQ支持异步实时刷盘，同步刷盘，同步Replication，异步Replication</td><td>1.RocketMQ的同步刷盘在单机可靠性上比Kafka更高，不会因为操作系统Crash，导致数据丢失。在强可靠性要求场景可用 2.另外Kafka的Replication以topic为单位，支持主机宕机，备机自动切换，但是这里有个问题，由于是异步Replication，那么切换后会有数据丢失，且会有消息乱序的风险。</td></tr><tr><td>消费失败重试</td><td>Kafka消费失败不支持自动重试</td><td>RocketMQ消费失败支持定时重试，每次重试间隔时间顺延</td><td>1. kafka如果需要实现消息重试，需要自己实现取出消息重新发送一遍。</td></tr><tr><td>消息顺序</td><td>Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序</td><td>RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序</td><td>当broker的leader挂掉瞬间，旧的leader对client可见，所以可能存在多个消费者消费不同的broker情况，造成消息乱序消费。</td></tr><tr><td>定时消息消费</td><td>Kafka不支持定时消息</td><td>RocketMQ支持</td><td>开源版本RocketMQ仅支持定时Level阿里云ONS支持定时Level，以及指定的毫秒级别的延时时间</td></tr><tr><td>事物消息</td><td>不支持</td><td>支持但是没有超时回查机制</td><td>阿里内部版本支持完整实物消息</td></tr><tr><td>消息回溯</td><td>可以按照Offset来回溯消息</td><td>支持按照时间来回溯消息，精度毫秒，例如从一天之前的某时某分某秒开始重新消费消息</td><td>典型业务场景如consumer做订单分析，但是由于程序逻辑或者依赖的系统发生故障等原因，导致今天消费的消息全部无效，需要重新从昨天零点开始消费，那么以时间为起点的消息重放功能对于业务非常有帮助。</td></tr><tr><td>消息消费并行度</td><td>Kafka的消费并行度依赖Topic配置的分区数，如分区数为10，那么最多10台机器来并行消费（每台机器只能开启一个线程），或者一台机器消费（10个线程并行消费）。即消费并行度和分区数一致</td><td>顺序消费方式并行度同Kafka完全一致<br> 乱序方式并行度取决于Consumer的线程数，如Topic配置10个队列，10台机器消费，每台机器100个线程，那么并行度为1000。</td><td>RoketMQ在不要求顺序消费时，并行度可以很高</td></tr><tr><td>开发语言</td><td>Scala</td><td>Java</td><td>分布式系统中，Java的语言生态更好</td></tr><tr><td>消息堆积能力</td><td>非常好，上亿级</td><td>非常好，上亿级</td><td>消息堆积能力都非常好</td></tr><tr><td>商业支持</td><td>LinkIn开源</td><td>Alibaba开源</td><td></td></tr><tr><td>成熟度</td><td>Kafka在日志领域比较成熟</td><td>RocketMQ在阿里集团内部有大量的应用在使用，每天都产生海量的消息，并且顺利支持了多次天猫双十一海量消息考验，是数据削峰填谷的利器。</td><td>商业场景RocketMQ更加适合，并且更符合开发习惯</td></tr></tbody></table><h1 id="qa"><a class="markdownIt-Anchor" href="#qa"></a> QA</h1><h2 id="为什么使用消息队列消息队列的作用是什么"><a class="markdownIt-Anchor" href="#为什么使用消息队列消息队列的作用是什么"></a> 为什么使用消息队列?消息队列的作用是什么?</h2><p>异步化、解耦、消除峰值</p><h2 id="kafka-的-topic-和分区内部是如何存储的有什么特点"><a class="markdownIt-Anchor" href="#kafka-的-topic-和分区内部是如何存储的有什么特点"></a> Kafka 的 Topic 和分区内部是如何存储的，有什么特点?</h2><p>新建topic时指定分区数量，并为每个分区维护消息数据存储文件，随着topic数量增加，文件数量增加，读写性能下降。</p><h2 id="与传统的消息系统相比kafka-的消费模型有什么优点"><a class="markdownIt-Anchor" href="#与传统的消息系统相比kafka-的消费模型有什么优点"></a> 与传统的消息系统相比，Kafka 的消费模型有什么优点?</h2><ol><li>Kafka是一个分布式系统，易于向外扩展。</li><li>它同时为发布和订阅提供高吞吐量。</li><li>它支持多订阅者，当失败时能自动平衡消费者。</li><li>消息的持久化。</li></ol><h2 id="kafka-如何实现分布式的数据存储与数据读取"><a class="markdownIt-Anchor" href="#kafka-如何实现分布式的数据存储与数据读取"></a> Kafka 如何实现分布式的数据存储与数据读取?</h2><p>日志形式存储，并生成索引文件，能够通过offset下标快速定位数据行</p><h2 id="kafka-为什么比-rocketmq-支持的单机-partition-要少"><a class="markdownIt-Anchor" href="#kafka-为什么比-rocketmq-支持的单机-partition-要少"></a> Kafka 为什么比 RocketMQ 支持的单机 Partition 要少?</h2><p>数据存储形式决定，kafka为每个分区都生成存储文件，当较多的Parition时，随机写冲突加大，性能下降</p><h2 id="为什么需要分区也就是说主题只有一个分区难道不行吗"><a class="markdownIt-Anchor" href="#为什么需要分区也就是说主题只有一个分区难道不行吗"></a> 为什么需要分区，也就是说主题只有一个分区，难道不行吗?</h2><p>分区是为了尽可能的减少资源竞争，增加处理并行度</p><h2 id="日志为什么需要分段"><a class="markdownIt-Anchor" href="#日志为什么需要分段"></a> 日志为什么需要分段?</h2><p>方便快速清理无用数据，提高磁盘利用率</p><h2 id="kafka-是依靠什么机制保持高可靠高可用"><a class="markdownIt-Anchor" href="#kafka-是依靠什么机制保持高可靠高可用"></a> Kafka 是依靠什么机制保持高可靠，高可用?</h2><p>利用zk实现Master/Slave主备切换</p><h2 id="消息队列如何保证消息幂等"><a class="markdownIt-Anchor" href="#消息队列如何保证消息幂等"></a> 消息队列如何保证消息幂等?</h2><p>利用消息的唯一标识，在业务系统中做好幂等，消息中间件本身无需保证幂等</p><h2 id="让你自己设计个消息队列你会怎么设计会考虑哪些方面"><a class="markdownIt-Anchor" href="#让你自己设计个消息队列你会怎么设计会考虑哪些方面"></a> 让你自己设计个消息队列，你会怎么设计，会考虑哪些方面?</h2><ul><li>消息的持久化</li><li>分布式可靠性</li><li>消息堆积能力</li><li>消息重试</li></ul><blockquote><p>参考文章：<br><a href="https://cloud.tencent.com/developer/news/306092" target="_blank" rel="noopener">分布式消息队列RocketMQ与Kafka架构上的巨大差异</a><br><a href="https://zl378837964.iteye.com/blog/2421888" target="_blank" rel="noopener">RocketMQ与Kafka对比</a><br><a href="https://github.com/javahongxi/whatsmars/wiki/RocketMQ%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93" target="_blank" rel="noopener">RocketMQ吐血总结</a><br><a href="https://www.cnblogs.com/xiaodf/p/5075167.html" target="_blank" rel="noopener">RocketMQ原理介绍最透彻的文章</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> RocketMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客搭建的介绍</title>
      <link href="/blog-introduce/"/>
      <url>/blog-introduce/</url>
      
        <content type="html"><![CDATA[<h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1><p>这是我修改自<a href="https://github.com/godweiyang/hexo-matery-modified" target="_blank" rel="noopener">hexo-theme-matery</a>的个性化hexo博客模板，主要修改了一些个性化配置，为了方便大家直接搭建使用。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20191128160144163.png" alt="image-20191128160144163"></p><h1 id="我的博客演示"><a class="markdownIt-Anchor" href="#我的博客演示"></a> 我的博客演示</h1><p><a href="https://okeeper.com">https://okeeper.com</a></p><h1 id="快速方法"><a class="markdownIt-Anchor" href="#快速方法"></a> 快速方法</h1><h2 id="1-下载主题源码"><a class="markdownIt-Anchor" href="#1-下载主题源码"></a> 1. 下载主题源码</h2><p>为了减小源码的体积，我将插件目录<code>node_modules</code>进行了压缩，大家下载完后需要解压。另外添加水印需要的字体文件我也删除了，大家可以直接从电脑自带的字体库中拷贝。</p><ul><li>首先运行<code>git clone git@github.com:godweiyang/hexo-matery-modified.git</code>将所有文件下载到本地。</li><li>解压<code>node_modules.zip</code>，然后删除<code>node_modules.zip</code>和<code>.git</code>文件夹。</li><li>还缺一个字体（为图片添加水印需要用到），去<code>C:\Windows\Fonts</code>下找到<code>STSong Regular</code>，复制到<code>hexo-matery-modified</code>文件夹下。</li></ul><h2 id="2-环境准备"><a class="markdownIt-Anchor" href="#2-环境准备"></a> 2. 环境准备</h2><h3 id="21-安装nodejs"><a class="markdownIt-Anchor" href="#21-安装nodejs"></a> 2.1 安装Node.js</h3><p>首先下载稳定版Node.js，我这里给的是64位的。<br>安装选项全部默认，一路点击Next。</p><p>最后安装好之后，按Win+R打开命令提示符，输入<code>node -v</code>和<code>npm -v</code>，如果出现版本号，那么就安装成功了。</p><p>添加国内镜像源<br>如果没有梯子的话，可以使用阿里的国内镜像进行加速。</p><pre class="highlight"><code class>npm config set registry https://registry.npm.taobao.org</code></pre><h3 id="22-安装hexo"><a class="markdownIt-Anchor" href="#22-安装hexo"></a> 2.2 安装hexo</h3><pre class="highlight"><code class>npm i hexo-cli -ghexo -vhexo init# 安装必要组件npm install# 生成静态文件hexo g#启动服务器hexo s</code></pre><h2 id="3-修改配置_configyml"><a class="markdownIt-Anchor" href="#3-修改配置_configyml"></a> 3. 修改配置<code>_config.yml</code></h2><pre class="highlight"><code class="properties"><span class="hljs-comment"># 修改git配置，当执行 `hexo d` 时, 将自动提交到这个git地址</span><span class="hljs-attr">deploy</span>:<span class="hljs-string"></span><span class="hljs-attr">-</span> <span class="hljs-string">type: git</span>  <span class="hljs-attr">repository</span>: <span class="hljs-string">https://github.com/okeeper/okeeper.github.io.git</span>  <span class="hljs-attr">branch</span>: <span class="hljs-string">master</span><span class="hljs-comment"># 修改标题和关键字</span></code></pre><h2 id="4-在github中添加你的博客项目"><a class="markdownIt-Anchor" href="#4-在github中添加你的博客项目"></a> 4. 在github中添加你的博客项目</h2><p>一般为 {你的id}.github.io, 这样后续就可以直接通过 {你的id}.github.io访问到你的blog</p><h2 id="5-编译发布"><a class="markdownIt-Anchor" href="#5-编译发布"></a> 5. 编译&amp;发布</h2><pre class="highlight"><code class># 编译source目录下的文章生成public静态文件hexo g# 提交到你的blog仓库hexo d</code></pre><blockquote><p>hexo部署到github时，提示typeError [ERR_INVALID_ARG_TYPE]: The “mode“ argument must be integer. Receive…<br>出现这个问题的原因是node版本较高</p></blockquote><blockquote><p>解决方法</p></blockquote><pre class="highlight"><code class>$ hexo -vhexo: 3.9.0hexo-cli: 4.3.0os: darwin 22.3.0 13.2.1node: 21.1.0acorn: 8.10.0</code></pre><p>hexo 版本才3.9.0,</p><p>而node 版本已经是14.17.5了</p><p>更换版本<br>使用nvm命令</p><pre class="highlight"><code class>查看可用node版本nvm list#使用低版本的nodenvm use v12.14.0# 再试一下hexo dhexo d</code></pre><h1 id="个性化"><a class="markdownIt-Anchor" href="#个性化"></a> 个性化</h1><h3 id="1-添加水印"><a class="markdownIt-Anchor" href="#1-添加水印"></a> 1. 添加水印</h3><p>为了防止别人抄袭你文章，可以把所有的图片都加上水印，方法很简单。<br><a href="http://xn--watermark-u75nydvqv95a9iho1p6nr2mn0qbjz0e1uk9i9esl5i.py" target="_blank" rel="noopener">首先在博客根目录下新建一个watermark.py</a>，代码如下：</p><pre class="highlight"><code class="python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><span class="hljs-keyword">import</span> sys<span class="hljs-keyword">import</span> glob<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageDraw<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageFont<span class="hljs-keyword">def</span> <span class="hljs-title function_">watermark</span>(<span class="hljs-params">post_name</span>):    <span class="hljs-keyword">if</span> post_name == <span class="hljs-string">&#x27;all&#x27;</span>:        post_name = <span class="hljs-string">&#x27;*&#x27;</span>    dir_name = <span class="hljs-string">&#x27;source/_posts/&#x27;</span> + post_name + <span class="hljs-string">&#x27;/*&#x27;</span>    <span class="hljs-keyword">for</span> files <span class="hljs-keyword">in</span> glob.glob(dir_name):        im = Image.<span class="hljs-built_in">open</span>(files)        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(im.getbands()) &lt; <span class="hljs-number">3</span>:            im = im.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)            <span class="hljs-built_in">print</span>(files)        font = ImageFont.truetype(<span class="hljs-string">&#x27;STSONG.TTF&#x27;</span>, <span class="hljs-built_in">max</span>(<span class="hljs-number">30</span>, <span class="hljs-built_in">int</span>(im.size[<span class="hljs-number">1</span>] / <span class="hljs-number">20</span>)))        draw = ImageDraw.Draw(im)        draw.text((im.size[<span class="hljs-number">0</span>] / <span class="hljs-number">2</span>, im.size[<span class="hljs-number">1</span>] / <span class="hljs-number">2</span>),                  <span class="hljs-string">u&#x27;@godweiyang&#x27;</span>, fill=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), font=font)        im.save(files)<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(sys.argv) == <span class="hljs-number">2</span>:        watermark(sys.argv[<span class="hljs-number">1</span>])    <span class="hljs-keyword">else</span>:        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[usage] &lt;input&gt;&#x27;</span>)</code></pre><p>字体也放根目录下，自己找字体。然后每次写完一篇文章可以运行python3 <a href="http://watermark.py" target="_blank" rel="noopener">watermark.py</a> postname添加水印，如果第一次运行要给所有文章添加水印，可以运行python3 <a href="http://watermark.py" target="_blank" rel="noopener">watermark.py</a> all</p><h3 id="2-添加快速评论"><a class="markdownIt-Anchor" href="#2-添加快速评论"></a> 2. 添加快速评论</h3><p>注册：<a href="https://leancloud.cn/" target="_blank" rel="noopener">https://leancloud.cn/</a></p><pre class="highlight"><code class="yaml"><span class="hljs-comment"># Valine 评论模块的配置，默认为不激活，如要使用，就请激活该配置项，并设置 appId 和 appKey.</span><span class="hljs-attr">valine:</span>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span>  <span class="hljs-attr">appId:</span> <span class="hljs-string">***修改成你自己的appId</span>  <span class="hljs-attr">appKey:</span> <span class="hljs-string">***修改成你自己的appKey</span>  <span class="hljs-attr">notify:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">verify:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">visitor:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">avatar:</span> <span class="hljs-string">&#x27;wavatar&#x27;</span> <span class="hljs-comment"># Gravatar style : mm/identicon/monsterid/wavatar/retro/hide</span>  <span class="hljs-attr">pageSize:</span> <span class="hljs-number">10</span>  <span class="hljs-attr">placeholder:</span> <span class="hljs-string">&#x27;来都来了，不留点啥啊！&#x27;</span> <span class="hljs-comment"># Comment Box placeholder</span></code></pre><h3 id="3-给文章添加背景音乐"><a class="markdownIt-Anchor" href="#3-给文章添加背景音乐"></a> 3. 给文章添加背景音乐</h3><p>在.md的markdown文件的开头添加这段代码</p><pre class="highlight"><code class>&lt;div align=&quot;middle&quot;&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=407679465&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</code></pre><h3 id="4-front-matter-选项详解"><a class="markdownIt-Anchor" href="#4-front-matter-选项详解"></a> 4. Front-matter 选项详解</h3><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2" target="_blank" rel="noopener">开源中国在线工具</a>、<a href="http://encode.chahuo.com/" target="_blank" rel="noopener">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx" target="_blank" rel="noopener">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><pre class="highlight"><code class="yaml"><span class="hljs-meta">---</span><span class="hljs-attr">title:</span> <span class="hljs-string">typora-vue-theme主题介绍</span><span class="hljs-attr">date:</span> <span class="hljs-number">2018-09-07 09:25:00</span><span class="hljs-attr">author:</span> <span class="hljs-string">赵奇</span><span class="hljs-attr">img:</span> <span class="hljs-string">/source/images/xxx.jpg</span><span class="hljs-attr">top:</span> <span class="hljs-literal">true</span><span class="hljs-attr">cover:</span> <span class="hljs-literal">true</span><span class="hljs-attr">coverImg:</span> <span class="hljs-string">/images/1.jpg</span><span class="hljs-attr">password:</span> <span class="hljs-string">8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92</span><span class="hljs-attr">toc:</span> <span class="hljs-literal">false</span><span class="hljs-attr">mathjax:</span> <span class="hljs-literal">false</span><span class="hljs-attr">summary:</span> <span class="hljs-string">这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</span><span class="hljs-attr">categories:</span> <span class="hljs-string">Markdown</span><span class="hljs-attr">tags:</span>  <span class="hljs-bullet">-</span> <span class="hljs-string">Typora</span>  <span class="hljs-bullet">-</span> <span class="hljs-string">Markdown</span><span class="hljs-meta">---</span></code></pre><h1 id="搭建教程请参考"><a class="markdownIt-Anchor" href="#搭建教程请参考"></a> 搭建教程请参考</h1><p><a href="https://godweiyang.com/2018/04/13/hexo-blog/" target="_blank" rel="noopener">https://godweiyang.com/2018/04/13/hexo-blog/</a></p><h1 id="写文章-发布文章"><a class="markdownIt-Anchor" href="#写文章-发布文章"></a> 写文章、发布文章</h1><p>然后输入<code>hexo new post &quot;article title&quot;</code>，新建一篇文章。</p><p>然后打开<code>source\_posts</code>的目录，可以发现下面多了一个文件夹和一个<code>.md</code>文件，一个用来存放你的图片等数据，另一个就是你的文章文件啦。</p><p>编写完markdown文件后，根目录下输入<code>hexo g</code>生成静态网页，然后输入<code>hexo s</code>可以本地预览效果，最后输入<code>hexo d</code>上传到github上。这时打开你的github.io主页就能看到发布的文章啦。</p><h1 id="结合typora的markdown编辑器"><a class="markdownIt-Anchor" href="#结合typora的markdown编辑器"></a> 结合Typora的markdown编辑器</h1><p>有强迫症的人适合当程序员，应为容不得半点不舒服</p><p>对比了市面上的主流markdown编辑器，兼顾以下几个点的，好像只有Typora了</p><ul><li>即时预览，当你输入markdown关键字时自动变换预览格式</li><li>截图直接粘贴生成图片存入指定目录，设置见文件-&gt;偏好设置&gt;图像&gt;路径配置</li><li>简洁并支持主题自定义</li><li>开源免费</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Blog </tag>
            
            <tag> typora-vue-theme </tag>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
